<!doctype html>
<html class="theme-next use-motion ">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-121973094-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-121973094-1');
</script>


<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
 <script type="text/x-mathjax-config">
 MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});
 </script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #272822; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #272822, 0 0 5px #272822; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #272822;    /*上边框颜色*/
        border-left-color: #272822;    /*左边框颜色*/
    }
</style>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />








  <link rel="stylesheet" type="text/css" href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5"/>



  
    <link href='//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  


<link rel="stylesheet" type="text/css" href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" />

<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.2"/>




  <meta name="keywords" content="Hexo,next" />



  <link rel="alternate" href="/atom.xml" title="程序员说" type="application/atom+xml" />



  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.2" />


<meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="程序员说">
<meta property="og:url" content="http://www.devtalking.com/page/2/index.html">
<meta property="og:site_name" content="程序员说">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="程序员说">
<meta name="twitter:description">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    sidebar: 'post'
  };
</script>



  <title> 程序员说 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?980738dc41a50d91861a17ad4b768a1f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  
<script type="text/javascript">
    //微信二维码点击背景关闭
    $('body').delegate('.-mob-share-weixin-qrcode-bg','click', function(){
         $(".-mob-share-weixin-qrcode-close").trigger("click");
    }); 
</script>


  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">程序员说</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home"></i> <br />
            
            首頁
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive"></i> <br />
            
            歸檔
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags"></i> <br />
            
            標籤
          </a>
        </li>
      

      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 
  <section id="posts" class="posts-expand">
    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/articles/machine-learning-7/" itemprop="url">
                  机器学习笔记七之主成分分析法（PCA）、人脸识别应用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2018-02-27T00:00:00+08:00" content="2018-02-27">
              2018-02-27
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/articles/machine-learning-7/#comments" itemprop="discussionUrl">
                <span class="post-comments-count disqus-comment-count" data-disqus-identifier="/articles/machine-learning-7/" itemprop="commentsCount"></span>
              </a>
            </span>
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>在机器学习的实际使用中，我们都希望有足够多的样本数据，并且有足够的特征来训练我们的模型，所以高维特征数据是经常会用到的，但是高维特征数据同样会带来一些问题：</p>
<ul>
<li>机器学习算法收敛速度下降。</li>
<li>特征难于分辨，很难第一时间认识某个特征代表的意义。</li>
<li>会产生冗余特征，增加模型训练难度，比如说某一品牌型号汽车的特征数据，有从中国采集的，也有从国外采集的，那么就会产生公里/小时和英里/小时这种特征，但其实这两个特征代表的意义是一样的。</li>
<li>无法通过可视化对训练数据进行综合分析。</li>
</ul>
<p>以上问题都是高维特征数据带来的普遍问题，所以将高维特征数据降为低维特征数据就很重要了。这篇笔记主要讲解机器学习中经常用到的降维算法PCA。</p>
<p>PCA是英文Principle Component Analysis的缩写，既主成分分析法。该算法能从冗余特征中提取主要成分，在不太损失模型质量的情况下，提升了模型训练速度。</p>
<h2 id="u7406_u89E3PCA_u7B97_u6CD5_u964D_u7EF4_u7684_u539F_u7406"><a href="#u7406_u89E3PCA_u7B97_u6CD5_u964D_u7EF4_u7684_u539F_u7406" class="headerlink" title="理解PCA算法降维的原理"></a>理解PCA算法降维的原理</h2><p><img src="http://paxigrdp0.bkt.clouddn.com/96db7d87e7af97e05b630366cc02bcf1.jpg" alt=""></p>
<p>我们从二维降一维的场景来理解PCA降维的原理。上面的图示显示了一个二维的特征坐标，横坐标是特征1，纵座标是特征2。图中的五个点就表示了五条特征数据。我们先来想一下最简单粗暴的降维方式就是丢弃掉其中一个特征。</p>
<p><img src="http://paxigrdp0.bkt.clouddn.com/b51d7ec017736d4f47fb7e836c33f074.jpg" alt=""></p>
<p>如上图中显示，将特征2抛弃，这里大家先注意一下这五个点落在特征1轴上的间距。</p>
<p><img src="http://paxigrdp0.bkt.clouddn.com/aa709dfbb796ada2b6b6dae9d0d43d64.jpg" alt=""></p>
<p>或者如上图所示抛弃特征1，大家再注意一下这五个点落在特征2轴上的间距。能很明显的发现，抛弃特征2，落在特征1轴上的五个点之间间距比较大，并且分布均匀。而抛弃特征1，落在特征2轴上的五个点之间间距大多都比较小，并且分布不均匀。</p>
<p>就这两种简单粗暴的降维方式而言，哪种更好一些呢？这里我们先来看看方差的概念，方差描述的是随机数据的离散程度，也就是离期望值（不严谨的说，期望值等同于均值）的距离。所以方差越大，数据的离散程度越高，约分散，离均值的距离越大。方差越小，数据的离散程度越小，约聚合，离均值的距离约小。那么大家可以想想作为机器学习算法训练的样本数据，每组特征应该尽可能的全，在该特征的合理范围内尽可能的广，这样才能更高的代表真实性，也就是每组特征数据的方差应该尽可能的大才好。所以就上面两种情况来看，抛弃特征2的降维方式更好一些。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/articles/machine-learning-7/#more" rel="contents">
              閱讀全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/articles/machine-learning-6/" itemprop="url">
                  机器学习笔记六之梯度下降、优化梯度公式、随机梯度下降
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2018-02-15T00:00:00+08:00" content="2018-02-15">
              2018-02-15
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/articles/machine-learning-6/#comments" itemprop="discussionUrl">
                <span class="post-comments-count disqus-comment-count" data-disqus-identifier="/articles/machine-learning-6/" itemprop="commentsCount"></span>
              </a>
            </span>
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这篇笔记主要介绍梯度下降法，梯度下降不是机器学习专属的算法，它是一种基于搜索的最优化方法，也就是通过不断的搜索然后找到损失函数的最小值。像上篇笔记中使用正规方程解实现多元线性回归，基于$X_b\theta$这个模型我们可以推导出$\theta$的数学解，但是很多模型是推导不出数学解的，所以就需要梯度下降法来搜索出最优解。</p>
<h2 id="u68AF_u5EA6_u4E0B_u964D_u6CD5_u6982_u5FF5"><a href="#u68AF_u5EA6_u4E0B_u964D_u6CD5_u6982_u5FF5" class="headerlink" title="梯度下降法概念"></a>梯度下降法概念</h2><p>我们来看看在二维坐标里的一个曲线方程：</p>
<p><img src="http://paxigrdp0.bkt.clouddn.com/8b3433626c22d7f31a236492458a58e0.jpg" alt=""></p>
<p>纵坐标表示损失函数L的值，横坐标表示系数$\theta$。每一个$\theta$的值都会对应一个损失函数L的值，我们希望损失函数收敛，既找到一个$\theta$的值，使损失函数L的值最小。</p>
<p><img src="http://paxigrdp0.bkt.clouddn.com/7d33b5dbd153029338804e42063e7dae.jpg" alt=""></p>
<p>在曲线上定义一点A，对应一个$\theta$值，一个损失函数L的值，要判断点A是否是损失函数L的最小值，既求该点的导数，在第一篇笔记中我解释过，点A的导数就是直线M的斜率，直线M是点A的切线，所以导数描述了一个函数在某一点附近的变化率，并且导数大于零时，函数在区间内单调递增，导数小于零时函数在区间内单调递减。所以$\frac {d L}{d \theta}$表示损失函数L增大的变化率，$-\frac {d L}{d \theta}$表示损失函数L减小的变化率。</p>
<p><img src="http://paxigrdp0.bkt.clouddn.com/79181d4455f5a40c4a652a41a743bc7b.jpg" alt=""></p>
<p>再在曲线上定义一点B，在点A的下方，B点的$\theta$值就是A点的$\theta$值加上让损失函数L递减的变化率$-\eta \frac {d L}{d \theta}$，$\eta$称为步长，既B点在$-\frac {d L}{d \theta}$变化率的基础下移动了多少距离，在机器学习中$\eta$这个值也称为学习率。</p>
<p><img src="http://paxigrdp0.bkt.clouddn.com/12d864def3bdafa3f3ecda683f2950e4.jpg" alt=""></p>
<p>同理还可以再求得点C，然后看是否是损失函数的L的最小值。所以梯度下降法就是基于损失函数在某一点的变化率$-\frac {d L}{d \theta}$，以及寻找下一个点的步长$\eta$，不停的找到下一个点，然后判断该点处的损失函数值是否为最小值的过程。$-\eta \frac {d L}{d \theta}$就称为梯度。</p>
<p>在第一篇笔记中将极值的时候提到过，当曲线或者曲面很复杂时，会有多个驻点，既局部极值，所以如果运行一次梯度下降法寻找损失函数极值的话很有可能找到的只是局部极小值点。所以在实际运用中我们需要多次运行算法，随机化初始点，然后进行比较找到真正的全局极小值点，所以初始点的位置是梯度下降法的一个超参数。</p>
<p>不过在线性回归的场景中，我们的损失函数$\sum_{i=1}^m(y^{(i)}-\hat y^{(i)})^2$是有唯一极小值的，所以暂时不需要多次执行算法搜寻全局极值。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/articles/machine-learning-6/#more" rel="contents">
              閱讀全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/articles/machine-learning-5/" itemprop="url">
                  机器学习笔记五之线性回归、评测标准、多元线性回归
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2018-02-05T00:00:00+08:00" content="2018-02-05">
              2018-02-05
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/articles/machine-learning-5/#comments" itemprop="discussionUrl">
                <span class="post-comments-count disqus-comment-count" data-disqus-identifier="/articles/machine-learning-5/" itemprop="commentsCount"></span>
              </a>
            </span>
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这篇笔记主要介绍线性回归算法，对在第一篇笔记中介绍过的线性回归算法进行实现。kNN算法主要解决的是分类问题，并且它的结果不具备良好的解释性。线性回归算法主要解决回归问题，它的结果具有良好的可解释性，和kNN算法的介绍过程一样，线性回归算法也蕴含了机器学习中很多重要的思想，并且它是许多强大的非线性模型的基础。</p>
<h2 id="u7B80_u5355_u7EBF_u6027_u56DE_u5F52"><a href="#u7B80_u5355_u7EBF_u6027_u56DE_u5F52" class="headerlink" title="简单线性回归"></a>简单线性回归</h2><p>在第一篇笔记中，我们举过房屋面积大小和价格例子，将其绘制在二维坐标图上，横轴表示房屋面积，纵轴表示房屋价格，这里样本特征数据只有一个，那就是房屋面积，而在kNN算法的分类问题中，二维坐标图上横纵轴表示的都是样本特征数据，这是一个比较明显的区别。如果线性回归问题要在图中表示两种样本特征数据的话就需要三维空间坐标来表示。我们一般将只有一种样本特征数据的线性回归问题称为简单线性回归问题。</p>
<h3 id="u56DE_u987E_u7EBF_u6027_u56DE_u5F52"><a href="#u56DE_u987E_u7EBF_u6027_u56DE_u5F52" class="headerlink" title="回顾线性回归"></a>回顾线性回归</h3><p>线性回归其实就是寻找一条直线，最大程度的拟合样本特征和样本输出标记之间的关系。</p>
<p><img src="http://paxigrdp0.bkt.clouddn.com/a9e2a5cbcffbf0037e8bf53f49cc414e.jpg" alt=""></p>
<p>我们来看上面这张图，大家知道直线的方程是$y=ax+b$，那么点A肯定是在一条直线上，该条直线方程为$y^{(i)}=ax^{(i)}+b$，那么点A的横轴值为$x^{(i)}$，既是A的样本特征值，纵轴值为$y^{(i)}$，既是A的样本输出值。我们假设图中的红线就是拟合直线，方程为$\hat y^{(i)}=ax^{(i)}+b$，也就是将$x^{(i)}$代入这条红线，会得到一个预测的纵轴值$\hat y^{(i)}$。我们希望真值$y^{(i)}$和预测值$\hat y^{(i)}$的差值越小，说明我们的拟合直线拟合的越好。</p>
<p>因为差值有正有负，为了保证都是正数，所以将差值进行平方，之所以不用绝对值，是为了方便求导数。</p>
<blockquote>
<p>方程求导的知识可参阅<a href="http://www.devtalking.com/articles/machine-learning-1/"> 《机器学习笔记一之机器学习定义、导数、最小二乘》 </a>。</p>
</blockquote>
<p>$$ (y^{(i)} - \hat y^{(i)})^2 $$</p>
<p>将所有样本特征都考虑到，既将所有真值和预测值的差值求和：</p>
<p>$$ \sum_{i=1}^m(y^{(i)} - \hat y^{(i)})^2 $$</p>
<p>将$ax^{(i)}+b$代入上面的公式就得到：</p>
<p>$$\sum_{i=1}^m(y^{(i)} - ax^{(i)}-b)^2$$</p>
<p>上面的公式我们称为损失函数（Loss Function），损失函数值越小，我们的拟合直线越好。在Loss函数中，$a$和$b$是变量，所以我们要做的就是找到使Loss函数值最小的$a$和$b$。这个套路是近乎所有参数学习算法常用的套路，既通过分析问题，确定问题的损失函数，通过最优化损失函数获得机器学习的模型。像线性回归、多项式回归、逻辑回归、SVM、神经网络等都是这个套路。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/articles/machine-learning-5/#more" rel="contents">
              閱讀全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/articles/machine-learning-4/" itemprop="url">
                  机器学习笔记四之kNN算法、超参数、数据归一化
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2018-01-27T00:00:00+08:00" content="2018-01-27">
              2018-01-27
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/articles/machine-learning-4/#comments" itemprop="discussionUrl">
                <span class="post-comments-count disqus-comment-count" data-disqus-identifier="/articles/machine-learning-4/" itemprop="commentsCount"></span>
              </a>
            </span>
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>上一篇笔记主要介绍了NumPy，Matplotlib和Scikit Learn中Datasets三个库的用法，以及基于欧拉定理的kNN算法的基本实现。这一篇笔记的主要内容是通过PyCharm封装kNN算法并且在Jupyter Notebook中调用，以及计算器算法的封装规范，kNN的<code>k</code>值如何计算，如何使用Scikit Learn中的kNN算法，还有机器学习算法中的一些主要概念，比如训练数据集、测试数据集，分类准确度，超参数，数据归一化。另外会具体用代码实现第一篇笔记中介绍过的线性回归算法。</p>
<h2 id="u5C01_u88C5kNN_u7B97_u6CD5"><a href="#u5C01_u88C5kNN_u7B97_u6CD5" class="headerlink" title="封装kNN算法"></a>封装kNN算法</h2><p>上一篇笔记中我们对kNN算法在Jupyter Notebook中进行了实现，但是想要复用这个算法就很不方便，所以我们来看看如何在PyCharm中封装算法，并且在Jupyter Notebook中进行调用。</p>
<p>PyCharm的配置这里我就不再累赘，如图所示，我们创建了一个Python文件<code>kNN.py</code>，然后定义了<code>kNNClassify</code>方法，该方法有4个参数，分别是kNN算法的<code>k</code>值，训练样本特征数据集<code>XTrain</code>，训练样本类别数据集<code>yTrain</code>，预测特征数据集<code>x</code>。该方法中的实现和在Jupyter Notebook中实现的一模一样，只不过加了三个断言，让方法的健壮性更好一点。我们给出<strong>N维欧拉定理</strong>：</p>
<p>$$ \sqrt {\sum_{i=1}^n(x_i^{(a)}-x_i^{(b)})^2} $$</p>
<p><img src="http://paxigrdp0.bkt.clouddn.com/574075757e0d0a820e2a8a7ef37f79ec.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kNN.py</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kNNClassify</span><span class="params">(k, XTrain, yTrain, x)</span>:</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">assert</span> <span class="number">1</span> &lt;= k &lt;= XTrain.shape[<span class="number">0</span>], <span class="string">"k 的取值范围不正确"</span></span><br><span class="line">	<span class="keyword">assert</span> XTrain.shape[<span class="number">0</span>] == yTrain.shape[<span class="number">0</span>], <span class="string">"训练样本数据行数应该与训练结果集行数相同"</span></span><br><span class="line">	<span class="keyword">assert</span> XTrain.shape[<span class="number">1</span>] == x.shape[<span class="number">0</span>], <span class="string">"训练样本数据特性个数应该与被预测数据特性个数相同"</span></span><br><span class="line"></span><br><span class="line">	distances = [sqrt(np.sum((xTrain - x) ** <span class="number">2</span>)) <span class="keyword">for</span> xTrain <span class="keyword">in</span> XTrain]</span><br><span class="line">	nearest = np.argsort(distances)</span><br><span class="line"></span><br><span class="line">	topKy = [yTrain[i] <span class="keyword">for</span> i <span class="keyword">in</span> nearest[:k]]</span><br><span class="line">	votes = Counter(topKy)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> votes.most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>这样我们就在PyCharm中封装好了kNN算法的方法，我们再来看看如何在Jupyter Notebook中调用封装好的方法呢，这就需要使用<code>%run</code>这个命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">raw_data_X = [[<span class="number">3.393533211</span>, <span class="number">2.331273381</span>],</span><br><span class="line">			  [<span class="number">3.110073483</span>, <span class="number">1.781539638</span>],</span><br><span class="line">			  [<span class="number">1.343808831</span>, <span class="number">3.368360954</span>],</span><br><span class="line">			  [<span class="number">3.582294042</span>, <span class="number">4.679179110</span>],</span><br><span class="line">			  [<span class="number">2.280362439</span>, <span class="number">2.866990263</span>],</span><br><span class="line">			  [<span class="number">7.423436942</span>, <span class="number">4.696522875</span>],</span><br><span class="line">			  [<span class="number">5.745051997</span>, <span class="number">3.533989803</span>],</span><br><span class="line">			  [<span class="number">9.172168622</span>, <span class="number">2.511101045</span>],</span><br><span class="line">			  [<span class="number">7.792783481</span>, <span class="number">3.424088941</span>],</span><br><span class="line">			  [<span class="number">7.939820817</span>, <span class="number">0.791637231</span>]</span><br><span class="line">			 ]</span><br><span class="line">raw_data_y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">XTrain = np.array(raw_data_X)</span><br><span class="line">yTrain = np.array(raw_data_y)</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">8.093607318</span>, <span class="number">3.365731514</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用%run命令可以引入Python文件，并可使用该Python文件中定义的属性和方法</span></span><br><span class="line">%run ../pycharm/kNN.py</span><br><span class="line">predicty = kNNClassify(<span class="number">6</span>, XTrain, yTrain, x)</span><br><span class="line">predicty</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
          <div class="post-more-link text-center">
            <a class="btn" href="/articles/machine-learning-4/#more" rel="contents">
              閱讀全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                <a class="post-title-link" href="/articles/machine-learning-3/" itemprop="url">
                  机器学习笔记三之NumPy、Matplotlib、kNN算法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2018-01-20T00:00:00+08:00" content="2018-01-20">
              2018-01-20
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/articles/machine-learning-3/#comments" itemprop="discussionUrl">
                <span class="post-comments-count disqus-comment-count" data-disqus-identifier="/articles/machine-learning-3/" itemprop="commentsCount"></span>
              </a>
            </span>
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="NumPy"><a href="#NumPy" class="headerlink" title="NumPy"></a>NumPy</h2><p>NumPy是Python中的一个类库，它支持高阶维度数组（矩阵）的创建及各种操作、运算，是我们在机器学习中经常会使用的一个类库。这一节再看一些NumPy的矩阵用法。</p>
<h3 id="numpy-random"><a href="#numpy-random" class="headerlink" title="numpy.random"></a>numpy.random</h3><p>NumPy也提供了生成随机数和随机元素数组的方法，我们来看一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成从0到10之间的随机数</span></span><br><span class="line">np.random.randint(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成元素从0到10，一共4个随机元素的数组</span></span><br><span class="line">np.random.randint(<span class="number">0</span>, <span class="number">10</span>, size=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">array([<span class="number">4</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成元素随机从0到10，3行5列的矩阵</span></span><br><span class="line">np.random.randint(<span class="number">0</span>, <span class="number">10</span>, size=(<span class="number">3</span>, <span class="number">5</span>))</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">array([[<span class="number">6</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">9</span>],</span><br><span class="line">	   [<span class="number">7</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">	   [<span class="number">4</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">2</span>]])</span><br></pre></td></tr></table></figure>
<p>如果我们希望每次使用随机方法生成的结果都是一样的，一般调试时候有这个需求，此时NumPy的<code>random()</code>方法也提供了方便简单的方式，既随机种子的概念：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成随机矩阵前给定一个种子</span></span><br><span class="line">np.random.seed(<span class="number">123</span>)</span><br><span class="line"><span class="comment"># 然后生成随机矩阵</span></span><br><span class="line">np.random.randint(<span class="number">0</span>, <span class="number">10</span>, size=(<span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">array([[<span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">	   [<span class="number">9</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">	   [<span class="number">9</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">3</span>],</span><br><span class="line">	   [<span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">1</span>]])</span><br><span class="line">	   </span><br><span class="line"><span class="comment"># 再次生成随机矩阵时，只要传入相同的种子，就可以得到相同结果的矩阵</span></span><br><span class="line">np.random.seed(<span class="number">123</span>)</span><br><span class="line">np.random.randint(<span class="number">0</span>, <span class="number">10</span>, size=(<span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">array([[<span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">	   [<span class="number">9</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">	   [<span class="number">9</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">3</span>],</span><br><span class="line">	   [<span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">1</span>]])</span><br><span class="line">	   </span><br><span class="line"><span class="comment"># 默认范围是从0.0到1.0，返回值为float型</span></span><br><span class="line">np.random.random()</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.18249173045349998</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 传入的参数是数组的大小</span></span><br><span class="line">np.random.random(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">array([ <span class="number">0.17545176</span>,  <span class="number">0.53155137</span>,  <span class="number">0.53182759</span>,  <span class="number">0.63440096</span>,  <span class="number">0.84943179</span>,</span><br><span class="line">		<span class="number">0.72445532</span>,  <span class="number">0.61102351</span>,  <span class="number">0.72244338</span>,  <span class="number">0.32295891</span>,  <span class="number">0.36178866</span>])</span><br><span class="line">		</span><br><span class="line"><span class="comment"># 创建4行5列，元素值的范围从0.0到1.0的矩阵</span></span><br><span class="line">np.random.random((<span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">array([[ <span class="number">0.22826323</span>,  <span class="number">0.29371405</span>,  <span class="number">0.63097612</span>,  <span class="number">0.09210494</span>,  <span class="number">0.43370117</span>],</span><br><span class="line">	   [ <span class="number">0.43086276</span>,  <span class="number">0.4936851</span> ,  <span class="number">0.42583029</span>,  <span class="number">0.31226122</span>,  <span class="number">0.42635131</span>],</span><br><span class="line">	   [ <span class="number">0.89338916</span>,  <span class="number">0.94416002</span>,  <span class="number">0.50183668</span>,  <span class="number">0.62395295</span>,  <span class="number">0.1156184</span> ],</span><br><span class="line">	   [ <span class="number">0.31728548</span>,  <span class="number">0.41482621</span>,  <span class="number">0.86630916</span>,  <span class="number">0.25045537</span>,  <span class="number">0.48303426</span>]])</span><br></pre></td></tr></table></figure>
<h3 id="u6307_u5B9A_u5747_u503C_u548C_u6807_u51C6_u5DEE_u751F_u6210_u968F_u673A_u6570_u6570_u7EC4_u6216_u77E9_u9635"><a href="#u6307_u5B9A_u5747_u503C_u548C_u6807_u51C6_u5DEE_u751F_u6210_u968F_u673A_u6570_u6570_u7EC4_u6216_u77E9_u9635" class="headerlink" title="指定均值和标准差生成随机数数组或矩阵"></a>指定均值和标准差生成随机数数组或矩阵</h3><p>我们先来看看均值、方差、标准差的概念。均值很好理解，就是所有样本数据的平均值，描述了样本集合的中间点：</p>
<p>$$ \overline X=\frac{\sum_{i=1}^nX_i}n $$</p>
<p>方差是衡量样本点和样本期望值相差的度量值：</p>
<p>$$ S^2 = \frac{\sum_{i=1}^n(X_i-\overline X)^2} n $$</p>
<p>标准差描述的是样本集合的各个样本点到均值的距离之平均：</p>
<p>$$ S = \sqrt {\frac{\sum_{i=1}^n(X_i-\overline X)^2} n } $$</p>
<p>标准差也就是对方差开根号。举个例子，<code>[0, 8, 12, 20]</code>和<code>[8, 9, 11, 12]</code>，两个集合的均值都是10，但显然两个集合的差别是很大的，计算两者的标准差，前者是8.3后者是1.8，显然后者较为集中，标准差描述的就是这种散布度或者叫做波动大小。综上，方差的意义在于描述随机变量稳定与波动、集中与分散的状况。标准差则体现随机变量取值与其期望值的偏差。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/articles/machine-learning-3/#more" rel="contents">
              閱讀全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>


 </div>

        

        
      </div>

      
        
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="http://www.devtalking.com/devtalking.png" alt="DevTalking" itemprop="image"/>
          <p class="site-author-name" itemprop="name">DevTalking</p>
        </div>
        <p class="site-description motion-element" itemprop="description"></p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">90</span>
              <span class="site-state-item-name">文章</span>
            </a>
          </div>

         <!-- <div class="site-state-item site-state-categories">
            
              <span class="site-state-item-count">0</span>
              <span class="site-state-item-name">分類</span>
              
          </div> -->

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">44</span>
              <span class="site-state-item-name">標籤</span>
              </a>
          </div>

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="menu-item-icon icon-next-feed"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/宇轩-付-5aa406a6" target="_blank">
                  
                    <i class="fa fa-linkedin"></i> linkedin
                  
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:jace.fu@icloud.com" target="_blank">
                  
                    <i class="fa fa-envelope"></i> Email
                  
                </a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


      
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy;  2014 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="icon-next-heart fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DevTalking</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 強力驅動
</div>

<div class="theme-info">
  主題 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT
  </a>
</div>


 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  
  
    
    

  

    <script type="text/javascript">
      var disqus_shortname = 'jacefu';
      var disqus_identifier = 'page/2/index.html';
      var disqus_title = '';
      var disqus_url = '';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
    </script>
  


  
  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.2"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.2"></script>
  

  <script type="text/javascript" src="/lib/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.2" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.2"></script>
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  

  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }

      motionIntegrator.bootstrap();
    });
  </script>

  
  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
</body>
</html>
