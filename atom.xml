<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[程序员说]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://www.devtalking.com/"/>
  <updated>2021-10-10T17:38:11.558Z</updated>
  <id>http://www.devtalking.com/</id>
  
  <author>
    <name><![CDATA[DevTalking]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[用Blender做甜甜圈学习笔记四 - 完善糖衣白模]]></title>
    <link href="http://www.devtalking.com//articles/blender-beginner-tutorial-4/"/>
    <id>http://www.devtalking.com//articles/blender-beginner-tutorial-4/</id>
    <published>2021-10-10T16:00:00.000Z</published>
    <updated>2021-10-10T17:38:11.558Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>目前甜甜圈的糖衣已经捏出了大体的样子，我们先来看看真正的甜甜圈上的糖衣是什么样的。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/0F19F4AB-2F35-4F6C-BD0F-51462A4936A2_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>可以看到在烘培甜甜圈时，糖衣是会沿着甜甜圈流淌下去的，所以这个细节是需要我们刻画出来的。</p>
<h2 id="u5B8C_u5584_u7CD6_u8863"><a href="#u5B8C_u5584_u7CD6_u8863" class="headerlink" title="完善糖衣"></a>完善糖衣</h2><p>选中糖衣，进入编辑模式，先取消Solidify修改器的效果。</p>
<a id="more"></a>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/2004A9EB-5362-4C37-A272-1CD42BC7DB44_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>选中某个点，按下<code>A</code>键，即可选中该对象所有的点，<code>Alt + A</code>或<code>Option + A</code>是取消所有点的选中。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/F9BE48B6-D552-41AB-8B22-F4BDDB052F20_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>点击鼠标右键，在弹出菜单中选择<code>Subdivide（细分）</code>。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/ADD90286-EE93-46A1-B2CC-29A1783978DC_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>对糖衣细分后，会发现拓扑结构变密了，也就是四边形的数量更多了，每细分一次，四边形数量多一倍。也就以为着我们可以捏出更多细节，因为点、线、面都变多了。另外在左下角弹出的细分设置中那个，我们也可以手动再增加细分，以及可以调整平滑度。这里我们只细分一次就足够了，然后将平滑度设置为1。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/F9CAF07C-F9E9-4BBC-97DE-A33E2098C78E_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>接下来有三个小技巧：</p>
<ul>
<li>如果我们想选中某一纬度或经度上的所有点，可以按下<code>Alt</code>点击你想全选的那条纬度或经度。</li>
</ul>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/079E8884-5E97-41F8-A98D-E39684C686AB_2/%201.jpeg" alt="切片 1.jpeg"></p>
<ul>
<li><code>Ctrl + I</code>或者<code>Command + I</code>可以反选，既选择其他圈上的所有点。</li>
</ul>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/5F491B43-B6E8-4652-82B4-7BBBDA337B70_2/%201.jpeg" alt="切片 1.jpeg"></p>
<ul>
<li><code>H</code>键可以隐藏所选内容，<code>Alt + H</code>或者<code>Option + H</code>可以显示隐藏的内容。</li>
</ul>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/18CEC86F-C5F0-4782-A938-FBDF916BC8E5_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>这样处理后，我们可以更聚焦在我们需要编辑的部分。</p>
<p>现在我们先把糖衣往下流淌的大概形状捏一下，依然选中<code>Proportional Editing</code>模式，选择某个点，往下移动。此时我们应该会看到有一部分点穿进了甜甜圈的模型，俗称穿模。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/56422D80-E287-4E84-AEF9-211BBDD2D9C2_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>我们更希望在移动点的时候，被移动的点能吸附在甜甜圈的表面上。所以我们可以使用<code>Snap</code>工具，选择吸附到面，并且关联的所有点都吸附到面。</p>
<p>打开<code>Snap</code>，将<code>Snap To</code>选择为<code>Face</code>，然后勾选上<code>Project Individual Elements</code>。然后再对点进行调整。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/FC965384-E18A-488C-A836-829D842E129C_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>调整完之后大概是这个样子。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/CD899E9A-7EA2-4522-B83E-7E74CC100C43_2/%201.jpeg" alt="切片 1.jpeg"></p>
<h2 id="u6324_u51FA_u62D3_u6251"><a href="#u6324_u51FA_u62D3_u6251" class="headerlink" title="挤出拓扑"></a>挤出拓扑</h2><p>接下来需要再完善细节，做几个流的比较低的糖衣流痕，也就是选择某个点往下移动的更低一些，看看会发生什么。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/3ADB4791-6E26-4614-8B25-4DBC09102480_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>分别切换到对象模式和开了透视视图的编辑模式。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/1FF8C958-413F-44DB-8B13-C2E5576BDE12_2/%202.jpeg" alt="切片 2.jpeg"></p>
<p>因为拓扑结构被拉的太长，导致都是糖衣那部分的面和甜甜圈的面接触，所以会导致穿模。解决这个问题的思路是额外增加可以表现糖衣流到底部的拓扑，而不是将原有的拓扑拉长。我们可以通过<code>Extrude（挤出）</code>功能来实现。</p>
<p>选中一个点，按住<code>Ctrl</code>或者<code>Command</code>再点击相邻的另一个点，也就是选中两个点，选择<code>Mesh → Extrude → Extrude Edges</code>，或者快捷键<code>E</code>。往下移动这两个点，就会产生一个新的四边形（拓扑）。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/762D0486-74E8-45FF-828B-76E3F4F23B9D_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/5280E769-2A42-4FE1-A90C-20532F243403_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>我们可以多做几个类似的效果，宽度和长度（既一次选择几个点，往下移动多少距离）可以根据自己喜好调整。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/67ABE26C-67C2-4E04-8F79-2AA3A94F12CE_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>我们仔细观察刚才挤出的糖衣部分，可以看到是有翘起来的感觉，没有和甜甜圈很好的贴合。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/A3B4C3C0-1BA2-4CDF-97B0-4C89011DD3F9_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>解决这个问题，可以调整<code>Solidify修改器</code>中的<code>Edge Data → Crease Inner</code>参数。该参数的作用相当于调整边缘内部折角的角度。将该属性调整为1，既将糖衣边缘内折角的角度调大，就可以和甜甜圈表面贴合起来了。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/0F372D9E-9943-4FED-9100-E1C63329DF00_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>至此，甜甜圈糖衣白模的完善第一步就基本完成了。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/AC6629E5-CB7F-4AA7-A95D-2AEC6A015365_2/%201.jpeg" alt="切片 1.jpeg"></p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>目前甜甜圈的糖衣已经捏出了大体的样子，我们先来看看真正的甜甜圈上的糖衣是什么样的。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/0F19F4AB-2F35-4F6C-BD0F-51462A4936A2_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>可以看到在烘培甜甜圈时，糖衣是会沿着甜甜圈流淌下去的，所以这个细节是需要我们刻画出来的。</p>
<h2 id="u5B8C_u5584_u7CD6_u8863"><a href="#u5B8C_u5584_u7CD6_u8863" class="headerlink" title="完善糖衣"></a>完善糖衣</h2><p>选中糖衣，进入编辑模式，先取消Solidify修改器的效果。</p>]]>
    
    </summary>
    
      <category term="Blender" scheme="http://www.devtalking.com/tags/Blender/"/>
    
      <category term="Blender" scheme="http://www.devtalking.com/categories/Blender/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[用Blender做甜甜圈学习笔记三 - 捏出糖衣白模]]></title>
    <link href="http://www.devtalking.com//articles/blender-beginner-tutorial-3/"/>
    <id>http://www.devtalking.com//articles/blender-beginner-tutorial-3/</id>
    <published>2021-10-06T16:00:00.000Z</published>
    <updated>2021-10-06T17:51:31.703Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>甜甜圈的白模胚子已经有了，然后我们开始做甜甜圈上面那一层糖衣的制作。基本思路是需要创建一个糖衣的白模，然后摞在甜甜圈白模上面，并且这个糖衣的白模需要有以下三个特点：</p>
<ul>
<li>甜甜圈的糖衣一般只覆盖到甜甜圈上部1/3的范围。</li>
<li>糖衣的轮廓和甜甜圈上半部分完全一致。</li>
<li>糖衣需要一点点厚度，能看出来是甜甜圈上面覆盖了一层东西。</li>
</ul>
<p>我们依照上面三个思路来进行制作。</p>
<a id="more"></a>
<h2 id="u5236_u4F5C_u7CD6_u8863_u767D_u6A21"><a href="#u5236_u4F5C_u7CD6_u8863_u767D_u6A21" class="headerlink" title="制作糖衣白模"></a>制作糖衣白模</h2><p>要想让糖衣的轮廓和甜甜圈完全一致，最好的做法就是复制甜甜圈上部1/3的部分。进入编辑模式，将视角切换到正前视图，然后用鼠标框选甜甜圈的上部1/3位置。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/8364E6AF-E901-4021-BA76-4BDD94CA668F_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>框选完之后，我们会发现，并没有按我们设想的那样把上部1/3的点和线都选中，而是只选中的一部分。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/5498A94F-1B93-418E-9C6B-2518D6919833_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>如果想要实现我们的设想，需要打开透视模式。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/E6F43932-1273-4943-A610-3E72FD9C728F_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>然后再切换到正前方的视角，重新框选上部1/3位置，这时就可以将上部1/3的点和线全部选中了。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/2B4D56FF-D32D-449D-B92A-85387363ACD5_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>然后按下<code>Shift + D</code>复制选中的内容，再按下<code>P</code>键，会弹出分离选择框，选择<code>Selection</code>，意思是将复制的内容和被复制的物体分离。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/8B1B6395-564A-4916-A324-634BA3B6A579_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>此时可以在集合中看到又出现了一个对象，说明现在整个场景中，一共有四个对象，分别是：</p>
<ul>
<li>摄像机（先不用管）</li>
<li>灯光（先不用管）</li>
<li>甜甜圈</li>
<li>糖衣</li>
</ul>
<blockquote>
<p>可以根据喜好，修改对象的名称，以便能更好的区分不同的对象。</p>
</blockquote>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/221F9BB0-03ED-4CFE-AA3E-A6F144E57D62_2/%202.jpeg" alt="切片 2.jpeg"></p>
<p>现在关闭透视模式，切换到对象模式，能够更清晰的看到糖衣的白模。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/047ABFD2-6C98-41D7-9A16-06521B2E2925_2/%201.jpeg" alt="切片 1.jpeg"></p>
<h2 id="u4F7F_u7528_u5B9E_u4F53_u5316_u4FEE_u6539_u5668_u5B8C_u5584_u7CD6_u8863"><a href="#u4F7F_u7528_u5B9E_u4F53_u5316_u4FEE_u6539_u5668_u5B8C_u5584_u7CD6_u8863" class="headerlink" title="使用实体化修改器完善糖衣"></a>使用实体化修改器完善糖衣</h2><p>我们将视图放大，可以看到目前的糖衣的边缘和甜甜圈并没有贴合，而且比较薄。而实际的情况糖衣应该是有一定厚度，并且是和甜甜圈贴合在一起的。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/2F021AFD-DF76-4B6A-8F46-AE3AFDBF40BD_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>解决这个问题，我们可以给糖衣添加一个<code>Solidify</code>修改器，这个修改器的作用可以调整模型的厚度。添加了<code>Solidify</code>修改器后，将Offset设置为1，然后将厚度（Thickness）设置为0.002m，这个可以根据个人喜好自行设置。然后就可以看到糖衣白模的变化，并且更加贴近真实。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/2DC7F47B-5CE0-4A00-A444-1A754B94B26F_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>此时我们选中糖衣，可以看到它的边缘轮廓不是很圆滑，有比较硬的角。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/BF8C4CA3-D338-4915-8879-BD9171289C37_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>我们可以通过调整修改器的顺序来解决这个问题，我们将<code>Subdivision</code>修改器调整到下面。因为修改器是从上到下的执行，如果<code>Solidify</code>修改器在下面，会覆盖掉<code>Subdivision</code>修改器。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/F5A49778-A521-4C11-A933-995CC0768ED5_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>将<code>Subdivision</code>修改器调整到最下面后，可以看到糖衣的轮廓就没有之前的硬角了。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/C2ACDB08-7DA9-4A9F-9B36-3CC338A29D1E_2/%201.jpeg" alt="切片 1.jpeg"></p>
<p>至此，糖衣的白模就基本完成了。</p>
<p><img src="https://res.craft.do/user/full/bfe2c8cd-7442-8ae7-5cb6-aebba1dc2b37/doc/2100B122-9D5B-476E-BDCA-1E41AFD7C342/A0E7A8E0-605F-489D-A220-AD107395CA7A_2/%201.jpeg" alt="切片 1.jpeg"></p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>甜甜圈的白模胚子已经有了，然后我们开始做甜甜圈上面那一层糖衣的制作。基本思路是需要创建一个糖衣的白模，然后摞在甜甜圈白模上面，并且这个糖衣的白模需要有以下三个特点：</p>
<ul>
<li>甜甜圈的糖衣一般只覆盖到甜甜圈上部1/3的范围。</li>
<li>糖衣的轮廓和甜甜圈上半部分完全一致。</li>
<li>糖衣需要一点点厚度，能看出来是甜甜圈上面覆盖了一层东西。</li>
</ul>
<p>我们依照上面三个思路来进行制作。</p>]]>
    
    </summary>
    
      <category term="Blender" scheme="http://www.devtalking.com/tags/Blender/"/>
    
      <category term="Blender" scheme="http://www.devtalking.com/categories/Blender/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[用Blender做甜甜圈学习笔记二 - 捏出白模胚子]]></title>
    <link href="http://www.devtalking.com//articles/blender-beginner-tutorial-2/"/>
    <id>http://www.devtalking.com//articles/blender-beginner-tutorial-2/</id>
    <published>2021-10-05T16:00:00.000Z</published>
    <updated>2021-10-11T12:18:42.510Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>我们删除了正方体，添加了一个圆环，添加圆环后，左下角会出现该物体的各项属性，可以进行调整：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-1.jpeg" alt="切片 1.jpeg"></p>
<h2 id="u7269_u4F53_u5C5E_u6027"><a href="#u7269_u4F53_u5C5E_u6027" class="headerlink" title="物体属性"></a>物体属性</h2><p>先看Major Radius，它表示我们添加的物体的大小，Blender的默认单位是米，这里看到添加的圆环大小是1米，可以将它调整到一个甜甜圈的实际大小，可以直接5cm，Blender会自动换算单位。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-2.jpeg" alt="切片 1.jpeg"></p>
<p>从场景中的网格大小也可以对比出物体大小和视角远近的变化。如果想修改单位，可以在右侧的场景属性中进行设置。</p>
<a id="more"></a>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-3.png" alt="切片 1@2x.png"></p>
<hr>
<p>物体整体的大小调整后，物体形状会变形，再通过Minor Radius调整整体的形状。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-4.jpeg" alt="切片 1.jpeg"></p>
<p>目前看到的圆环表面还是有很明显的棱角，整体看上去整个圆环是有若干个四边形组成的，可以通过调整Major Segments和Minor Segments调整横向和纵向的四边形的个数，个数越多，每个四边形面积越小，圆环表面整体看上去越光滑。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-5.jpeg" alt="切片 1@2x.jpeg"></p>
<h2 id="u7F16_u8F91_u6A21_u5F0F"><a href="#u7F16_u8F91_u6A21_u5F0F" class="headerlink" title="编辑模式"></a>编辑模式</h2><p>甜甜圈不可能是一个完全周正的圆环，所以我们需要将圆环的形状调整的更加真实一些，在视图左上角有切换模式的下拉菜单，当需要对物体进行编辑时，可以进入编辑模式（Edit Mode），或者可以使用快捷键<code>Tab</code>快速切换。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-6.jpeg" alt="切片 1@2x.jpeg"></p>
<p>进入编辑模式后，可以看到物体的拓扑结构，可以对点、线、面进行调整。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-7.jpeg" alt="切片 1.jpeg"></p>
<p>我们选中某个点，然后按下<code>G</code>移动选中的点，可以看到该点周围的拓扑结构会发生变化，和该点相邻的四个面会被拉伸，从而圆环表面会出现一个尖角。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-8.jpeg" alt="切片 1.jpeg"></p>
<p>这种调整显然不符合我们的预期，我们希望在调整某个点时，和该点相邻的点能一起自适应的调整，这样才能调整出甜甜圈上的一些小坑洼、凹陷，以及圆环的长宽。那么我们需要用到按比例编辑的功能。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-9.jpeg" alt="切片 1.jpeg"></p>
<p>选中<code>Proportional Editing</code>模式后，再选中某个点，按下G，会出现一个圆圈，滑动鼠标中键可以调整圆圈的大小。</p>
<blockquote>
<p>如果没有看到圆圈，请滑动鼠标中键缩放，有可能是圆圈过大，超出了屏幕。</p>
</blockquote>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-10.jpeg" alt="切片 1.jpeg"></p>
<p>该圆圈就是用来圈定与选中的点一起联动的点的范围。选中同样的点向上移动，不同的联动范围有不同的表现。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-11.jpeg" alt="切片 1.jpeg"></p>
<p>现在我们可以使用<code>Proportional Editing</code>模式对圆环进行微调，将表面调整的不那么光滑，有一些坑洼，将圆环也调整的不那么周正，从而更像一个真实的甜甜圈的样子。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-12.jpeg" alt="切片 1.jpeg"></p>
<h2 id="u4FEE_u6539_u5668"><a href="#u4FEE_u6539_u5668" class="headerlink" title="修改器"></a>修改器</h2><p>按下<code>Tab键</code>，切换到物体模式，选中圆环，点击<code>鼠标左键</code>，在弹出的菜单中选择<code>Shade Smooth</code>，让Blender自动对理物体表面进行光滑处理。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-13.jpeg" alt="切片 1.jpeg"></p>
<p>此时我们可以看到圆环的表面已经没有四边形的面了，取而代之的是光滑的表面，但是当我们把视图调整到正左、正右或者前后时，可以看到圆环的轮廓并不是光滑的，依然有棱角。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-14.jpeg" alt="切片 1.jpeg"></p>
<p>要解决这个问题，我们需要用到Blender的修改器。可以简单的理解为，我们可以给一个选中的物体添加多种效果从而改变该物体各个表象。选中物体，在右侧属性面板中可以找到一个扳手形状的菜单，这就是添加修改器的地方。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-15.jpeg" alt="切片 1.jpeg"></p>
<p>点击Add Modifier，可以看到有很多种修改器，我们选择<code>Subdivision Surface（细分表面）</code>修改器。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-16.jpeg" alt="切片 1.jpeg"></p>
<p>我们可以将细分值调整为2，此时可以看到圆环的轮廓也变的光滑了。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-17.jpeg" alt="切片 1.jpeg"></p>
<p>到目前为止，一个甜甜圈的白模胚子的基本雏形就完成了。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-18.jpeg" alt="切片 1.jpeg"></p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>我们删除了正方体，添加了一个圆环，添加圆环后，左下角会出现该物体的各项属性，可以进行调整：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-1.jpeg" alt="切片 1.jpeg"></p>
<h2 id="u7269_u4F53_u5C5E_u6027"><a href="#u7269_u4F53_u5C5E_u6027" class="headerlink" title="物体属性"></a>物体属性</h2><p>先看Major Radius，它表示我们添加的物体的大小，Blender的默认单位是米，这里看到添加的圆环大小是1米，可以将它调整到一个甜甜圈的实际大小，可以直接5cm，Blender会自动换算单位。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-2/2-2.jpeg" alt="切片 1.jpeg"></p>
<p>从场景中的网格大小也可以对比出物体大小和视角远近的变化。如果想修改单位，可以在右侧的场景属性中进行设置。</p>]]>
    
    </summary>
    
      <category term="Blender" scheme="http://www.devtalking.com/tags/Blender/"/>
    
      <category term="Blender" scheme="http://www.devtalking.com/categories/Blender/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[用Blender做甜甜圈学习笔记一 - 基本操作]]></title>
    <link href="http://www.devtalking.com//articles/blender-beginner-tutorial-1/"/>
    <id>http://www.devtalking.com//articles/blender-beginner-tutorial-1/</id>
    <published>2021-10-03T16:00:00.000Z</published>
    <updated>2021-10-11T11:49:42.609Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<h2 id="Blender_u57FA_u672C_u64CD_u4F5C"><a href="#Blender_u57FA_u672C_u64CD_u4F5C" class="headerlink" title="Blender基本操作"></a>Blender基本操作</h2><h3 id="u548C_u573A_u666F_u76F8_u5173_u7684_u57FA_u672C_u64CD_u4F5C"><a href="#u548C_u573A_u666F_u76F8_u5173_u7684_u57FA_u672C_u64CD_u4F5C" class="headerlink" title="和场景相关的基本操作"></a>和场景相关的基本操作</h3><ul>
<li>按住<code>鼠标中键</code>，可以基于原点旋转场景。</li>
<li>按住<code>Shift+鼠标中键</code>，移动场景。</li>
<li>按下```，出现8个选项的轮盘，鼠标快速移到对应的方位即可触发效果。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-1/Image1-1.png" alt="Image.png"></p>
<p>   这8个选项分别是：</p>
<ul>
<li>Top：从上往下看的正交视图。</li>
<li>Bottom：从下往上看的正交视图。</li>
<li>Left：从左往右看的正交视图。</li>
<li>Right：从右往左看的正交视图。</li>
<li>Front：从物体正前方看的视图。</li>
<li>Back：从物体正后方看的视图。</li>
<li>View Camera：开启摄像机视图。</li>
<li>View Selected：将视角拉近选中的物体。</li>
</ul>
<a id="more"></a>
<h3 id="u548C_u7269_u4F53_u76F8_u5173_u7684_u57FA_u672C_u64CD_u4F5C"><a href="#u548C_u7269_u4F53_u76F8_u5173_u7684_u57FA_u672C_u64CD_u4F5C" class="headerlink" title="和物体相关的基本操作"></a>和物体相关的基本操作</h3><ul>
<li>移动，快捷键<code>G</code></li>
<li>旋转，快捷键<code>R</code></li>
<li>变换，快捷键<code>S</code></li>
</ul>
<p>以上三个操作，都可以在按了对应快捷键后，再按下X或Y或Z，然后就可以沿着X轴、Y轴、Z轴进行移动、旋转或变换。或者当按下对应快捷键后，将鼠标移动到X轴、Y轴或Z轴附近，按下鼠标中键，也可以达到同样的效果。</p>
<ul>
<li><code>Shift + D</code>，可以复制选中的物体。</li>
<li><code>X</code>或者<code>Delete</code>键可以删除选中的物体，比如删除初始化的正方体。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-1/Image1-2.png" alt="Image.png"></p>
<ul>
<li><code>Shift + A</code>，可以添加物体，比如添加一个圆环。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-1/%E5%88%87%E7%89%87%201%402x1-3.jpeg" alt="切片 1@2x.jpeg"></p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<h2 id="Blender_u57FA_u672C_u64CD_u4F5C"><a href="#Blender_u57FA_u672C_u64CD_u4F5C" class="headerlink" title="Blender基本操作"></a>Blender基本操作</h2><h3 id="u548C_u573A_u666F_u76F8_u5173_u7684_u57FA_u672C_u64CD_u4F5C"><a href="#u548C_u573A_u666F_u76F8_u5173_u7684_u57FA_u672C_u64CD_u4F5C" class="headerlink" title="和场景相关的基本操作"></a>和场景相关的基本操作</h3><ul>
<li>按住<code>鼠标中键</code>，可以基于原点旋转场景。</li>
<li>按住<code>Shift+鼠标中键</code>，移动场景。</li>
<li>按下```，出现8个选项的轮盘，鼠标快速移到对应的方位即可触发效果。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2021/blender/blender-beginner-tutorial-1/Image1-1.png" alt="Image.png"></p>
<p>   这8个选项分别是：</p>
<ul>
<li>Top：从上往下看的正交视图。</li>
<li>Bottom：从下往上看的正交视图。</li>
<li>Left：从左往右看的正交视图。</li>
<li>Right：从右往左看的正交视图。</li>
<li>Front：从物体正前方看的视图。</li>
<li>Back：从物体正后方看的视图。</li>
<li>View Camera：开启摄像机视图。</li>
<li>View Selected：将视角拉近选中的物体。</li>
</ul>]]>
    
    </summary>
    
      <category term="Blender" scheme="http://www.devtalking.com/tags/Blender/"/>
    
      <category term="Blender" scheme="http://www.devtalking.com/categories/Blender/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Serverless在游戏运营行业进行数据采集分析的最佳实践]]></title>
    <link href="http://www.devtalking.com//articles/serverless-game-bigdata/"/>
    <id>http://www.devtalking.com//articles/serverless-game-bigdata/</id>
    <published>2020-06-19T16:00:00.000Z</published>
    <updated>2021-10-05T16:46:43.813Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p>众所周知，游戏行业在当今的互联网行业中算是一棵常青树。在疫情之前的2019年，中国游戏市场营收规模约2884.8亿元，同比增长17.1%。2020年因为疫情，游戏行业更是突飞猛进。玩游戏本就是中国网民最普遍的娱乐方式之一，疫情期间更甚。据不完全统计，截止2019年，中国移动游戏用户规模约6.6亿人，占中国总网民规模8.47亿的77.92%，足以说明，游戏作为一种低门槛、低成本的娱乐手段，已成为大部分人生活中习以为常的一部分。</p>
<p>对于玩家而言，市面上的游戏数量多如牛毛，那么玩家如何能发现和认知到一款游戏，并且持续的玩下去恐怕是所有游戏厂商需要思考的问题。加之2018年游戏版号停发事件，游戏厂商更加珍惜每一个已获得版号的游戏产品，所以这也使得“深度打磨产品质量”和“提高运营精细程度”这两个游戏产业发展方向成为广大游戏厂商的发展思路，无论是新游戏还是老游戏都在努力落实这两点：</p>
<ul>
<li>新游戏：以更充足的推广资源和更完整的游戏内容面向玩家。</li>
<li>老游戏：通过用户行为分析，投入更多的精力和成本，制作更优质的版本内容。</li>
</ul>
<p>这里我们重点来看新游戏。一家游戏企业辛辛苦苦研发三年，等着新游戏发售时一飞冲天。那么问题来了，新游戏如何被广大玩家看到？先来看看游戏行业公司的分类：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled.png" alt=""></p>
<ul>
<li>游戏研发商：研发游戏的公司，生产和制作游戏内容。比如王者荣耀的所有英雄设计、游戏战斗场景、战斗逻辑等等，这些全部由游戏研发公司提供。</li>
<li><p>游戏发行商：游戏发行商的主要工作分三大块：市场工作、运营工作、客服工作。游戏发行商把控游戏命脉，市场工作核心是导入玩家，运营工作核心是将用户价值最大化、赚取更多利益。</p>
<p>  <img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%201.png" alt=""></p>
</li>
<li><p>游戏平台/渠道商：游戏平台和渠道商的核心目的就是曝光游戏，让尽量多的人能发现你的游戏。</p>
</li>
</ul>
<a id="more"></a>
<p>这三种类型的公司做的事情有各自专注在某一块领域的独立公司，也有一家公司把这三种事情全部都做的，但无论那一种，这三者之间的关系是不会变的：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%202.png" alt=""></p>
<p>所以不难理解，要想让更多的玩家看到你的游戏，游戏发行和运营是关键，通俗来讲就是如果你的游戏出现在所有目前大家熟知的平台的广告中，那么最起码游戏的新用户注册数量是很可观的。那么这就引出了一个关键词，买量。</p>
<p>根据数据显示，2019年月均买量手游数达6000+款，而2018年仅为4200款。另一方面，随着抖音、微博等超级APP在游戏买量市场的资源倾斜，也助推手游买量的效果和效率都有所提升，游戏厂商也更愿意使用买量的方式来吸引用户。但需要注意的是，在游戏买量的精准化程度不断提高的同时，买量的成本也在节节攀升，唯有合理配置买量、渠道与整合营销之间的关系，才能将宣发资源发挥到最大的效果。</p>
<p>通俗来讲，买量其实就是在各大主流平台投放广告，广大用户看到游戏广告后，有可能会点击广告，然后进入游戏厂商的宣传页面，同时会采集用户的一些信息，然后游戏厂商对采集到的用户信息进行大数据分析，进行进一步的定向推广。</p>
<h1 id="u6E38_u620F_u8FD0_u8425_u6838_u5FC3_u8BC9_u6C42"><a href="#u6E38_u620F_u8FD0_u8425_u6838_u5FC3_u8BC9_u6C42" class="headerlink" title="游戏运营核心诉求"></a>游戏运营核心诉求</h1><p>游戏厂商花钱买量，换来用户信息以及新用户注册信息是为持续的游戏运营服务的，那么这个场景的核心诉求就是采集用户信息的完整性。比如说，某游戏厂商一天花5000w投放广告，在某平台某时段产生了每秒1w次的广告点击率，那么在这个时段内每一个点击广告的用户信息要完整的被采集到然后入库进行后续分析。这就对数据采集系统有着很高的要求，最核心的一点就是系统暴露接口的环节要能够平稳承载买量期间的不定时的流量脉冲。在买量期间，游戏厂商通常会在多个平台投放广告，每个平台投放广告的时间是不一样的，所以就出现全天不定时的流量脉冲现象。如果这个环节出现问题，那么相当于买量的钱就打水漂了。</p>
<h1 id="u6570_u636E_u91C7_u96C6_u7CFB_u7EDF_u4F20_u7EDF_u67B6_u6784"><a href="#u6570_u636E_u91C7_u96C6_u7CFB_u7EDF_u4F20_u7EDF_u67B6_u6784" class="headerlink" title="数据采集系统传统架构"></a>数据采集系统传统架构</h1><p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%203.png" alt=""></p>
<p>上图是一个相对传统的数据采集系统的架构，最关键的就是暴露HTTP接口回传数据这部分，这部分如果出问题，那么采集数据的链路就断了。但这部分往往会面临两个挑战：</p>
<ul>
<li>当流量脉冲来的时候，这部分是否可以很快的扩容来应对流量冲击。</li>
<li>游戏运营并不是天天都在进行的，是有潮汐特性的，那么这部分的资源利用率如何优化。</li>
</ul>
<p>在传统架构下，通常情况在游戏有运营活动之前，会提前通知运维同学，对这个环节的服务增加节点，但要增加多少其实是无法预估的，只能大概拍一个数字。这就会导致两个问题：</p>
<ul>
<li>流量太大，节点加少了，导致一部分流量的数据没有采集到。</li>
<li>流量没有预期那么大，节点加多了，导致资源浪费。</li>
</ul>
<h1 id="u6570_u636E_u91C7_u96C6_u7CFB_u7EDFServerless_u67B6_u6784"><a href="#u6570_u636E_u91C7_u96C6_u7CFB_u7EDFServerless_u67B6_u6784" class="headerlink" title="数据采集系统Serverless架构"></a>数据采集系统Serverless架构</h1><p>我们可以通过Serverless<a href="https://help.aliyun.com/document_detail/52895.html?spm=5176.10695662.1112509.4.560f3821kjdWJB" target="_blank" rel="external">函数计算</a>（函数计算的基本概念可以参考<a href="http://www.devtalking.com/articles/serverless-online-coding/">这篇文章</a>）来取代传统架构中暴露HTTP回传数据这部分，从而完美的解决传统架构中存在问题，先来看架构图：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%204.png" alt=""></p>
<p>传统架构中的两个问题均可以通过函数计算百毫秒弹性的特性来解决。我们并不需要去估算营销活动会带来多大的流量，也不需要去担心和考虑对数据采集系统的性能，运维同学更不需要提前预备ECS。</p>
<p>因为函数计算的极致弹性特性，当没有买量，没有营销活动的时候，函数计算的运行实例是零。有买量活动时，流量脉冲的情况下，函数计算会快速拉起实例来承载流量压力，当流量减少时函数计算会及时释放没有请求的实例进行缩容。所以Serverless架构带来的优势有以下三点：</p>
<ul>
<li>无需运维介入，研发同学就可以很快的搭建出来。</li>
<li>无论流量大小，均可以平稳的承接。</li>
<li>函数计算拉起的实例数量可以紧贴流量大小的曲线，做到资源利用率最优化，再加上按量计费的模式，可以最大程度优化成本。</li>
</ul>
<h1 id="u67B6_u6784_u89E3_u6790"><a href="#u67B6_u6784_u89E3_u6790" class="headerlink" title="架构解析"></a>架构解析</h1><p>从上面的架构图可以看到，整个采集数据阶段，分了两个函数来实现，第一个函数的作用是单纯的暴露HTTP接口接收数据，第二个函数用于处理数据，然后将数据发送至消息队列Kafka和数据库RDS。</p>
<h2 id="u63A5_u6536_u6570_u636E_u51FD_u6570"><a href="#u63A5_u6536_u6570_u636E_u51FD_u6570" class="headerlink" title="接收数据函数"></a>接收数据函数</h2><p>我们打开函数计算控制台，创建一个函数：</p>
<ul>
<li>函数类型：HTTP（即触发器为HTTP）</li>
<li>函数名称：receiveData</li>
<li>运行环境：Python3</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%205.png" alt=""></p>
<ul>
<li>函数实例类型：弹性实例</li>
<li>函数执行内存：512MB</li>
<li>函数运行超时时间：60秒</li>
<li>函数单实例并发度：1</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%206.png" alt=""></p>
<ul>
<li>触发器类型：HTTP触发器</li>
<li>触发器名称：defaultTrigger</li>
<li>认证方式：anonymous（即无需认证）</li>
<li>请求方式：GET，POST</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%207.png" alt=""></p>
<p>创建好函数之后，我们通过在线编辑器编写代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line">HELLO_WORLD = <span class="string">b'Hello world!\n'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(environ, start_response)</span>:</span></span><br><span class="line">    logger = logging.getLogger() </span><br><span class="line">    context = environ[<span class="string">'fc.context'</span>]</span><br><span class="line">    request_uri = environ[<span class="string">'fc.request_uri'</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> environ.items():</span><br><span class="line">      <span class="keyword">if</span> k.startswith(<span class="string">'HTTP_'</span>):</span><br><span class="line">        <span class="comment"># process custom request headers</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">try</span>:        </span><br><span class="line">        request_body_size = int(environ.get(<span class="string">'CONTENT_LENGTH'</span>, <span class="number">0</span>))    </span><br><span class="line">    <span class="keyword">except</span> (ValueError):        </span><br><span class="line">        request_body_size = <span class="number">0</span>   </span><br><span class="line">    <span class="comment"># 接收回传的数据</span></span><br><span class="line">    request_body = environ[<span class="string">'wsgi.input'</span>].read(request_body_size)  </span><br><span class="line">    request_body_str = urllib.parse.unquote(request_body.decode(<span class="string">"GBK"</span>))</span><br><span class="line">    request_body_obj = json.loads(request_body_str)</span><br><span class="line">    logger.info(request_body_obj[<span class="string">"action"</span>])</span><br><span class="line">    logger.info(request_body_obj[<span class="string">"articleAuthorId"</span>])</span><br><span class="line">    </span><br><span class="line">    status = <span class="string">'200 OK'</span></span><br><span class="line">    response_headers = [(<span class="string">'Content-type'</span>, <span class="string">'text/plain'</span>)]</span><br><span class="line">    start_response(status, response_headers)</span><br><span class="line">    <span class="keyword">return</span> [HELLO_WORLD]</span><br></pre></td></tr></table></figure>
<p>此时的代码非常简单，就是接收用户传来的参数，我们可以调用接口进行验证：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%208.png" alt=""></p>
<p>可以在函数的日志查询中看到此次调用的日志：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%209.png" alt=""></p>
<p>同时，我们也可以查看函数的链路追踪来分析每一个步骤的调用耗时，比如函数接到请求→冷启动（无活跃实例时）→准备代码→执行初始化方法→执行入口函数逻辑这个过程：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2010.png" alt=""></p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2011.png" alt=""></p>
<p>从调用链路图中可以看到，刚才的那次请求包含了冷启动的时间，因为当时没有活跃实例，整个过程耗时418毫秒，真正执行入口函数代码的时间为8毫秒。</p>
<p>当再次调用接口时，可以看到就直接执行了入口函数的逻辑，因为此时已经有实例在运行，整个耗时只有2.3毫秒：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2012.png" alt=""></p>
<h2 id="u5904_u7406_u6570_u636E_u7684_u51FD_u6570"><a href="#u5904_u7406_u6570_u636E_u7684_u51FD_u6570" class="headerlink" title="处理数据的函数"></a>处理数据的函数</h2><p>第一个函数是通过在函数计算控制台在界面上创建的，选择了运行环境是Python3，我们可以在<a href="https://help.aliyun.com/document_detail/56316.html?spm=a2c4g.11186623.6.576.6057e341oS5CrS" target="_blank" rel="external">官方文档</a>中查看预置的Python3运行环境内置了哪些模块，因为第二个函数要操作Kafka和RDS，所以需要我们确认对应的模块。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2013.png" alt=""></p>
<p>从文档中可以看到，内置的模块中包含RDS的SDK模块，但是没有Kafka的SDK模块，此时就需要我们手动安装Kafka SDK模块，并且创建函数也会使用另一种方式。</p>
<h3 id="Funcraft"><a href="#Funcraft" class="headerlink" title="Funcraft"></a>Funcraft</h3><p>Funcraft是一个用于支持 Serverless 应用部署的命令行工具，能帮助我们便捷地管理函数计算、API 网关、日志服务等资源。它通过一个资源配置文件（<code>template.yml</code>），协助我们进行开发、构建、部署操作。</p>
<p>所以第二个函数我们需要使用Fun来进行操作，整个操作分为四个步骤：</p>
<ul>
<li>安装fun工具。</li>
<li>编写<code>template.yml</code>模板文件，用来描述函数。</li>
<li>安装我们需要的第三方依赖。</li>
<li>上传部署函数。</li>
</ul>
<h3 id="u5B89_u88C5Fun"><a href="#u5B89_u88C5Fun" class="headerlink" title="安装Fun"></a>安装Fun</h3><p>Fun提供了三种安装方式：</p>
<ul>
<li>通过 npm 包管理安装 —— 适合所有平台（Windows/Mac/Linux）且已经预装了 npm 的开发者。</li>
<li>通过下载二进制安装 —— 适合所有平台（Windows/Mac/Linux）。</li>
<li>通过 Homebrew 包管理器安装 —— 适合 Mac 平台，更符合 MacOS 开发者习惯。</li>
</ul>
<p>文本示例环境为Mac，所以使用npm方式安装，非常的简单，一行命令搞定：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">sudo npm install @alicloud/fun -g</span><br></pre></td></tr></table></figure>
<p>安装完成之后。在控制终端输入 fun 命令可以查看版本信息：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">$ fun --version</span><br><span class="line"><span class="number">3.6</span>.<span class="number">20</span></span><br></pre></td></tr></table></figure>
<p>在第一次使用 fun 之前需要先执行 <code>fun config</code> 命令进行配置，按照提示，依次配置 Account ID、Access Key Id、Secret Access Key、 Default Region Name 即可。其中 Account ID、Access Key Id 你可以从<a href="https://fc.console.aliyun.com/" target="_blank" rel="external">函数计算控制台</a>首页的右上方获得：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">fun config</span><br><span class="line"></span><br><span class="line">? Aliyun Account ID ***************<span class="number">01</span></span><br><span class="line">? Aliyun Access Key ID ***********qef6j</span><br><span class="line">? Aliyun Access Key Secret ***********UFJG</span><br><span class="line">? Default region name cn-hangzhou</span><br><span class="line">? The timeout <span class="keyword">in</span> seconds <span class="keyword">for</span> each SDK client invoking <span class="number">60</span></span><br><span class="line">? The maximum number of retries <span class="keyword">for</span> each SDK client <span class="number">3</span></span><br></pre></td></tr></table></figure>
<h3 id="u7F16_u5199template-yml"><a href="#u7F16_u5199template-yml" class="headerlink" title="编写template.yml"></a>编写template.yml</h3><p>新建一个目录，在该目录下创建一个名为<code>template.yml</code>的YAML文件，该文件主要描述要创建的函数的各项配置，说白了就是将函数计算控制台上配置的那些配置信息以YAML格式写在文件里：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">ROSTemplateFormatVersion: &#39;2015-09-01&#39;&#10;Transform: &#39;Aliyun::Serverless-2018-04-03&#39;&#10;Resources:&#10;  FCBigDataDemo:&#10;    Type: &#39;Aliyun::Serverless::Service&#39;&#10;    Properties:&#10;      Description: &#39;local invoke demo&#39;&#10;      VpcConfig:&#10;       VpcId: &#39;vpc-xxxxxxxxxxx&#39;&#10;       VSwitchIds: [ &#39;vsw-xxxxxxxxxx&#39; ]&#10;       SecurityGroupId: &#39;sg-xxxxxxxxx&#39;&#10;      LogConfig:&#10;       Project: fcdemo&#10;       Logstore: fc_demo_store&#10;    dataToKafka:&#10;      Type: &#39;Aliyun::Serverless::Function&#39;&#10;      Properties:&#10;&#9;&#9;&#9;&#9;Initializer: index.my_initializer&#10;        Handler: index.handler&#10;        CodeUri: &#39;./&#39;&#10;        Description: &#39;&#39;&#10;        Runtime: python3</span><br></pre></td></tr></table></figure>
<p>我们来解析以上文件的核心内容：</p>
<ul>
<li>FCBigDataDemo：自定义的服务名称。通过下面的<code>Type</code>属性标明是服务，即<code>Aliyun::Serverless::Service</code>。</li>
<li>Properties：Properties下的属性都是该服务的各配置项。</li>
<li>VpcConfig：服务的VPC配置，包含：<ul>
<li>VpcId：VPC ID。</li>
<li>VSwitchIds：交换机ID，这里是数组，可以配置多个交换机。</li>
<li>SecurityGroupId：安全组ID。</li>
</ul>
</li>
<li>LogConfig：服务绑定的日志服务（SLS）配置，包含：<ul>
<li>Project：日志服务项目。</li>
<li>Logstore：LogStore名称。</li>
</ul>
</li>
<li>dataToKafka：该服务下自定义的函数名称。通过下面的<code>Type</code>属性标明是函数，即<code>Aliyun::Serverless::Function</code>。</li>
<li>Properties：Properties下的属性都是该函数的各配置项。</li>
<li>Initializer：配置初始化函数。</li>
<li>Handler：配置入口函数。</li>
<li>Runtime：函数运行环境。</li>
</ul>
<p>目录结构为：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2014.png" alt=""></p>
<h3 id="u5B89_u88C5_u7B2C_u4E09_u65B9_u4F9D_u8D56"><a href="#u5B89_u88C5_u7B2C_u4E09_u65B9_u4F9D_u8D56" class="headerlink" title="安装第三方依赖"></a>安装第三方依赖</h3><p>服务和函数的模板创建好之后，我们来安装需要使用的第三方依赖。在这个示例的场景中，第二个函数需要使用Kafka SDK，所以可以通过fun工具结合Python包管理工具pip进行安装：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fun install --runtime python3 --package-type pip kafka-python</span><br></pre></td></tr></table></figure>
<p>执行命令后有如下提示信息：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2015.png" alt=""></p>
<p>此时我们会发现在目录下会生成一个<code>.fun</code>文件夹 ，我们安装的依赖包就在该目录下：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2016.png" alt=""></p>
<h3 id="u90E8_u7F72_u51FD_u6570"><a href="#u90E8_u7F72_u51FD_u6570" class="headerlink" title="部署函数"></a>部署函数</h3><p>现在编写好了模板文件以及安装好了我们需要的Kafka SDK后，还需要添加我们的代码文件<code>index.py</code>，代码内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer</span><br><span class="line">producer = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_initializer</span><span class="params">(context)</span>:</span>    </span><br><span class="line">    logger = logging.getLogger() </span><br><span class="line">    logger.info(<span class="string">"init kafka producer"</span>)</span><br><span class="line">    <span class="keyword">global</span> producer</span><br><span class="line">    producer = KafkaProducer(bootstrap_servers=<span class="string">'XX.XX.XX.XX:9092,XX.XX.XX.XX:9092,XX.XX.XX.XX:9092'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(event, context)</span>:</span></span><br><span class="line">    logger = logging.getLogger()   </span><br><span class="line">    <span class="comment"># 接收回传的数据</span></span><br><span class="line">    event_str = json.loads(event)</span><br><span class="line">    event_obj = json.loads(event_str)</span><br><span class="line">    logger.info(event_obj[<span class="string">"action"</span>])</span><br><span class="line">    logger.info(event_obj[<span class="string">"articleAuthorId"</span>])</span><br><span class="line">    <span class="comment"># 向Kafka发送消息</span></span><br><span class="line">    <span class="keyword">global</span> producer</span><br><span class="line">    producer.send(<span class="string">'ikf-demo'</span>, json.dumps(event_str).encode(<span class="string">'utf-8'</span>))</span><br><span class="line">    producer.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure>
<p>代码很简单，这里做以简单的解析：</p>
<ul>
<li><code>my_initializer</code>：函数实例被拉起时会先执行该函数，然后再执行<code>handler</code>函数 ，当函数实例在运行时，之后的请求都不会执行<code>my_initializer</code>函数 。一般用于各种连接的初始化工作，这里将初始化Kafka Producer的方法放在了这里，避免反复初始化Produer。</li>
<li><code>handler</code>：该函数只有两个逻辑，接收回传的数据和将数据发送至Kafka的指定Topic。</li>
</ul>
<p>下面通过<code>fun deploy</code>命令部署函数，该命令会做两件事：</p>
<ul>
<li>根据<code>template.yml</code>中的配置创建服务和函数。</li>
<li>将<code>index.py</code>和<code>.fun</code>上传至函数中。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2017.png" alt=""></p>
<p>登录函数计算控制台，可以看到通过<code>fun</code>命令部署的服务和函数：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2018.png" alt=""></p>
<p>进入函数，也可以清晰的看到第三方依赖包的目录结构：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2019.png" alt=""></p>
<h2 id="u51FD_u6570_u4E4B_u95F4_u8C03_u7528"><a href="#u51FD_u6570_u4E4B_u95F4_u8C03_u7528" class="headerlink" title="函数之间调用"></a>函数之间调用</h2><p>目前两个函数都创建好了，下面的工作就是由第一个函数接收到数据后拉起第二个函数发送消息给Kafka。我们只需要对第一个函数做些许改动即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> fc2</span><br><span class="line">HELLO_WORLD = <span class="string">b'Hello world!\n'</span></span><br><span class="line">client = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_initializer</span><span class="params">(context)</span>:</span>    </span><br><span class="line">    logger = logging.getLogger() </span><br><span class="line">    logger.info(<span class="string">"init fc client"</span>)</span><br><span class="line">    <span class="keyword">global</span> client</span><br><span class="line">    client = fc2.Client(</span><br><span class="line">        endpoint=<span class="string">"http://your_account_id.cn-hangzhou-internal.fc.aliyuncs.com"</span>,</span><br><span class="line">        accessKeyID=<span class="string">"your_ak"</span>,</span><br><span class="line">        accessKeySecret=<span class="string">"your_sk"</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(environ, start_response)</span>:</span></span><br><span class="line">    logger = logging.getLogger() </span><br><span class="line">    context = environ[<span class="string">'fc.context'</span>]</span><br><span class="line">    request_uri = environ[<span class="string">'fc.request_uri'</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> environ.items():</span><br><span class="line">      <span class="keyword">if</span> k.startswith(<span class="string">'HTTP_'</span>):</span><br><span class="line">        <span class="comment"># process custom request headers</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">try</span>:        </span><br><span class="line">        request_body_size = int(environ.get(<span class="string">'CONTENT_LENGTH'</span>, <span class="number">0</span>))    </span><br><span class="line">    <span class="keyword">except</span> (ValueError):        </span><br><span class="line">        request_body_size = <span class="number">0</span>   </span><br><span class="line">    <span class="comment"># 接收回传的数据</span></span><br><span class="line">    request_body = environ[<span class="string">'wsgi.input'</span>].read(request_body_size)  </span><br><span class="line">    request_body_str = urllib.parse.unquote(request_body.decode(<span class="string">"GBK"</span>))</span><br><span class="line">    request_body_obj = json.loads(request_body_str)</span><br><span class="line">    logger.info(request_body_obj[<span class="string">"action"</span>])</span><br><span class="line">    logger.info(request_body_obj[<span class="string">"articleAuthorId"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">global</span> client</span><br><span class="line">    client.invoke_function(</span><br><span class="line">        <span class="string">'FCBigDataDemo'</span>,</span><br><span class="line">        <span class="string">'dataToKafka'</span>,</span><br><span class="line">        payload=json.dumps(request_body_str),</span><br><span class="line">        headers = &#123;<span class="string">'x-fc-invocation-type'</span>: <span class="string">'Async'</span>&#125;</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    status = <span class="string">'200 OK'</span></span><br><span class="line">    response_headers = [(<span class="string">'Content-type'</span>, <span class="string">'text/plain'</span>)]</span><br><span class="line">    start_response(status, response_headers)</span><br><span class="line">    <span class="keyword">return</span> [HELLO_WORLD]</span><br></pre></td></tr></table></figure>
<p>如上面代码所示，对第一个函数的代码做了三个地方的改动：</p>
<ul>
<li>导入函数计算的库：<code>import fc2</code></li>
<li><p>添加初始化方法，用于创建函数计算Client：</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_initializer</span><span class="params">(context)</span>:</span>    </span><br><span class="line">    logger = logging.getLogger() </span><br><span class="line">    logger.info(<span class="string">"init fc client"</span>)</span><br><span class="line">    <span class="keyword">global</span> client</span><br><span class="line">    client = fc2.Client(</span><br><span class="line">        endpoint=<span class="string">"http://your_account_id.cn-hangzhou-internal.fc.aliyuncs.com"</span>,</span><br><span class="line">        accessKeyID=<span class="string">"your_ak"</span>,</span><br><span class="line">        accessKeySecret=<span class="string">"your_sk"</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>  这里需要注意的时，当我们在代码里增加了初始化方法后，需要在函数配置中指定初始化方法的入口：</p>
<p>  <img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2020.png" alt=""></p>
</li>
<li><p>通过函数计算Client调用第二个函数：</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">global</span> client</span><br><span class="line">client.invoke_function(</span><br><span class="line">		<span class="string">'FCBigDataDemo'</span>,</span><br><span class="line">		<span class="string">'dataToKafka'</span>,</span><br><span class="line">	  payload=json.dumps(request_body_str),</span><br><span class="line">		headers = &#123;<span class="string">'x-fc-invocation-type'</span>: <span class="string">'Async'</span>&#125;</span><br><span class="line"> )</span><br></pre></td></tr></table></figure>
<p>  <code>invoke_function</code>函数有四个参数：</p>
<ul>
<li>第一个参数：调用函数所在的服务名称。</li>
<li>第二个参数：调用函数的函数名称。</li>
<li>第三个参数：向调用函数传的数据。</li>
<li>第四个参数：调用第二个函数Request Header信息。这里主要通过<code>x-fc-invocation-type</code>这个Key来设置是同步调用还是异步调用。这里设置<code>Async</code>为异步调用。</li>
</ul>
</li>
</ul>
<p>如此设置，我们便可以验证通过第一个函数提供的HTTP接口发起请求→采集数据→调用第二个函数→将数据作为消息传给Kafka这个流程了。</p>
<h3 id="u4F7F_u7528_u4E24_u4E2A_u51FD_u6570_u7684_u76EE_u7684"><a href="#u4F7F_u7528_u4E24_u4E2A_u51FD_u6570_u7684_u76EE_u7684" class="headerlink" title="使用两个函数的目的"></a>使用两个函数的目的</h3><p>到这里有些同学可能会有疑问，为什么需要两个函数，而不在第一个函数里直接向Kafka发送数据呢？我们先来看这张图：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2021.png" alt=""></p>
<p>当我们使用异步调用函数时，在函数内部会默认先将请求的数据放入消息队列进行第一道削峰填谷，然后每一个队列在对应函数实例，通过函数实例的弹性拉起多个实例进行第二道削峰填谷。所以这也就是为什么这个架构能稳定承载大并发请求的核心原因之一。</p>
<h2 id="u914D_u7F6EKafka"><a href="#u914D_u7F6EKafka" class="headerlink" title="配置Kafka"></a>配置Kafka</h2><p>在游戏运营这个场景中，数据量是比较大的，所以对Kafka的性能要求也是比较高的，相比开源自建，使用云上的Kafka省去很多的运维操作，比如：</p>
<ul>
<li>我们不再需要再维护Kafka集群的各个节点。</li>
<li>不需要关心主从节点数据同步问题。</li>
<li>可以快速、动态扩展Kafka集群规格，动态增加Topic，动态增加分区数。</li>
<li>完善的指标监控功能，消息查询功能。</li>
</ul>
<p>总的来说，就是一切SLA都有云上兜底，我们只需要关注在消息发送和消息消费即可。</p>
<p>所以我们可以打开<a href="https://common-buy.aliyun.com/?commodityCode=alikafka_pre&amp;regionId=cn-hangzhou" target="_blank" rel="external">Kafka开通界面</a>，根据实际场景的需求一键开通Kafka实例，开通Kafka后登录<a href="https://kafka.console.aliyun.com/?spm=5176.167616.1kquk9v2l.2.6a3d5a1cqKUEUh#/InstanceList?instanceId=alikafka_post-cn-nif1osdl400w&amp;regionId=cn-hangzhou" target="_blank" rel="external">控制台</a>，在基本信息中可以看到Kafka的接入点：</p>
<ul>
<li>默认接入点：走VPC内网场景的接入点。</li>
<li>SSL接入点：走公网场景的接入点。</li>
</ul>
<p>将默认接入点配置到函数计算的第二个函数中即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">....</span><br><span class="line">producer = KafkaProducer(bootstrap_servers=<span class="string">'XX.XX.XX.XX:9092,XX.XX.XX.XX:9092,XX.XX.XX.XX:9092'</span>)</span><br><span class="line">....</span><br></pre></td></tr></table></figure>
<p>然后点击左侧控制台<strong>Topic管理</strong>，创建Topic：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2022.png" alt=""></p>
<p>将创建好的Topic配置到函数计算的第二个函数中即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment"># 第一个参数为Topic名称</span></span><br><span class="line">producer.send(<span class="string">'ikf-demo'</span>, json.dumps(event_str).encode(<span class="string">'utf-8'</span>))</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>上文已经列举过云上Kafka的优势，比如动态增加Topic的分区数，我们可以在Topic列表中，对Topic的分区数进行动态调整：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2023.png" alt=""></p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2024.png" alt=""></p>
<p>单Topic最大支持到360个分区，这是开源自建无法做到的。</p>
<p>接下来点击控制台左侧<strong>Consumer Group管理</strong>，创建Consumer Group：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2025.png" alt=""></p>
<p>至此，云上的Kafka就算配置完毕了，即Producer可以往刚刚创建的Topic中发消息了，Consumer可以设置刚刚创建的GID以及订阅Topic进行消息接受和消费。</p>
<h3 id="Flink_Kafka_u6D88_u8D39_u8005"><a href="#Flink_Kafka_u6D88_u8D39_u8005" class="headerlink" title="Flink Kafka消费者"></a>Flink Kafka消费者</h3><p>在这个场景中，Kafka后面往往会跟着Flink，所以这里简要给大家介绍一下在Flink中如何创建Kafka Consumer并消费数据。代码片段如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> ParameterTool parameterTool = ParameterTool.fromArgs(args);</span><br><span class="line">String kafkaTopic = parameterTool.get(<span class="string">"kafka-topic"</span>,<span class="string">"ikf-demo"</span>);</span><br><span class="line">String brokers = parameterTool.get(<span class="string">"brokers"</span>, <span class="string">"XX.XX.XX.XX:9092,XX.XX.XX.XX:9092,XX.XX.XX.XX:9092"</span>);</span><br><span class="line">Properties kafkaProps = <span class="keyword">new</span> Properties();</span><br><span class="line">kafkaProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokers);</span><br><span class="line">kafkaProps.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"ikf-demo"</span>);</span><br><span class="line">FlinkKafkaConsumer&lt;UserBehaviorEvent&gt; kafka = <span class="keyword">new</span> FlinkKafkaConsumer&lt;&gt;(kafkaTopic, <span class="keyword">new</span> UserBehaviorEventSchema(), kafkaProps);</span><br><span class="line">kafka.setStartFromLatest();</span><br><span class="line">kafka.setCommitOffsetsOnCheckpoints(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">DataStreamSource&lt;UserBehaviorEvent&gt; dataStreamByEventTime = env.addSource(kafka);</span><br></pre></td></tr></table></figure>
<p>以上就是构建Flink Kafka Consumer和添加Kafka Source的代码片段，还是非常简单的。</p>
<h1 id="u538B_u6D4B_u9A8C_u8BC1"><a href="#u538B_u6D4B_u9A8C_u8BC1" class="headerlink" title="压测验证"></a>压测验证</h1><p>至此，整个数据采集的架构就搭建完毕了，下面我们通过压测来检验一下整个架构的性能。这里使用阿里云PTS来进行压测。</p>
<h2 id="u521B_u5EFA_u538B_u6D4B_u573A_u666F"><a href="#u521B_u5EFA_u538B_u6D4B_u573A_u666F" class="headerlink" title="创建压测场景"></a>创建压测场景</h2><p>打开<a href="https://pts.console.aliyun.com/#/overviewpage" target="_blank" rel="external">PTS控制台</a>，点击左侧菜单<strong>创建压测/创建PTS场景</strong>：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2026.png" alt=""></p>
<p>在场景配置中，将第一个函数计算函数暴露的HTTP接口作为串联链路，配置如下图所示：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2027.png" alt=""></p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2028.png" alt=""></p>
<p>接口配置完后，我们来配置施压：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2029.png" alt=""></p>
<ul>
<li>压力模式：<ul>
<li>并发模式：指定有多少并发用户同时发请求。</li>
<li>RPS模式：指定每秒有多少请求数。</li>
<li>递增模式：在压测过程中可以通过手动调节压力，也可以自动按百分比递增压力。</li>
<li>最大并发：同时有多少个虚拟用户发起请求。</li>
<li>递增百分比：如果是自动递增的话，按这里的百分比递增。</li>
<li>单量级持续时长：在未完全达到压力全量的时候，每一级梯度的压力保持的时长。</li>
<li>压测总时长：一共需要压测的时长。</li>
</ul>
</li>
</ul>
<p>这里因为资源成本原因，并发用户数设置为2500来进行验证。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2030.png" alt=""></p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%2031.png" alt=""></p>
<p>从上图压测中的情况来看，TPS达到了2w的封顶，549w+的请求，99.99%的请求是成功的，那369个异常也可以点击查看，都是压测工具请求超时导致的。</p>
<h1 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h1><p>至此，整个基于Serverless搭建的大数据采集传输的架构就搭建好了，并且进行了压测验证，整体的性能也是不错的。并且整个架构搭建起来也是非常简单和容易理解的。这个架构不光适用于游戏运营行业，其实任何大数据采集传输的场景都是适用的，目前也已经有很多客户正在基于Serverless的架构跑在生产环境，或者正走在改造Serverless架构的路上。</p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p>众所周知，游戏行业在当今的互联网行业中算是一棵常青树。在疫情之前的2019年，中国游戏市场营收规模约2884.8亿元，同比增长17.1%。2020年因为疫情，游戏行业更是突飞猛进。玩游戏本就是中国网民最普遍的娱乐方式之一，疫情期间更甚。据不完全统计，截止2019年，中国移动游戏用户规模约6.6亿人，占中国总网民规模8.47亿的77.92%，足以说明，游戏作为一种低门槛、低成本的娱乐手段，已成为大部分人生活中习以为常的一部分。</p>
<p>对于玩家而言，市面上的游戏数量多如牛毛，那么玩家如何能发现和认知到一款游戏，并且持续的玩下去恐怕是所有游戏厂商需要思考的问题。加之2018年游戏版号停发事件，游戏厂商更加珍惜每一个已获得版号的游戏产品，所以这也使得“深度打磨产品质量”和“提高运营精细程度”这两个游戏产业发展方向成为广大游戏厂商的发展思路，无论是新游戏还是老游戏都在努力落实这两点：</p>
<ul>
<li>新游戏：以更充足的推广资源和更完整的游戏内容面向玩家。</li>
<li>老游戏：通过用户行为分析，投入更多的精力和成本，制作更优质的版本内容。</li>
</ul>
<p>这里我们重点来看新游戏。一家游戏企业辛辛苦苦研发三年，等着新游戏发售时一飞冲天。那么问题来了，新游戏如何被广大玩家看到？先来看看游戏行业公司的分类：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled.png" alt=""></p>
<ul>
<li>游戏研发商：研发游戏的公司，生产和制作游戏内容。比如王者荣耀的所有英雄设计、游戏战斗场景、战斗逻辑等等，这些全部由游戏研发公司提供。</li>
<li><p>游戏发行商：游戏发行商的主要工作分三大块：市场工作、运营工作、客服工作。游戏发行商把控游戏命脉，市场工作核心是导入玩家，运营工作核心是将用户价值最大化、赚取更多利益。</p>
<p>  <img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_game_bigdata/Untitled%201.png" alt=""></p>
</li>
<li><p>游戏平台/渠道商：游戏平台和渠道商的核心目的就是曝光游戏，让尽量多的人能发现你的游戏。</p>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Serverless" scheme="http://www.devtalking.com/tags/Serverless/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Serverless在SaaS领域中的实践]]></title>
    <link href="http://www.devtalking.com//articles/serverless-saas/"/>
    <id>http://www.devtalking.com//articles/serverless-saas/</id>
    <published>2020-05-19T16:00:00.000Z</published>
    <updated>2021-10-05T16:46:43.814Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p>随着互联网人口红利逐渐减弱，基于流量的增长已经放缓，互联网行业迫切需要找到一片足以承载自身持续增长的新蓝海。产业互联网正是这一宏大背景下的新趋势。我们看到互联网浪潮正在席卷传统行业，云计算、大数据、人工智能开始大规模融入到金融、制造、物流、零售、文娱、教育、医疗等行业的生产环节中，这种融合称为产业互联网。而在产业互联网中，有一块不可小觑的领域是SaaS领域，它是ToB赛道的中间力量。比如CRM、HRM、费控系统、财务系统、协同办公等等。</p>
<h2 id="SaaS_u7CFB_u7EDF_u9762_u4E34_u7684_u6311_u6218"><a href="#SaaS_u7CFB_u7EDF_u9762_u4E34_u7684_u6311_u6218" class="headerlink" title="SaaS系统面临的挑战"></a>SaaS系统面临的挑战</h2><p>在消费互联网时代，大家是<strong>搜</strong>我想要的东西，各个厂商在云计算、大数据、人工智能等技术基座之上建立流量最大化的服务与生态，基于海量内容分发与流量共享为逻辑构建系统。而到了产业互联网时代，供给关系发生了变化，大家是<strong>定制</strong>我想要的东西，需要从供给与需求两侧出发进行双向建设，这个时候系统的灵活性和扩展性面临着前所未有的挑战，尤其是ToB的SaaS领域。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%201.png" alt=""></p>
<p>尤其当下的经济环境，SaaS厂商要明白，不能再通过烧钱的方式，只关注在自己的用户数量上，而更多的要思考如何帮助客户降低成本、增加效率，所以需要将更多的精力放在自己产品的定制化能力上。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%202.png" alt=""></p>
<h2 id="u5982_u4F55_u5E94_u5BF9_u6311_u6218"><a href="#u5982_u4F55_u5E94_u5BF9_u6311_u6218" class="headerlink" title="如何应对挑战"></a>如何应对挑战</h2><p>SaaS领域中的佼佼者Salesforce，将CRM的概念扩展到Marketing、Sales、Service，而这三块领域中只有Sales有专门的SaaS产品，其他两个领域都是各个ISV在不同行业的行业解决方案，靠的是什么？毋庸置疑，是Salesforce强大的aPaaS平台。ISV、内部实施、客户均可以在各自维度通过aPaaS平台构建自己行业、自己领域的SaaS系统，建立完整的生态。所以在我看来，现在的Salesforce已经由一家SaaS公司升华为一家aPaaS平台公司了。这种演进的过程也印证了消费互联网和产业互联网的转换逻辑以及后者的核心诉求。</p>
<p>然而不是所有SaaS公司都有财力和时间去孵化和打磨自己的aPaaS平台，但市场的变化、用户的诉求是实实在在存在的，若要生存，就要求变。这个变的核心就是能够让自己目前的SaaS系统变的灵活起来。相对建设困难的aPaaS平台，我们其实可以选择轻量且有效的Serverless方案来提升现有系统的灵活性和可扩展性，从而实现用户不同的定制需求。</p>
<h2 id="Serverless_u5DE5_u4F5C_u6D41"><a href="#Serverless_u5DE5_u4F5C_u6D41" class="headerlink" title="Serverless工作流"></a>Serverless工作流</h2><p>在上一篇文章<a href="http://www.devtalking.com/articles/serverless-online-coding/">《资源成本双优化！看Serverless颠覆编程教育的创新实践》</a>中，已经对Serverless的概念做过阐述了，并且也介绍了Serverless函数计算（FC）的概念和实践。这篇文章中介绍一下构建系统灵活性的核心要素服务编排，Serverless工作流。</p>
<p>Serverless 工作流（FnF）是一个用来协调多个分布式任务执行的全托管云服务。在 Serverless工作流中，可以用顺序、分支、并行等方式来编排分布式任务，Serverless工作流会按照设定好的步骤可靠地协调任务执行，跟踪每个任务的状态转换，并在必要时执行您定义的重试逻辑，以确保工作流顺利完成。Serverless工作流通过提供日志记录和审计来监视工作流的执行，可以轻松地诊断和调试应用。</p>
<a id="more"></a>
<p>下面这张图描述了Serverless工作流如何协调分布式任务，这些任务可以是函数、已集成云服务API、运行在虚拟机或容器上的程序。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%203.png" alt=""></p>
<p>看完Serverless工作流的介绍，大家可能已经多少有点思路了吧。系统灵活性和可扩展性的核心是服务可编排，无论是以前的BPM还是现在的aPaaS。所以基于Serverless工作流重构SaaS系统灵活性方案的核心思路，是将系统内用户最希望定制的功能进行梳理、拆分、抽离，再配合函数计算（FC）提供无状态的能力，通过Serverless工作流进行这些功能点的编排，从而实现不同的业务流程。</p>
<h2 id="u901A_u8FC7Serverless_u51FD_u6570_u8BA1_u7B97_u548CServerless_u5DE5_u4F5C_u6D41_u642D_u5EFA_u7075_u6D3B_u7684_u8BA2_u9910_u6A21_u5757"><a href="#u901A_u8FC7Serverless_u51FD_u6570_u8BA1_u7B97_u548CServerless_u5DE5_u4F5C_u6D41_u642D_u5EFA_u7075_u6D3B_u7684_u8BA2_u9910_u6A21_u5757" class="headerlink" title="通过Serverless函数计算和Serverless工作流搭建灵活的订餐模块"></a>通过Serverless函数计算和Serverless工作流搭建灵活的订餐模块</h2><p>订餐场景相信大家都不会陌生，在家叫外卖或者在餐馆点餐，都涉及到这个场景。当下也有很多提供点餐系统的SaaS服务厂商，有很多不错的SaaS点餐系统。随着消费互联网向产业互联网转换，这些SaaS点餐系统面临的定制化的需求也越来越多，其中有一个需求是不同的商家在支付时会显示不同的支付方式，比如从A商家点餐后付款时显示支付宝、微信支付、银联支付，从B商家点餐后付款时显示支付宝、京东支付。突然美团又冒出来了美团支付，此时B商家接了美团支付，那么从B商家点餐后付款时显示支付宝、京东支付、美团支付。诸如此类的定制化需求越来越多，这些SaaS产品如果没有PaaS平台，那么就会疲于不断的通过硬代码增加条件判断来实现不同商家的需求，这显然不是一个可持续发展的模式。</p>
<p>那么我们来看看通过Serverless函数计算和Serverless工作流如何优雅的解决这个问题。先来看看这个点餐流程：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%204.png" alt=""></p>
<h3 id="u901A_u8FC7Serverless_u5DE5_u4F5C_u6D41_u521B_u5EFA_u6D41_u7A0B"><a href="#u901A_u8FC7Serverless_u5DE5_u4F5C_u6D41_u521B_u5EFA_u6D41_u7A0B" class="headerlink" title="通过Serverless工作流创建流程"></a>通过Serverless工作流创建流程</h3><p>首选我需要将上面用户侧的流程转变为程序侧的流程，此时就需要使用Serverless工作流来担任此任务了。</p>
<p>打开<a href="https://fnf.console.aliyun.com/fnf/cn-hangzhou/flows" target="_blank" rel="external">Serverless控制台</a>，创建订餐流程，这里Serverless工作流使用流程定义语言FDL创建工作流，如何使用FDL创建工作流请参阅<a href="https://help.aliyun.com/document_detail/122492.html?spm=a2c4g.11186623.6.575.464c2d0eKxcO5d" target="_blank" rel="external">文档</a>。流程图如下图所示：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%205.png" alt=""></p>
<p>FDL代码为：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">version: v1beta1</span><br><span class="line">type: flow</span><br><span class="line">timeoutSeconds: <span class="number">3600</span></span><br><span class="line">steps:</span><br><span class="line">  - type: task</span><br><span class="line">    name: generateInfo</span><br><span class="line">    timeoutSeconds: <span class="number">300</span></span><br><span class="line">    resourceArn: acs:mns:::/topics/generateInfo-fnf-demo-jiyuan/messages</span><br><span class="line">    pattern: waitForCallback</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $context.task.token</span><br><span class="line">      - target: products</span><br><span class="line">        source: $input.products</span><br><span class="line">      - target: supplier</span><br><span class="line">        source: $input.supplier</span><br><span class="line">      - target: address</span><br><span class="line">        source: $input.address</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $input.orderNum</span><br><span class="line">      - target: type</span><br><span class="line">        source: $context.step.name </span><br><span class="line">    outputMappings:</span><br><span class="line">      - target: paymentcombination</span><br><span class="line">        source: $local.paymentcombination</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">    serviceParams:</span><br><span class="line">      MessageBody: $</span><br><span class="line">      Priority: <span class="number">1</span></span><br><span class="line">    catch:</span><br><span class="line">      - errors:</span><br><span class="line">          - FnF.TaskTimeout</span><br><span class="line">        goto: orderCanceled</span><br><span class="line">  - type: task</span><br><span class="line">    name: payment</span><br><span class="line">    timeoutSeconds: <span class="number">300</span></span><br><span class="line">    resourceArn: acs:mns:::/topics/payment-fnf-demo-jiyuan/messages</span><br><span class="line">    pattern: waitForCallback</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $context.task.token</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: paymentcombination</span><br><span class="line">        source: $local.paymentcombination</span><br><span class="line">      - target: type</span><br><span class="line">        source: $context.step.name </span><br><span class="line">    outputMappings:</span><br><span class="line">      - target: paymentMethod</span><br><span class="line">        source: $local.paymentMethod</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: price</span><br><span class="line">        source: $local.price</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $input.taskToken</span><br><span class="line">    serviceParams:</span><br><span class="line">      MessageBody: $</span><br><span class="line">      Priority: <span class="number">1</span></span><br><span class="line">    catch:</span><br><span class="line">      - errors:</span><br><span class="line">          - FnF.TaskTimeout</span><br><span class="line">        goto: orderCanceled</span><br><span class="line">  - type: choice</span><br><span class="line">    name: paymentCombination</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: paymentMethod</span><br><span class="line">        source: $local.paymentMethod</span><br><span class="line">      - target: price</span><br><span class="line">        source: $local.price</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $local.taskToken</span><br><span class="line">    choices:</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"zhifubao"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: zhifubao</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan/functions/zhifubao-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">              - target: price</span><br><span class="line">                source: $input.price             </span><br><span class="line">              - target: orderNum</span><br><span class="line">                source: $input.orderNum </span><br><span class="line">              - target: paymentMethod</span><br><span class="line">                source: $input.paymentMethod</span><br><span class="line">              - target: taskToken</span><br><span class="line">                source: $input.taskToken</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"weixin"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: weixin</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/weixin-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">            - target: price</span><br><span class="line">              source: $input.price             </span><br><span class="line">            - target: orderNum</span><br><span class="line">              source: $input.orderNum</span><br><span class="line">            - target: paymentMethod</span><br><span class="line">              source: $input.paymentMethod</span><br><span class="line">            - target: taskToken</span><br><span class="line">              source: $input.taskToken</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"unionpay"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: unionpay</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/union-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">            - target: price</span><br><span class="line">              source: $input.price             </span><br><span class="line">            - target: orderNum</span><br><span class="line">              source: $input.orderNum </span><br><span class="line">            - target: paymentMethod</span><br><span class="line">              source: $input.paymentMethod</span><br><span class="line">            - target: taskToken</span><br><span class="line">              source: $input.taskToken</span><br><span class="line">    default:</span><br><span class="line">      goto: orderCanceled</span><br><span class="line">  - type: task</span><br><span class="line">    name: orderCompleted</span><br><span class="line">    resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/orderCompleted</span><br><span class="line">    end: true</span><br><span class="line">  - type: task</span><br><span class="line">    name: orderCanceled</span><br><span class="line">    resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/cancerOrder</span><br></pre></td></tr></table></figure></p>
<p>在解析整个流程之前，我先要说明的一点是，我们不是完全通过Serverless函数计算和Serverless工作流来搭建订餐模块，只是用它来解决灵活性的问题，所以这个示例的主体应用是Java编写的，然后结合了Serverless函数计算和Serverless工作流。下面我们来详细解析这个流程。</p>
<h3 id="u542F_u52A8_u6D41_u7A0B"><a href="#u542F_u52A8_u6D41_u7A0B" class="headerlink" title="启动流程"></a>启动流程</h3><p>按常理，开始点餐时流程就应该启动了，所以在这个示例中，我的设计是当我们选择完商品、商家、填完地址后启动流程：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%206.png" alt=""></p>
<p>这里我们通过Serverless工作流提供的OpenAPI来启动流程。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%207.png" alt=""></p>
<h4 id="Java_u542F_u52A8_u6D41_u7A0B"><a href="#Java_u542F_u52A8_u6D41_u7A0B" class="headerlink" title="Java启动流程"></a>Java启动流程</h4><p>这个示例我使用Serverless工作流的Java SDK，首先在POM文件中添加依赖：<br><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.aliyun&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;[4.3.2,5.0.0)&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.aliyun&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;aliyun-java-sdk-fnf&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;[1.0.0,5.0.0)&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p>
<p>然后创建初始化Java SDK的Config类：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="annotation">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FNFConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="annotation">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> IAcsClient <span class="title">createDefaultAcsClient</span><span class="params">()</span></span>&#123;</span><br><span class="line">        DefaultProfile profile = DefaultProfile.getProfile(</span><br><span class="line">                <span class="string">"cn-xxx"</span>,          <span class="comment">// 地域ID</span></span><br><span class="line">                <span class="string">"ak"</span>,      <span class="comment">// RAM 账号的AccessKey ID</span></span><br><span class="line">                <span class="string">"sk"</span>); <span class="comment">// RAM 账号Access Key Secret</span></span><br><span class="line">        IAcsClient client = <span class="keyword">new</span> DefaultAcsClient(profile);</span><br><span class="line">        <span class="keyword">return</span> client;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>再来看Controller中的<code>startFNF</code>方法，该方法暴露GET方式的接口，传入三个参数：</p>
<ol>
<li><code>fnfname</code>：要启动的流程名称。</li>
<li><code>execuname</code>：流程启动后的流程实例名称。</li>
<li><code>input</code>：启动输入参数，比如业务参数。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="annotation">@GetMapping</span>(<span class="string">"/startFNF/&#123;fnfname&#125;/&#123;execuname&#125;/&#123;input&#125;"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> StartExecutionResponse <span class="title">startFNF</span><span class="params">(@PathVariable(<span class="string">"fnfname"</span>)</span> String fnfName,</span><br><span class="line">                                       @<span class="title">PathVariable</span><span class="params">(<span class="string">"execuname"</span>)</span> String execuName,</span><br><span class="line">                                       @<span class="title">PathVariable</span><span class="params">(<span class="string">"input"</span>)</span> String inputStr) <span class="keyword">throws</span> ClientException </span>&#123;</span><br><span class="line">    JSONObject jsonObject = <span class="keyword">new</span> JSONObject();</span><br><span class="line">    jsonObject.put(<span class="string">"fnfname"</span>, fnfName);</span><br><span class="line">    jsonObject.put(<span class="string">"execuname"</span>, execuName);</span><br><span class="line">    jsonObject.put(<span class="string">"input"</span>, inputStr);</span><br><span class="line">    <span class="keyword">return</span> fnfService.startFNF(jsonObject);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再来看Service中的<code>startFNF</code>方法，该方法分两部分，第一个部分是启动流程，第二部分是创建订单对象，并模拟入库（示例中是放在Map里了）：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> StartExecutionResponse <span class="title">startFNF</span><span class="params">(JSONObject jsonObject)</span> <span class="keyword">throws</span> ClientException </span>&#123;</span><br><span class="line">    StartExecutionRequest request = <span class="keyword">new</span> StartExecutionRequest();</span><br><span class="line">    String orderNum = jsonObject.getString(<span class="string">"execuname"</span>);</span><br><span class="line">    request.setFlowName(jsonObject.getString(<span class="string">"fnfname"</span>));</span><br><span class="line">    request.setExecutionName(orderNum);</span><br><span class="line">    request.setInput(jsonObject.getString(<span class="string">"input"</span>));</span><br><span class="line"></span><br><span class="line">    JSONObject inputObj = jsonObject.getJSONObject(<span class="string">"input"</span>);</span><br><span class="line">    Order order = <span class="keyword">new</span> Order();</span><br><span class="line">    order.setOrderNum(orderNum);</span><br><span class="line">    order.setAddress(inputObj.getString(<span class="string">"address"</span>));</span><br><span class="line">    order.setProducts(inputObj.getString(<span class="string">"products"</span>));</span><br><span class="line">    order.setSupplier(inputObj.getString(<span class="string">"supplier"</span>));</span><br><span class="line">    orderMap.put(orderNum, order);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> iAcsClient.getAcsResponse(request);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>启动流程时，流程名称和启动流程实例的名称是需要传入的参数，这里我将每次的订单编号作为启动流程的实例名称。至于Input，可以根据需求构造JSON字符串传入。这里我将商品、商家、地址、订单号构造了JSON字符串在流程启动时传入流程中。</p>
<p>另外，创建了此次订单的<code>Order</code>实例，并存在<code>Map</code>中，模拟入库，后续环节还会查询该订单实例更新订单属性。</p>
<h4 id="VUE_u9009_u62E9_u5546_u54C1/_u5546_u5BB6_u9875_u9762"><a href="#VUE_u9009_u62E9_u5546_u54C1/_u5546_u5BB6_u9875_u9762" class="headerlink" title="VUE选择商品/商家页面"></a>VUE选择商品/商家页面</h4><p>前端我使用VUE搭建，当点击选择商品和商家页面中的下一步后，通过GET方式调用HTTP协议的接口<code>/startFNF/{fnfname}/{execuname}/{input}</code>。和上面的Java方法对应。</p>
<ol>
<li><code>fnfname</code>：要启动的流程名称。</li>
<li><code>execuname</code>：随机生成uuid，作为订单的编号，也作为启动流程实例的名称。</li>
<li><code>input</code>：将商品、商家、订单号、地址构建为JSON字符串传入流程。<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">submitOrder()&#123;</span><br><span class="line">    <span class="keyword">const</span> orderNum = uuid.v1()</span><br><span class="line">    <span class="keyword">this</span>.$axios.$get(<span class="string">'/startFNF/OrderDemo-Jiyuan/'</span>+orderNum+<span class="string">'/&#123;\n'</span> +</span><br><span class="line">        <span class="string">'  "products": "'</span>+<span class="keyword">this</span>.products+<span class="string">'",\n'</span> +</span><br><span class="line">        <span class="string">'  "supplier": "'</span>+<span class="keyword">this</span>.supplier+<span class="string">'",\n'</span> +</span><br><span class="line">        <span class="string">'  "orderNum": "'</span>+orderNum+<span class="string">'",\n'</span> +</span><br><span class="line">        <span class="string">'  "address": "'</span>+<span class="keyword">this</span>.address+<span class="string">'"\n'</span> +</span><br><span class="line">        <span class="string">'&#125;'</span> ).then((response) =&gt; &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(response)</span><br><span class="line">        <span class="keyword">if</span>(response.message == <span class="string">"success"</span>)&#123;</span><br><span class="line">            <span class="keyword">this</span>.$router.push(<span class="string">'/orderdemo/'</span> + orderNum)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="generateInfo_u8282_u70B9"><a href="#generateInfo_u8282_u70B9" class="headerlink" title="generateInfo节点"></a>generateInfo节点</h3><p>第一个节点<code>generateInfo</code>，先来看看FDL的含义：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">- type: task</span><br><span class="line">  name: generateInfo</span><br><span class="line">  timeoutSeconds: <span class="number">300</span></span><br><span class="line">  resourceArn: acs:mns:::/topics/generateInfo-fnf-demo-jiyuan/messages</span><br><span class="line">  pattern: waitForCallback</span><br><span class="line">  inputMappings:</span><br><span class="line">    - target: taskToken</span><br><span class="line">      source: $context.task.token</span><br><span class="line">    - target: products</span><br><span class="line">      source: $input.products</span><br><span class="line">    - target: supplier</span><br><span class="line">      source: $input.supplier</span><br><span class="line">    - target: address</span><br><span class="line">      source: $input.address</span><br><span class="line">    - target: orderNum</span><br><span class="line">      source: $input.orderNum</span><br><span class="line">    - target: type</span><br><span class="line">      source: $context.step.name </span><br><span class="line">  outputMappings:</span><br><span class="line">    - target: paymentcombination</span><br><span class="line">      source: $local.paymentcombination</span><br><span class="line">    - target: orderNum</span><br><span class="line">      source: $local.orderNum</span><br><span class="line">  serviceParams:</span><br><span class="line">    MessageBody: $</span><br><span class="line">    Priority: <span class="number">1</span></span><br><span class="line">  <span class="keyword">catch</span>:</span><br><span class="line">    - errors:</span><br><span class="line">        - FnF.TaskTimeout</span><br><span class="line">      goto: orderCanceled</span><br></pre></td></tr></table></figure></p>
<ol>
<li><code>name</code>：节点名称。</li>
<li><code>timeoutSeconds</code>：超时时间。该节点等待的时长，超过时间后会跳转到<code>goto</code>分支指向的<code>orderCanceled</code>节点。</li>
<li><code>pattern</code>：设置为<code>waitForCallback</code>，表示需要等待确认。<code>inputMappings</code>：该节点入参。<ul>
<li><code>taskToken</code>：Serverless工作流自动生成的Token。</li>
<li><code>products</code>：选择的商品。</li>
<li><code>supplier</code>：选择的商家。</li>
<li><code>address</code>：送餐地址。</li>
<li><code>orderNum</code>：订单号。</li>
</ul>
</li>
<li><code>outputMappings</code>：该节点的出参。<ul>
<li><code>paymentcombination</code>：该商家支持的支付方式。</li>
<li><code>orderNum</code>：订单号。</li>
</ul>
</li>
<li><code>catch</code>：捕获异常，跳转到其他分支。</li>
</ol>
<p>这里<code>resourceArn</code>和<code>serviceParams</code>需要拿出来单独解释。Serverless工作流支持与多个云服务集成，即将其他服务作为任务步骤的执行单元。服务集成方式由FDL语言表达，在任务步骤中，可以使用<code>resourceArn</code>来定义集成的目标服务，使用<code>pattern</code>定义集成模式。所以可以看到在<code>resourceArn</code>中配置<code>acs:mns:::/topics/generateInfo-fnf-demo-jiyuan/messages</code>信息，即在<code>generateInfo</code>节点中集成了MNS消息队列服务，当<code>generateInfo</code>节点触发后会向<code>generateInfo-fnf-demo-jiyuan</code>Topic中发送一条消息。那么消息正文和参数则在<code>serviceParams</code>对象中指定。<code>MessageBody</code>是消息正文，配置<code>$</code>表示通过输入映射<code>inputMappings</code>产生消息正文。</p>
<p>看完第一个节点的示例，大家可以看到，在Serverless工作流中，节点之间的信息传递可以通过集成MNS发送消息来传递，也是使用比较广泛的方式之一。</p>
<h3 id="generateInfo-fnf-demo_u51FD_u6570"><a href="#generateInfo-fnf-demo_u51FD_u6570" class="headerlink" title="generateInfo-fnf-demo函数"></a>generateInfo-fnf-demo函数</h3><p>向<code>generateInfo-fnf-demo-jiyuan</code>Topic中发送的这条消息包含了商品信息、商家信息、地址、订单号，表示一个下订单流程的开始，既然有发消息，那么必然有接受消息进行后续处理。所以打开<a href="https://fc.console.aliyun.com/fc/overview/cn-hangzhou" target="_blank" rel="external">函数计算控制台</a>，创建服务，在服务下创建名为<code>generateInfo-fnf-demo</code>的事件触发器函数，这里选择Python Runtime：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%208.png" alt=""></p>
<p>创建MNS触发器，选择监听<code>generateInfo-fnf-demo-jiyuan</code>Topic。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%209.png" alt=""></p>
<p>打开<a href="https://mns.console.aliyun.com/?spm=5176.10695662.J_8058803260.1265.1de04783MJKJ82#/Mnstheme?regionId=cn-hangzhou" target="_blank" rel="external">消息服务MNS控制台</a>，创建<code>generateInfo-fnf-demo-jiyuan</code>Topic：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2010.png" alt=""></p>
<p>做好函数的准备工作，我们来开始写代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.client <span class="keyword">import</span> AcsClient</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.acs_exception.exceptions <span class="keyword">import</span> ServerException</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskSucceededRequest</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskFailedRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(event, context)</span>:</span></span><br><span class="line">	<span class="comment"># 1. 构建Serverless工作流Client</span></span><br><span class="line">    region = <span class="string">"cn-hangzhou"</span></span><br><span class="line">    account_id = <span class="string">"XXXX"</span></span><br><span class="line">    ak_id = <span class="string">"XXX"</span></span><br><span class="line">    ak_secret = <span class="string">"XXX"</span></span><br><span class="line">    fnf_client = AcsClient(</span><br><span class="line">        ak_id,</span><br><span class="line">        ak_secret,</span><br><span class="line">        region</span><br><span class="line">    )</span><br><span class="line">    logger = logging.getLogger()</span><br><span class="line">	<span class="comment"># 2. event内的信息即接受到Topic generateInfo-fnf-demo-jiyuan中的消息内容，将其转换为Json对象</span></span><br><span class="line">    bodyJson = json.loads(event)</span><br><span class="line">    logger.info(<span class="string">"products:"</span> + bodyJson[<span class="string">"products"</span>])</span><br><span class="line">    logger.info(<span class="string">"supplier:"</span> + bodyJson[<span class="string">"supplier"</span>])</span><br><span class="line">    logger.info(<span class="string">"address:"</span> + bodyJson[<span class="string">"address"</span>])</span><br><span class="line">    logger.info(<span class="string">"taskToken:"</span> + bodyJson[<span class="string">"taskToken"</span>])</span><br><span class="line">    supplier = bodyJson[<span class="string">"supplier"</span>]</span><br><span class="line">    taskToken = bodyJson[<span class="string">"taskToken"</span>]</span><br><span class="line">    orderNum = bodyJson[<span class="string">"orderNum"</span>]</span><br><span class="line">	<span class="comment"># 3. 判断什么商家使用什么样的支付方式组合，这里的示例比较简单粗暴，正常情况下，应该使用元数据配置的方式获取</span></span><br><span class="line">    paymentcombination = <span class="string">""</span></span><br><span class="line">    <span class="keyword">if</span> supplier == <span class="string">"haidilao"</span>:</span><br><span class="line">        paymentcombination = <span class="string">"zhifubao,weixin"</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        paymentcombination = <span class="string">"zhifubao,weixin,unionpay"</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 4. 调用Java服务暴露的接口，更新订单信息，主要是更新支付方式</span></span><br><span class="line">    url = <span class="string">"http://xx.xx.xx.xx:8080/setPaymentCombination/"</span> + orderNum + <span class="string">"/"</span> + paymentcombination + <span class="string">"/0"</span></span><br><span class="line">    x = requests.get(url)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 5. 给予generateInfo节点响应，并返回数据，这里返回了订单号和支付方式</span></span><br><span class="line">    output = <span class="string">"&#123;\"orderNum\": \"%s\", \"paymentcombination\":\"%s\" "</span> \</span><br><span class="line">                         <span class="string">"&#125;"</span> % (orderNum, paymentcombination)</span><br><span class="line">    request = ReportTaskSucceededRequest.ReportTaskSucceededRequest()</span><br><span class="line">    request.set_Output(output)</span><br><span class="line">    request.set_TaskToken(taskToken)</span><br><span class="line">    resp = fnf_client.do_action_with_exception(request)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure></p>
<p>因为<code>generateInfo-fnf-demo</code>函数配置了MNS触发器，所以当Topic<code>generateInfo-fnf-demo-jiyuan</code>有消息后就会触发执行<code>generateInfo-fnf-demo</code>函数。</p>
<p>整个代码分五部分：</p>
<ol>
<li>构建Serverless工作流Client。</li>
<li>event内的信息即接受到Topic<code>generateInfo-fnf-demo-jiyuan</code>中的消息内容，将其转换为Json对象。</li>
<li>判断什么商家使用什么样的支付方式组合，这里的示例比较简单粗暴，正常情况下，应该使用元数据配置的方式获取。比如在系统内有商家信息的配置功能，通过在界面上配置该商家支持哪些支付方式，形成元数据配置信息，提供查询接口，在这里进行查询。</li>
<li>调用Java服务暴露的接口，更新订单信息，主要是更新支付方式。</li>
<li>给予<code>generateInfo</code>节点响应，并返回数据，这里返回了订单号和支付方式。因为该节点的<code>pattern</code>是<code>waitForCallback</code>，所以需要等待响应结果。</li>
</ol>
<h3 id="payment_u8282_u70B9"><a href="#payment_u8282_u70B9" class="headerlink" title="payment节点"></a>payment节点</h3><p>我们再来看第二个节点<code>payment</code>，先来看FDL代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- type: task</span><br><span class="line">    name: payment</span><br><span class="line">    timeoutSeconds: <span class="number">300</span></span><br><span class="line">    resourceArn: acs:mns:::/topics/payment-fnf-demo-jiyuan/messages</span><br><span class="line">    pattern: waitForCallback</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $context.task.token</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: paymentcombination</span><br><span class="line">        source: $local.paymentcombination</span><br><span class="line">      - target: type</span><br><span class="line">        source: $context.step.name </span><br><span class="line">    outputMappings:</span><br><span class="line">      - target: paymentMethod</span><br><span class="line">        source: $local.paymentMethod</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: price</span><br><span class="line">        source: $local.price</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $input.taskToken</span><br><span class="line">    serviceParams:</span><br><span class="line">      MessageBody: $</span><br><span class="line">      Priority: <span class="number">1</span></span><br><span class="line">    catch:</span><br><span class="line">      - errors:</span><br><span class="line">          - FnF.TaskTimeout</span><br><span class="line">        goto: orderCanceled</span><br></pre></td></tr></table></figure></p>
<p>当流程流转到<code>payment</code>节点后，意味着用户进入了支付页面。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2011.png" alt=""></p>
<p>这时<code>payment</code>节点会向MNS的Topic<code>payment-fnf-demo-jiyuan</code>发送消息，会触发<code>payment-fnf-demo</code>函数。</p>
<h3 id="payment-fnf-demo_u51FD_u6570"><a href="#payment-fnf-demo_u51FD_u6570" class="headerlink" title="payment-fnf-demo函数"></a>payment-fnf-demo函数</h3><p><code>payment-fnf-demo</code>函数的创建方式和<code>generateInfo-fnf-demo</code>函数类似，这里不再累赘。我们直接来看代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.client <span class="keyword">import</span> AcsClient</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.acs_exception.exceptions <span class="keyword">import</span> ServerException</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.client <span class="keyword">import</span> AcsClient</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskSucceededRequest</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskFailedRequest</span><br><span class="line"><span class="keyword">from</span> mns.account <span class="keyword">import</span> Account  <span class="comment"># pip install aliyun-mns</span></span><br><span class="line"><span class="keyword">from</span> mns.queue <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(event, context)</span>:</span></span><br><span class="line">    logger = logging.getLogger()</span><br><span class="line">    region = <span class="string">"xxx"</span></span><br><span class="line">    account_id = <span class="string">"xxx"</span></span><br><span class="line">    ak_id = <span class="string">"xxx"</span></span><br><span class="line">    ak_secret = <span class="string">"xxx"</span></span><br><span class="line">    mns_endpoint = <span class="string">"http://your_account_id.mns.cn-hangzhou.aliyuncs.com/"</span></span><br><span class="line">    queue_name = <span class="string">"payment-queue-fnf-demo"</span></span><br><span class="line">    my_account = Account(mns_endpoint, ak_id, ak_secret)</span><br><span class="line">    my_queue = my_account.get_queue(queue_name)</span><br><span class="line">    <span class="comment"># my_queue.set_encoding(False)</span></span><br><span class="line">    fnf_client = AcsClient(</span><br><span class="line">        ak_id,</span><br><span class="line">        ak_secret,</span><br><span class="line">        region</span><br><span class="line">    )</span><br><span class="line">    eventJson = json.loads(event)</span><br><span class="line"></span><br><span class="line">    isLoop = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">while</span> isLoop:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            recv_msg = my_queue.receive_message(<span class="number">30</span>)</span><br><span class="line">            isLoop = <span class="keyword">False</span></span><br><span class="line">            <span class="comment"># body = json.loads(recv_msg.message_body)</span></span><br><span class="line">            logger.info(<span class="string">"recv_msg.message_body:======================"</span> + recv_msg.message_body)</span><br><span class="line">            msgJson = json.loads(recv_msg.message_body)</span><br><span class="line">            my_queue.delete_message(recv_msg.receipt_handle)</span><br><span class="line">            <span class="comment"># orderCode = int(time.time())</span></span><br><span class="line">            task_token = eventJson[<span class="string">"taskToken"</span>]</span><br><span class="line">            orderNum = eventJson[<span class="string">"orderNum"</span>]</span><br><span class="line">            output = <span class="string">"&#123;\"orderNum\": \"%s\", \"paymentMethod\": \"%s\", \"price\": \"%s\" "</span> \</span><br><span class="line">                         <span class="string">"&#125;"</span> % (orderNum, msgJson[<span class="string">"paymentMethod"</span>], msgJson[<span class="string">"price"</span>])</span><br><span class="line">            request = ReportTaskSucceededRequest.ReportTaskSucceededRequest()</span><br><span class="line">            request.set_Output(output)</span><br><span class="line">            request.set_TaskToken(task_token)</span><br><span class="line">            resp = fnf_client.do_action_with_exception(request)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            logger.info(<span class="string">"new loop"</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure></p>
<p>该函数的核心思路是等待用户在支付页面选择某个支付方式确认支付。所以这里使用了MNS的队列来模拟等待。循环等待接收队列<code>payment-queue-fnf-demo</code>中的消息，当收到消息后将订单号和用户选择的具体支付方式以及金额返回给<code>payment</code>节点。</p>
<h3 id="VUE_u9009_u62E9_u652F_u4ED8_u65B9_u5F0F_u9875_u9762"><a href="#VUE_u9009_u62E9_u652F_u4ED8_u65B9_u5F0F_u9875_u9762" class="headerlink" title="VUE选择支付方式页面"></a>VUE选择支付方式页面</h3><p>因为经过<code>generateInfo</code>节点后，该订单的支付方式信息已经有了，所以对于用户而言，当填完商品、商家、地址后，跳转到的页面就是该确认支付页面，并且包含了该商家支持的支付方式。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2012.png" alt=""></p>
<p>当进入该页面后，会请求Java服务暴露的接口，获取订单信息，根据支付方式在页面上显示不同的支付方式。代码片段如下：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2013.png" alt=""></p>
<p>当用户选定某个支付方式点击提交订单按钮后，向<code>payment-queue-fnf-demo</code>队列发送消息，即通知<code>payment-fnf-demo</code>函数继续后续的逻辑。</p>
<p>这里我使用了一个HTTP触发器类型的函数，用于实现向MNS发消息的逻辑，<code>paymentMethod-fnf-demo</code>函数代码如下。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> mns.account <span class="keyword">import</span> Account  <span class="comment"># pip install aliyun-mns</span></span><br><span class="line"><span class="keyword">from</span> mns.queue <span class="keyword">import</span> *</span><br><span class="line">HELLO_WORLD = <span class="string">b'Hello world!\n'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(environ, start_response)</span>:</span></span><br><span class="line">    logger = logging.getLogger()  </span><br><span class="line">    context = environ[<span class="string">'fc.context'</span>]</span><br><span class="line">    request_uri = environ[<span class="string">'fc.request_uri'</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> environ.items():</span><br><span class="line">      <span class="keyword">if</span> k.startswith(<span class="string">'HTTP_'</span>):</span><br><span class="line">        <span class="comment"># process custom request headers</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">try</span>:        </span><br><span class="line">        request_body_size = int(environ.get(<span class="string">'CONTENT_LENGTH'</span>, <span class="number">0</span>))    </span><br><span class="line">    <span class="keyword">except</span> (ValueError):        </span><br><span class="line">        request_body_size = <span class="number">0</span>   </span><br><span class="line">    request_body = environ[<span class="string">'wsgi.input'</span>].read(request_body_size)  </span><br><span class="line">    paymentMethod = urllib.parse.unquote(request_body.decode(<span class="string">"GBK"</span>))</span><br><span class="line">    logger.info(paymentMethod)</span><br><span class="line">    paymentMethodJson = json.loads(paymentMethod)</span><br><span class="line"></span><br><span class="line">    region = <span class="string">"cn-xxx"</span></span><br><span class="line">    account_id = <span class="string">"xxx"</span></span><br><span class="line">    ak_id = <span class="string">"xxx"</span></span><br><span class="line">    ak_secret = <span class="string">"xxx"</span></span><br><span class="line">    mns_endpoint = <span class="string">"http://your_account_id.mns.cn-hangzhou.aliyuncs.com/"</span></span><br><span class="line">    queue_name = <span class="string">"payment-queue-fnf-demo"</span></span><br><span class="line">    my_account = Account(mns_endpoint, ak_id, ak_secret)</span><br><span class="line">    my_queue = my_account.get_queue(queue_name)</span><br><span class="line">    output = <span class="string">"&#123;\"paymentMethod\": \"%s\", \"price\":\"%s\" "</span> \</span><br><span class="line">                         <span class="string">"&#125;"</span> % (paymentMethodJson[<span class="string">"paymentMethod"</span>], paymentMethodJson[<span class="string">"price"</span>])</span><br><span class="line">    msg = Message(output)</span><br><span class="line">    my_queue.send_message(msg)</span><br><span class="line">    </span><br><span class="line">    status = <span class="string">'200 OK'</span></span><br><span class="line">    response_headers = [(<span class="string">'Content-type'</span>, <span class="string">'text/plain'</span>)]</span><br><span class="line">    start_response(status, response_headers)</span><br><span class="line">    <span class="keyword">return</span> [HELLO_WORLD]</span><br></pre></td></tr></table></figure></p>
<p>该函数的逻辑很简单，就是向MNS的队列<code>payment-queue-fnf-demo</code>发送用户选择的支付方式和金额。</p>
<p>VUE代码片段如下：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2014.png" alt=""></p>
<h3 id="paymentCombination_u8282_u70B9"><a href="#paymentCombination_u8282_u70B9" class="headerlink" title="paymentCombination节点"></a>paymentCombination节点</h3><p><code>paymentCombination</code>节点是一个路由节点，通过判断某个参数路由到不同的节点，这里自然使用<code>paymentMethod</code>作为判断条件。FDL代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- type: choice</span><br><span class="line">    name: paymentCombination</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: paymentMethod</span><br><span class="line">        source: $local.paymentMethod</span><br><span class="line">      - target: price</span><br><span class="line">        source: $local.price</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $local.taskToken</span><br><span class="line">    choices:</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"zhifubao"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: zhifubao</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan/functions/zhifubao-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">              - target: price</span><br><span class="line">                source: $input.price             </span><br><span class="line">              - target: orderNum</span><br><span class="line">                source: $input.orderNum </span><br><span class="line">              - target: paymentMethod</span><br><span class="line">                source: $input.paymentMethod</span><br><span class="line">              - target: taskToken</span><br><span class="line">                source: $input.taskToken</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"weixin"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: weixin</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/weixin-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">            - target: price</span><br><span class="line">              source: $input.price             </span><br><span class="line">            - target: orderNum</span><br><span class="line">              source: $input.orderNum</span><br><span class="line">            - target: paymentMethod</span><br><span class="line">              source: $input.paymentMethod</span><br><span class="line">            - target: taskToken</span><br><span class="line">              source: $input.taskToken</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"unionpay"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: unionpay</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/union-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">            - target: price</span><br><span class="line">              source: $input.price             </span><br><span class="line">            - target: orderNum</span><br><span class="line">              source: $input.orderNum </span><br><span class="line">            - target: paymentMethod</span><br><span class="line">              source: $input.paymentMethod</span><br><span class="line">            - target: taskToken</span><br><span class="line">              source: $input.taskToken</span><br><span class="line">    default:</span><br><span class="line">      goto: orderCanceled</span><br></pre></td></tr></table></figure></p>
<p>这里的流程是，用户选择支付方式后，通过消息发送给<code>payment-fnf-demo</code>函数，然后将支付方式返回，于是流转到<code>paymentCombination</code>节点通过判断支付方式流转到具体处理支付逻辑的节点和函数。</p>
<h3 id="zhifubao_u8282_u70B9"><a href="#zhifubao_u8282_u70B9" class="headerlink" title="zhifubao节点"></a>zhifubao节点</h3><p>我们具体来看一个<code>zhifubao</code>节点：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">choices:</span><br><span class="line">  - condition: $.paymentMethod == <span class="string">"zhifubao"</span></span><br><span class="line">    steps:</span><br><span class="line">      - type: task</span><br><span class="line">        name: zhifubao</span><br><span class="line">        resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan/functions/zhifubao-fnf-demo</span><br><span class="line">        inputMappings:</span><br><span class="line">          - target: price</span><br><span class="line">            source: $input.price             </span><br><span class="line">          - target: orderNum</span><br><span class="line">            source: $input.orderNum </span><br><span class="line">          - target: paymentMethod</span><br><span class="line">            source: $input.paymentMethod</span><br><span class="line">          - target: taskToken</span><br><span class="line">            source: $input.taskToken</span><br></pre></td></tr></table></figure></p>
<p>这个节点的<code>resourceArn</code>和之前两个节点的不同，这里配置的是函数计算中函数的ARN，也就是说当流程流转到这个节点时会触发<code>zhifubao-fnf-demo</code>函数，该函数是一个事件触发函数，但不需要创建任何触发器。流程将订单金额、订单号、支付方式传给<code>zhifubao-fnf-demo</code>函数。</p>
<h3 id="zhifubao-fnf-demo_u51FD_u6570"><a href="#zhifubao-fnf-demo_u51FD_u6570" class="headerlink" title="zhifubao-fnf-demo函数"></a>zhifubao-fnf-demo函数</h3><p>来看<code>zhifubao-fnf-demo</code>函数的代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.client <span class="keyword">import</span> AcsClient</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.acs_exception.exceptions <span class="keyword">import</span> ServerException</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskSucceededRequest</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskFailedRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(event, context)</span>:</span></span><br><span class="line">  region = <span class="string">"cn-xxx"</span></span><br><span class="line">  account_id = <span class="string">"xxx"</span></span><br><span class="line">  ak_id = <span class="string">"xxx"</span></span><br><span class="line">  ak_secret = <span class="string">"xxx"</span></span><br><span class="line">  fnf_client = AcsClient(</span><br><span class="line">    ak_id,</span><br><span class="line">    ak_secret,</span><br><span class="line">    region</span><br><span class="line">  )</span><br><span class="line">  logger = logging.getLogger()</span><br><span class="line">  logger.info(event)</span><br><span class="line">  bodyJson = json.loads(event)</span><br><span class="line">  price = bodyJson[<span class="string">"price"</span>]</span><br><span class="line">  taskToken = bodyJson[<span class="string">"taskToken"</span>]</span><br><span class="line">  orderNum = bodyJson[<span class="string">"orderNum"</span>]</span><br><span class="line">  paymentMethod = bodyJson[<span class="string">"paymentMethod"</span>]</span><br><span class="line">  logger.info(<span class="string">"price:"</span> + price)</span><br><span class="line">  newPrice = int(price) * <span class="number">0.8</span></span><br><span class="line">  logger.info(<span class="string">"newPrice:"</span> + str(newPrice))</span><br><span class="line">  url = <span class="string">"http://xx.xx.xx.xx:8080/setPaymentCombination/"</span> + orderNum + <span class="string">"/"</span> + paymentMethod + <span class="string">"/"</span> + str(newPrice)</span><br><span class="line">  x = requests.get(url)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> &#123;<span class="string">"Status"</span>:<span class="string">"ok"</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>示例中的代码逻辑很简单，接收到金额后，将金额打8折，然后将价格更新回订单。其他支付方式的节点和函数如法炮制，变更实现逻辑就可以，在这个示例中，微信支付打了5折，银联支付打7折。</p>
<h3 id="u5B8C_u6574_u6D41_u7A0B"><a href="#u5B8C_u6574_u6D41_u7A0B" class="headerlink" title="完整流程"></a>完整流程</h3><p>流程中的<code>orderCompleted</code>和<code>orderCanceled</code>节点没做什么逻辑，大家可以自行发挥，思路和之前的节点一样。所以完整的流程是这样：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2015.png" alt=""><br>从Serverless工作流中看到的节点流转是这样的：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2016.png" alt=""></p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>到此，我们基于Serverless工作流和Serverless函数计算构建的订单模块示例就算完成了，在示例中，有两个点需要大家注意：</p>
<ol>
<li>配置商家和支付方式的元数据规则。</li>
<li>确认支付页面的元数据规则。<br>因为在实际生产中，我们需要将可定制的部分都抽象为元数据描述，需要有配置界面制定商家的支付方式即更新元数据规则，然后前端页面基于元数据信息展示相应的内容。</li>
</ol>
<p>所以如果之后需要接入其他的支付方式，只需在<code>paymentCombination</code>路由节点中确定好路由规则，然后增加对应的支付方式函数即可。通过增加元数据配置项，就可以在页面显示新加的支付方式，并且路由到处理新支付方式的函数中。</p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p>随着互联网人口红利逐渐减弱，基于流量的增长已经放缓，互联网行业迫切需要找到一片足以承载自身持续增长的新蓝海。产业互联网正是这一宏大背景下的新趋势。我们看到互联网浪潮正在席卷传统行业，云计算、大数据、人工智能开始大规模融入到金融、制造、物流、零售、文娱、教育、医疗等行业的生产环节中，这种融合称为产业互联网。而在产业互联网中，有一块不可小觑的领域是SaaS领域，它是ToB赛道的中间力量。比如CRM、HRM、费控系统、财务系统、协同办公等等。</p>
<h2 id="SaaS_u7CFB_u7EDF_u9762_u4E34_u7684_u6311_u6218"><a href="#SaaS_u7CFB_u7EDF_u9762_u4E34_u7684_u6311_u6218" class="headerlink" title="SaaS系统面临的挑战"></a>SaaS系统面临的挑战</h2><p>在消费互联网时代，大家是<strong>搜</strong>我想要的东西，各个厂商在云计算、大数据、人工智能等技术基座之上建立流量最大化的服务与生态，基于海量内容分发与流量共享为逻辑构建系统。而到了产业互联网时代，供给关系发生了变化，大家是<strong>定制</strong>我想要的东西，需要从供给与需求两侧出发进行双向建设，这个时候系统的灵活性和扩展性面临着前所未有的挑战，尤其是ToB的SaaS领域。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%201.png" alt=""></p>
<p>尤其当下的经济环境，SaaS厂商要明白，不能再通过烧钱的方式，只关注在自己的用户数量上，而更多的要思考如何帮助客户降低成本、增加效率，所以需要将更多的精力放在自己产品的定制化能力上。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%202.png" alt=""></p>
<h2 id="u5982_u4F55_u5E94_u5BF9_u6311_u6218"><a href="#u5982_u4F55_u5E94_u5BF9_u6311_u6218" class="headerlink" title="如何应对挑战"></a>如何应对挑战</h2><p>SaaS领域中的佼佼者Salesforce，将CRM的概念扩展到Marketing、Sales、Service，而这三块领域中只有Sales有专门的SaaS产品，其他两个领域都是各个ISV在不同行业的行业解决方案，靠的是什么？毋庸置疑，是Salesforce强大的aPaaS平台。ISV、内部实施、客户均可以在各自维度通过aPaaS平台构建自己行业、自己领域的SaaS系统，建立完整的生态。所以在我看来，现在的Salesforce已经由一家SaaS公司升华为一家aPaaS平台公司了。这种演进的过程也印证了消费互联网和产业互联网的转换逻辑以及后者的核心诉求。</p>
<p>然而不是所有SaaS公司都有财力和时间去孵化和打磨自己的aPaaS平台，但市场的变化、用户的诉求是实实在在存在的，若要生存，就要求变。这个变的核心就是能够让自己目前的SaaS系统变的灵活起来。相对建设困难的aPaaS平台，我们其实可以选择轻量且有效的Serverless方案来提升现有系统的灵活性和可扩展性，从而实现用户不同的定制需求。</p>
<h2 id="Serverless_u5DE5_u4F5C_u6D41"><a href="#Serverless_u5DE5_u4F5C_u6D41" class="headerlink" title="Serverless工作流"></a>Serverless工作流</h2><p>在上一篇文章<a href="http://www.devtalking.com/articles/serverless-online-coding/">《资源成本双优化！看Serverless颠覆编程教育的创新实践》</a>中，已经对Serverless的概念做过阐述了，并且也介绍了Serverless函数计算（FC）的概念和实践。这篇文章中介绍一下构建系统灵活性的核心要素服务编排，Serverless工作流。</p>
<p>Serverless 工作流（FnF）是一个用来协调多个分布式任务执行的全托管云服务。在 Serverless工作流中，可以用顺序、分支、并行等方式来编排分布式任务，Serverless工作流会按照设定好的步骤可靠地协调任务执行，跟踪每个任务的状态转换，并在必要时执行您定义的重试逻辑，以确保工作流顺利完成。Serverless工作流通过提供日志记录和审计来监视工作流的执行，可以轻松地诊断和调试应用。</p>]]>
    
    </summary>
    
      <category term="Serverless" scheme="http://www.devtalking.com/tags/Serverless/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Serverless在编程教育中的实践]]></title>
    <link href="http://www.devtalking.com//articles/serverless-online-coding/"/>
    <id>http://www.devtalking.com//articles/serverless-online-coding/</id>
    <published>2020-04-19T16:00:00.000Z</published>
    <updated>2021-10-05T16:46:43.813Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>说起Serverless这个词，我想大家应该都不陌生，那么Serverless这个词到底是什么意思？Serverless到底能解决什么问题？可能很多朋友还没有深刻的体会和体感。这篇文章我就和大家一起聊聊Serverless。</p>
<h2 id="u4EC0_u4E48_u662FServerless"><a href="#u4EC0_u4E48_u662FServerless" class="headerlink" title="什么是Serverless"></a>什么是Serverless</h2><p>我们先将Serverless这个词拆开来看。Server，大家都知道是服务器的意思，说明Serverless解决的问题范围在服务端。Less，大家肯定也知道它的意思是较少的。那么Serverless连起来，再稍加修饰，那就是较少的关心服务器的意思。</p>
<h3 id="Serverfull_u65F6_u4EE3"><a href="#Serverfull_u65F6_u4EE3" class="headerlink" title="Serverfull时代"></a>Serverfull时代</h3><p>我们都知道，在研发侧都会有研发人员和运维人员两个角色，要开发一个新系统的时候，研发人员根据产品经理的PRD开始写代码开发功能，当功能开发、测试完之后，要发布到服务器。这个时候开始由运维人员规划服务器规格、服务器数量、每个服务部署的节点数量、服务器的扩缩容策略和机制、发布服务过程、服务优雅上下线机制等等。这种模式是研发和运维隔离，服务端运维都由专门的运维人员处理，而且很多时候是靠纯人力处理，也就是Serverfull时代。</p>
<h3 id="DevOps_u65F6_u4EE3"><a href="#DevOps_u65F6_u4EE3" class="headerlink" title="DevOps时代"></a>DevOps时代</h3><p>互联网公司里最辛苦的是谁？我相信大多数都是运维同学。白天做各种网络规划、环境规划、数据库规划等等，晚上熬夜发布新版本，做上线保障，而且很多事情是重复性的工作。然后慢慢就有了赋能研发这样的声音，运维同学帮助研发同学做一套运维控制台，可以让研发同学在运维控制台上自行发布服务、查看日志、查询数据。这样一来，运维同学主要维护这套运维控制台系统，并且不断完善功能，轻松了不少。这就是研发兼运维的DevOps时代。</p>
<h3 id="Serverless_u65F6_u4EE3"><a href="#Serverless_u65F6_u4EE3" class="headerlink" title="Serverless时代"></a>Serverless时代</h3><p>渐渐的，研发同学和运维同学的关注点都在运维控制台了，运维控制台的功能越来越强大，比如根据运维侧的需求增加了自动弹性扩缩、性能监控的功能，根据研发侧的需求增加了自动化发布的流水线功能。因为有了这套系统，代码质量检测、单元测试、打包编译、部署、集成测试、灰度发布、弹性扩缩、性能监控、应用防护这一系列服务端的工作基本上不需要人工参与处理了。这就是NoOps，Serverless时代。</p>
<a id="more"></a>
<h2 id="Serverless_u5728_u7F16_u7A0B_u6559_u80B2_u4E2D_u7684_u5E94_u7528"><a href="#Serverless_u5728_u7F16_u7A0B_u6559_u80B2_u4E2D_u7684_u5E94_u7528" class="headerlink" title="Serverless在编程教育中的应用"></a>Serverless在编程教育中的应用</h2><p>2020年注定是不平凡的一年，疫情期间，多少家企业如割韭菜般倒下，又有多少家企业如雨后春笋般茁壮成长，比如在线教育行业。</p>
<p>没错，在线教育行业是这次疫情的最大受益者，在在线教育在这个行业里，有一个细分市场是在线编程教育，尤其是少儿编程教育和面向非专业人士的编程教育，比如编程猫、斑马AI、小象学院等。这些企业的在线编程系统都有一些共同的特点和诉求：</p>
<ul>
<li>屏幕一侧写代码，执行代码，另一侧显示运行结果。</li>
<li>根据题目编写的代码都是代码块，每道题的代码量不会很大。</li>
<li>运行代码的速度要快。</li>
<li>支持多种编程语言。</li>
<li>能支撑不可预计的流量洪峰冲击。</li>
</ul>
<p>例如小象学院的编程课界面：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%201.png" alt=""></p>
<p>结合上述这些特点和诉求，不难看出，构建这样一套在线编程系统的核心在于有一个支持多种编程语言的、健壮高可用的代码运行环境。</p>
<p>那么我们先来看看传统的实现架构：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%202.png" alt=""></p>
<p>从High Level的架构来看，前端只需要将代码片段和编程语言的标识传给Server端即可，然后等待响应展示结果。所以整个Server端要负责对不同语言的代码进行分类、预处理然后传给不同编程语言的Runtime。这种架构有以下几个比较核心的问题。</p>
<h3 id="u5DE5_u4F5C_u91CF_u5927_uFF0C_u7075_u6D3B_u6027_u5DEE"><a href="#u5DE5_u4F5C_u91CF_u5927_uFF0C_u7075_u6D3B_u6027_u5DEE" class="headerlink" title="工作量大，灵活性差"></a>工作量大，灵活性差</h3><p>首先是研发和运维工作量的问题，当市场有新的需求，或者洞察到新业务模式时需要增加编程语言，此时研发侧需要增加编程代码分类和预处理的逻辑，另外需要构建对应编程语言的Runtime。在运维侧需要规划支撑新语言的服务器规格以及数量，还有整体的CICD流程等。所以支持新的编程语言这个需求要落地，需要研发、运维花费不少的时间来实现，再加上黑/白盒测试和CICD流程测试的时间，对市场需求的支撑不能快速的响应，灵活性相对较差。</p>
<h3 id="u9AD8_u53EF_u7528_u81EA_u5DF1_u515C_u5E95"><a href="#u9AD8_u53EF_u7528_u81EA_u5DF1_u515C_u5E95" class="headerlink" title="高可用自己兜底"></a>高可用自己兜底</h3><p>其次整个在线编程系统的稳定性是重中之重。所以所有Server端服务的高可用架构都需要自己搭建，用以保证流量高峰场景和稳态场景下的系统稳定。高可用一方面是代码逻辑编写的是否优雅和完善，另一方面是部署服务的集群，无论是ECS集群还是K8s集群，都需要研发和运维同学一起规划，那么对于对编程语言进行分类和预处理的服务来讲，尚能给定一个节点数，但是对于不同语言的Runtime服务来讲，市场需求随时会变，所以不好具体衡量每个服务的节点数。另外很重要的一点是所以服务的扩容，缩容机制都需要运维同学来实时手动操作，即便是通过脚本实现自动化，那么ECS弹起的速度也是远达不到业务预期的。</p>
<h3 id="u6210_u672C_u63A7_u5236_u7C92_u5EA6_u7C97"><a href="#u6210_u672C_u63A7_u5236_u7C92_u5EA6_u7C97" class="headerlink" title="成本控制粒度粗"></a>成本控制粒度粗</h3><p>再次是整个IaaS资源的成本控制，我们都知道这种在线教育是有明显的流量潮汐的，比如上午10点到12点，下午3点到5点，晚上8点到10点这几个时段是流量比较大的时候，其他时间端流量比较小，而且夜晚更是没什么流量。所以在这种情况下，传统的部署架构无法做到IaaS资源和流量的贴合。举个例子，加入为了应对流量高峰时期，需要20台ECS搭建集群来承载流量冲击，此时每台ECS的资源使用率可能在70%以上，利用率较高，但是在流量小的时候和夜晚，每台ECS的资源使用率可能就是百分之十几甚至更低，这就是一种资源浪费。</p>
<h3 id="Serverless_u67B6_u6784"><a href="#Serverless_u67B6_u6784" class="headerlink" title="Serverless架构"></a>Serverless架构</h3><p>那么我们来看看如何使用Serverless架构来实现同样的功能，并且解决上述几个问题。在选择Serverless产品时，在国内自然而然优先想到的就是阿里云的产品。阿里云有两款Serverless架构的产品Serverless 应用引擎和函数计算，这里我们使用函数计算来实现编程教育的场景。</p>
<p>函数计算（Function Compute）是事件驱动的全托管计算服务，简称FC。使用函数计算，我们无需采购与管理服务器等基础设施，只需编写并上传代码。函数计算为您准备好计算资源，弹性地、可靠地运行任务，并提供日志查询、性能监控和报警等功能。</p>
<p>这里不对FC的含义做过多赘述，只举一个例子。FC中有两个概念，一个是服务，一个是函数。一个服务包含多个函数：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%203.png" alt=""></p>
<p>这里拿Java微服务架构来对应，可以理解为，FC中的服务是Java中的一个类，FC中的函数是Java类中的一个方法：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%204.png" alt=""></p>
<p>但是Java类中的方法固然只能是Java代码，而FC中的函数可以设置不同语言的Runtime来运行不同的编程语言：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%205.png" alt=""></p>
<p>这个结构理解清楚之后，我们来看看如何调用FC的函数，这里会引出一个触发器的概念。我们最常使用的HTTP请求协议其实就是一种类型的触发器，在FC里称为HTTP触发器，除了HTTP触发器以外，还提供了OSS（对象存储）触发器、SLS（日志服务）触发器、定时触发器、MNS触发器、CDN触发器等。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%206.png" alt=""></p>
<p>从上图可以大概理解，我们可以通过多种途径调用FC中的函数。举例两个场景，比如每当我在指定的OSS Bucket的某个目录下上传一张图片后，就可以触发FC中的函数，函数的逻辑是将刚刚上传的图片下载下来，然后对图片做处理，然后再上传回OSS。再比如向MNS的某个队列发送一条消息，然后触发FC中的函数来处理针对这条消息的逻辑。</p>
<p>最后我们再来看看FC的高可用。每一个函数在运行代码时底层肯定还是IaaS资源，但我们只需要给每个函数设置运行代码时需要的内存数即可，最小128M，最大3G，对使用者而言，不需要考虑多少核数，也不需要知道代码运行在什么样的服务器上，不需要关心启动了多少个函数实例，也不需要关心弹性扩缩的问题等，这些都由FC来处理。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%207.png" alt=""></p>
<p>从上图可以看到，高可用有两种策略：</p>
<ul>
<li>给函数设置并发实例数，假如设置为3，那么有三个请求进来时，该函数只启一个实例，但是会启三个线程来运行逻辑。</li>
<li>线程数达到上限后，会再拉起一个函数实例。</li>
</ul>
<p>大家看到这里，可能已经大概对基于FC实现在线编程教育系统的架构有了一个大概的轮廓。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%208.png" alt=""></p>
<p>上图是基于FC实现的在线编程教育系统的架构图，在这个架构下来看看上述那三个核心问题怎么解：</p>
<ul>
<li>工作量和灵活性：我们只需要关注在如何执行代码的业务逻辑上，如果要加新语言，只需要创建一个对应语言Runtime的FC函数即可。</li>
<li>高可用：多线程运行业务逻辑和多实例运行业务逻辑两层高可用保障，并且函数实例的扩缩完全都是FC自动处理，不需要研发和运维同学做任何配置。</li>
<li>成本优化：当没有请求的时候，函数实例是不会被拉起的，此时也不会计费，所以在流量低谷期或者夜间时，整个FC的成本消耗是非常低的。可以做到函数实例个数、计费粒度和流量完美的贴合。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%209.png" alt=""></p>
<h2 id="Python_u7F16_u7A0B_u8BED_u8A00_u793A_u4F8B"><a href="#Python_u7F16_u7A0B_u8BED_u8A00_u793A_u4F8B" class="headerlink" title="Python编程语言示例"></a>Python编程语言示例</h2><p>下面以运行Python代码为例来看看如何用FC实现Python在线编程Demo。</p>
<h3 id="u521B_u5EFA_u670D_u52A1_u548C_u51FD_u6570"><a href="#u521B_u5EFA_u670D_u52A1_u548C_u51FD_u6570" class="headerlink" title="创建服务和函数"></a>创建服务和函数</h3><p>打开函数计算（FC）<a href="https://fc.console.aliyun.com/fc/overview/cn-hangzhou" target="_blank" rel="external">控制台</a>，选择对应的Region，选择左侧服务/函数，然后新建服务：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2010.png" alt=""></p>
<p>输出服务名称，创建服务。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2011.png" alt=""></p>
<p>进入新创建的服务，然后创建函数，选择HTTP函数，即可配置HTTP触发器的函数：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2012.png" alt=""></p>
<p>设置函数的各个参数：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2013.png" alt=""></p>
<p>几个需要的注意的参数这里做以说明：</p>
<ul>
<li>运行环境：这个很好理解，这里选择Python3</li>
<li>函数实例类型：这里有弹性实例和性能实例两种，前者最大支持2C3G规格的实例，后者支持更大的规格，最大到8C16G。</li>
<li>函数入口：详细参见<a href="https://help.aliyun.com/document_detail/74756.html?spm=a2c4g.11186623.6.572.195359cdselnzR" target="_blank" rel="external">文档</a></li>
<li>HTTP触发器认证方式：anonymous为不需要鉴权，function是需要鉴权的。</li>
</ul>
<h3 id="u4EE3_u7801_u89E3_u6790"><a href="#u4EE3_u7801_u89E3_u6790" class="headerlink" title="代码解析"></a>代码解析</h3><p>函数创建好，进入函数，可以看到概述、代码执行、触发器、日志查询等页签，我们先看触发器，会看到这个函数自动创建了一个HTTP触发器，有调用该函数对应的HTTP路径：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2014.png" alt=""></p>
<p>然后我们选择代码执行，直接在线写入我们的代码：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2015.png" alt=""></p>
<p>具体代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(environ, start_response)</span>:</span></span><br><span class="line">    context = environ[<span class="string">'fc.context'</span>]</span><br><span class="line">    request_uri = environ[<span class="string">'fc.request_uri'</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> environ.items():</span><br><span class="line">      <span class="keyword">if</span> k.startswith(<span class="string">'HTTP_'</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">try</span>:        </span><br><span class="line">        request_body_size = int(environ.get(<span class="string">'CONTENT_LENGTH'</span>, <span class="number">0</span>))    </span><br><span class="line">    <span class="keyword">except</span> (ValueError):        </span><br><span class="line">        request_body_size = <span class="number">0</span>   </span><br><span class="line">    <span class="comment"># 获取用户传入的code</span></span><br><span class="line">    request_body = environ[<span class="string">'wsgi.input'</span>].read(request_body_size)  </span><br><span class="line">    codeStr = urllib.parse.unquote(request_body.decode(<span class="string">"GBK"</span>))</span><br><span class="line">    <span class="comment"># 因为body里的对象里有code和input两个属性，这里分别获取用户code和用户输入</span></span><br><span class="line">    codeArr = codeStr.split(<span class="string">'&amp;'</span>)</span><br><span class="line">    code = codeArr[<span class="number">0</span>][<span class="number">5</span>:]</span><br><span class="line">    inputStr = codeArr[<span class="number">1</span>][<span class="number">6</span>:]</span><br><span class="line">    <span class="comment"># 将用户code保存为py文件，放/tmp目录下，以时间戳为文件名</span></span><br><span class="line">    fileName = <span class="string">'/tmp/'</span> + str(int(time.time())) + <span class="string">'.py'</span></span><br><span class="line">    f = open(fileName, <span class="string">"w"</span>)</span><br><span class="line">    <span class="comment"># 这里预置引入了time库</span></span><br><span class="line">    f.write(<span class="string">'import time \r\n'</span>)</span><br><span class="line">    f = open(fileName, <span class="string">"a"</span>)</span><br><span class="line">    f.write(code)</span><br><span class="line">    f.close()</span><br><span class="line">    <span class="comment"># 创建子进程，执行刚才保存的用户code py文件</span></span><br><span class="line">    p = subprocess.Popen(<span class="string">"python "</span> + fileName, stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE, shell=<span class="keyword">True</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment"># 通过标准输入传入用户的input输入</span></span><br><span class="line">    <span class="keyword">if</span> inputStr != <span class="string">''</span> :</span><br><span class="line">        p.stdin.write(inputStr + <span class="string">"\n"</span>)</span><br><span class="line">        p.stdin.flush()</span><br><span class="line">    <span class="comment"># 通过标准输出获取代码执行结果</span></span><br><span class="line">    r = p.stdout.read()</span><br><span class="line">    status = <span class="string">'200 OK'</span></span><br><span class="line">    response_headers = [(<span class="string">'Content-type'</span>, <span class="string">'text/plain'</span>)]</span><br><span class="line">    start_response(status, response_headers)</span><br><span class="line">    <span class="keyword">return</span> [r.encode(<span class="string">'UTF-8'</span>)]</span><br></pre></td></tr></table></figure></p>
<p>整个代码思路如下：</p>
<ul>
<li>从前端传入代码片段，格式是字符串。</li>
<li>在FC函数中获取到传入的代码字符串，截取code内容和input的内容。因为这里简单实现了Python中input交互的能力。</li>
<li>将代码保存为一个Python文件，以时间戳为文件名，保存在FC函数的/tmp目录下。（每个FC函数都有独立的/tmp目录，可以存放临时文件）</li>
<li>然后在文件中追加了引入time库的代码，应对sleep这种交互场景。</li>
<li>通过subprocess创建子进程，以Shell的方式通过Python命令执行保存在/tmp目录下的Python文件。如果有用户输入的信息，则通过标准输入输出写入子进程。</li>
<li>最后读取执行结果返回给前端。</li>
</ul>
<h3 id="u524D_u7AEF_u4EE3_u7801"><a href="#u524D_u7AEF_u4EE3_u7801" class="headerlink" title="前端代码"></a>前端代码</h3><p>前端我使用VUE写了简单的页面，这里解析两个简单的方法：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2016.png" alt=""></p>
<p>页面加载时初始化HTTP请求对象，调用的HTTP路径就是方才函数的HTTP触发器的路径。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2017.png" alt=""></p>
<p>这个方法就是调用FC中的PythonRuntime函数，将前端页面的代码片段传给该函数。这里处理input交互的思路是，扫描整个代码片段，以包含input代码为标识将整个代码段分成多段。没有包含input代码的直接送给FC函数执行，包含input代码的，请求用户的输入，然后代码片段带着用户输入的信息一起送给FC函数执行。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2018.png" alt=""></p>
<p>演示如下：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/lagoudemo.gif" alt=""></p>
<h2 id="u7ED3_u675F_u8BED"><a href="#u7ED3_u675F_u8BED" class="headerlink" title="结束语"></a>结束语</h2><p>这篇文章洋洋洒洒给大家介绍了Serverless，阿里云的Serverless产品函数计算（FC）以及基于函数计算（FC）实现的在线编程系统的Demo。大家应该有所体感，基于函数计算（FC）实现在线编程系统时，研发同学只需要专注在如何执行由前端传入的代码即可，整个Server端的各个环节都不需要研发同学和运维同学去关心，基本体现了Serverless的精髓。</p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>说起Serverless这个词，我想大家应该都不陌生，那么Serverless这个词到底是什么意思？Serverless到底能解决什么问题？可能很多朋友还没有深刻的体会和体感。这篇文章我就和大家一起聊聊Serverless。</p>
<h2 id="u4EC0_u4E48_u662FServerless"><a href="#u4EC0_u4E48_u662FServerless" class="headerlink" title="什么是Serverless"></a>什么是Serverless</h2><p>我们先将Serverless这个词拆开来看。Server，大家都知道是服务器的意思，说明Serverless解决的问题范围在服务端。Less，大家肯定也知道它的意思是较少的。那么Serverless连起来，再稍加修饰，那就是较少的关心服务器的意思。</p>
<h3 id="Serverfull_u65F6_u4EE3"><a href="#Serverfull_u65F6_u4EE3" class="headerlink" title="Serverfull时代"></a>Serverfull时代</h3><p>我们都知道，在研发侧都会有研发人员和运维人员两个角色，要开发一个新系统的时候，研发人员根据产品经理的PRD开始写代码开发功能，当功能开发、测试完之后，要发布到服务器。这个时候开始由运维人员规划服务器规格、服务器数量、每个服务部署的节点数量、服务器的扩缩容策略和机制、发布服务过程、服务优雅上下线机制等等。这种模式是研发和运维隔离，服务端运维都由专门的运维人员处理，而且很多时候是靠纯人力处理，也就是Serverfull时代。</p>
<h3 id="DevOps_u65F6_u4EE3"><a href="#DevOps_u65F6_u4EE3" class="headerlink" title="DevOps时代"></a>DevOps时代</h3><p>互联网公司里最辛苦的是谁？我相信大多数都是运维同学。白天做各种网络规划、环境规划、数据库规划等等，晚上熬夜发布新版本，做上线保障，而且很多事情是重复性的工作。然后慢慢就有了赋能研发这样的声音，运维同学帮助研发同学做一套运维控制台，可以让研发同学在运维控制台上自行发布服务、查看日志、查询数据。这样一来，运维同学主要维护这套运维控制台系统，并且不断完善功能，轻松了不少。这就是研发兼运维的DevOps时代。</p>
<h3 id="Serverless_u65F6_u4EE3"><a href="#Serverless_u65F6_u4EE3" class="headerlink" title="Serverless时代"></a>Serverless时代</h3><p>渐渐的，研发同学和运维同学的关注点都在运维控制台了，运维控制台的功能越来越强大，比如根据运维侧的需求增加了自动弹性扩缩、性能监控的功能，根据研发侧的需求增加了自动化发布的流水线功能。因为有了这套系统，代码质量检测、单元测试、打包编译、部署、集成测试、灰度发布、弹性扩缩、性能监控、应用防护这一系列服务端的工作基本上不需要人工参与处理了。这就是NoOps，Serverless时代。</p>]]>
    
    </summary>
    
      <category term="Serverless" scheme="http://www.devtalking.com/tags/Serverless/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：重要配置和性能探讨]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-19/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-19/</id>
    <published>2019-04-14T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.115Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>最后这一章节总结Kafka中需要特别关注的重要配置以及影响Kafka性能的因素。</p>
<h3 id="u91CD_u8981_u914D_u7F6E"><a href="#u91CD_u8981_u914D_u7F6E" class="headerlink" title="重要配置"></a>重要配置</h3><ul>
<li><code>auto.create.topics.enable</code>：该配置项默认值是<code>true</code>，但在生产环境最好设置为<code>false</code>。这样可以控制创建Topic的人以及创建时间。</li>
<li><code>background.threads</code>：该配置项默认值是10，既整个Kafka在执行各种任务时会启动的线程数。如果你的CPU很强劲，那么可以将线程数设大一点。</li>
<li><code>delete.topic.enable</code>：该配置项默认值是<code>false</code>，可以根据实际需求改变，在生产环境还是建议保持默认值，这样至少不会出现Topic被误删的情况。</li>
<li><code>log.flush.interval.messages</code>：该配置项最好保持默认值，把这个任务交给操作系统的文件系统去处理。</li>
<li><code>log.retention.hours</code>：日志文件保留的时间默认是168小时，既7天。这个配置可以根据具体业务需求而定。</li>
<li><code>message.max.bytes</code>：每条Message或一批次Message的大小默认是1MB。这个配置也要根据具体需求而定，比如带宽的情况。</li>
<li><code>min.insync.replicas</code>：该配置项的默认值是1，既在acks=all时，最少得有一个Replica进行确认回执。建议在生产环境配置为2，保证数据的完整性。</li>
<li><code>num.io.threads</code>：处理I/O操作的线程数，默认是8个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.network.threads</code>：处理网络请求和响应的线程数，默认是3个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。默认值是1，根据实际情况配置数据目录数，从而判断该配置项应该如何设置。</li>
<li><code>num.replica.fetchers</code>：该配置项影响Replicas同步数据的速度，默认值是1，如果发现Replicas同步延迟较大，可以提升该配置项。</li>
<li><code>offsets.retention.minutes</code>：Offset保留的时间，默认值是1440，既24小时。在生产环境建议将该配置项设大一点，比如设置为1个月，保证消费数据的完整性。</li>
<li><code>unclean.leader.election.enable</code>：该配置项的作用是，指定是否可以将非ISR的Replicas选举为Leader，默认值为<code>false</code>。在生产环境建议保持默认值，防止数据丢失。</li>
<li><code>zookeeper.session.timeout.ms</code>：Zookeeper会话超时时间，默认值为6000。按实际情况而定，通常情况下保持60秒即可。</li>
<li><code>default.replication.factor</code>：默认Replication Factor为1，建议设置为2或者3，以保证数据完整性和整个集群的健壮性。</li>
<li><code>num.partitions</code>：Topic默认的Partition数，默认是1，建议设置为3或者6，以保证数据完整性和整个集群的健壮性。</li>
</ul>
<a id="more"></a>
<p>以上是比较重要，需要我们根据实际情况额外关注的配置项。</p>
<h3 id="u5F71_u54CD_u6027_u80FD_u7684_u56E0_u7D20"><a href="#u5F71_u54CD_u6027_u80FD_u7684_u56E0_u7D20" class="headerlink" title="影响性能的因素"></a>影响性能的因素</h3><p>影响Kafka性能大概有五个因素。</p>
<h4 id="u78C1_u76D8I/O"><a href="#u78C1_u76D8I/O" class="headerlink" title="磁盘I/O"></a>磁盘I/O</h4><p>我们知道Kafka是将大多数数据保存在磁盘上的。所以磁盘的读写性能很大程度上会影响Kafka系统的性能。所以我们可以注意以下几点：</p>
<ul>
<li>使用性能比较好的XFS日志文档系统，既Linux中的文件系统。</li>
<li>如果发现在I/O操作方面出现了瓶颈，那么可以通过扩充磁盘来改善。Broker配置文件中的<code>log.dirs</code>配置项可以配置多个数据目录路径。</li>
<li>设置合理的数据清理时间，也就是配置文件中的<code>log.retention.hours</code>配置项。如果已经消费的数据长时间保留在磁盘中，既没有意义又会对Kafka读写性能造成影响。</li>
<li>及时监控部署Kafka服务器的磁盘情况。</li>
</ul>
<h4 id="u7F51_u7EDC"><a href="#u7F51_u7EDC" class="headerlink" title="网络"></a>网络</h4><p>数据传输的延迟性是任何MQ系统都要关注的问题，Kafka也不例外，在这方面我们要注意以下几点：</p>
<ul>
<li>确保部署Kafka的服务器和部署Zookeeper的服务器在一个内网内，服务器之间的物理距离不要太远，比如一个在北京，一个在上海。</li>
<li>确保部署不同Kafka Broker的服务器在一个内网内，服务器之间的物理距离不要太远。</li>
<li>保证服务器有比较好的网络带宽配置。</li>
</ul>
<h4 id="RAM"><a href="#RAM" class="headerlink" title="RAM"></a>RAM</h4><p>Kafka的高性能特性离不开对计算机内存的使用技术，对内存的使用大体分Java堆内存的使用和操作系统（Linux）Page Cache的使用：</p>
<ul>
<li>在启动Kafka Broker时，可以通过环境变量<code>KAFKA_HEAP_OPTS</code>设置对Java堆内存的使用大小。比如<code>export KAFKA_HEAP_OPTS=“-Xmx4g”</code>。</li>
<li>Broker中的Partition数量会影响对Java堆内存的使用大小。Partition越多，堆内存使用的越多。</li>
<li>对于Page Cache/文件Cache，我们不用做任何设置：<blockquote>
<p>Page Cache：当应用程序需要读取文件中的数据时，操作系统先分配一些内存，将数据从存储设备读入到这些内存中，然后再将数据分发给应用程序；当需要往文件中写数据时，操作系统先分配内存接收用户数据，然后再将数据从内存写到磁盘上。文件 Cache 管理指的就是对这些由操作系统分配，并用来存储文件数据的内存的管理。</p>
</blockquote>
</li>
</ul>
<h4 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h4><p>因为Kafka在Message传输的整个过程中，不会对Message进行任何计算，所以CPU通常不会成为Kafka性能的主要瓶颈。但是在一些情况下，也会对Kafka的性能产生影响：</p>
<ul>
<li>Message加密/解密的过程中会增加CPU的负载。</li>
<li>Message压缩/解压的过程中会增加CPU的负载。</li>
<li>在GC堆内存时会增加CPU的负载。</li>
</ul>
<h4 id="u64CD_u4F5C_u7CFB_u7EDF"><a href="#u64CD_u4F5C_u7CFB_u7EDF" class="headerlink" title="操作系统"></a>操作系统</h4><p>通常优先推荐使用Linux系统，尤其在高性能计算领域，Linux已经成为一个占主导地位的操作系统。其次也可以使用Solaris系统。Windows系统是不推荐使用的。另外，尽量保证运行Kafka Broker的操作系统中，不要运行其他的应用程序，避免和Kafka产生资源竞争，从而影响性能。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这是本小册的最后一章节，探讨了Kafka的一些重要配置和影响Kafka性能的关键因素。整个小册从最基本的认知到核心概念的诠释再到实践，帮助小伙伴渡过Kafka和Zookeeper的萌新阶段。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>最后这一章节总结Kafka中需要特别关注的重要配置以及影响Kafka性能的因素。</p>
<h3 id="u91CD_u8981_u914D_u7F6E"><a href="#u91CD_u8981_u914D_u7F6E" class="headerlink" title="重要配置"></a>重要配置</h3><ul>
<li><code>auto.create.topics.enable</code>：该配置项默认值是<code>true</code>，但在生产环境最好设置为<code>false</code>。这样可以控制创建Topic的人以及创建时间。</li>
<li><code>background.threads</code>：该配置项默认值是10，既整个Kafka在执行各种任务时会启动的线程数。如果你的CPU很强劲，那么可以将线程数设大一点。</li>
<li><code>delete.topic.enable</code>：该配置项默认值是<code>false</code>，可以根据实际需求改变，在生产环境还是建议保持默认值，这样至少不会出现Topic被误删的情况。</li>
<li><code>log.flush.interval.messages</code>：该配置项最好保持默认值，把这个任务交给操作系统的文件系统去处理。</li>
<li><code>log.retention.hours</code>：日志文件保留的时间默认是168小时，既7天。这个配置可以根据具体业务需求而定。</li>
<li><code>message.max.bytes</code>：每条Message或一批次Message的大小默认是1MB。这个配置也要根据具体需求而定，比如带宽的情况。</li>
<li><code>min.insync.replicas</code>：该配置项的默认值是1，既在acks=all时，最少得有一个Replica进行确认回执。建议在生产环境配置为2，保证数据的完整性。</li>
<li><code>num.io.threads</code>：处理I/O操作的线程数，默认是8个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.network.threads</code>：处理网络请求和响应的线程数，默认是3个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。默认值是1，根据实际情况配置数据目录数，从而判断该配置项应该如何设置。</li>
<li><code>num.replica.fetchers</code>：该配置项影响Replicas同步数据的速度，默认值是1，如果发现Replicas同步延迟较大，可以提升该配置项。</li>
<li><code>offsets.retention.minutes</code>：Offset保留的时间，默认值是1440，既24小时。在生产环境建议将该配置项设大一点，比如设置为1个月，保证消费数据的完整性。</li>
<li><code>unclean.leader.election.enable</code>：该配置项的作用是，指定是否可以将非ISR的Replicas选举为Leader，默认值为<code>false</code>。在生产环境建议保持默认值，防止数据丢失。</li>
<li><code>zookeeper.session.timeout.ms</code>：Zookeeper会话超时时间，默认值为6000。按实际情况而定，通常情况下保持60秒即可。</li>
<li><code>default.replication.factor</code>：默认Replication Factor为1，建议设置为2或者3，以保证数据完整性和整个集群的健壮性。</li>
<li><code>num.partitions</code>：Topic默认的Partition数，默认是1，建议设置为3或者6，以保证数据完整性和整个集群的健壮性。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：搭建Kafka相关的UI工具]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-18/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-18/</id>
    <published>2019-03-31T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.115Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节主要介绍Zookeeper和Kafka的UI管理工具。</p>
<h3 id="ZKUI"><a href="#ZKUI" class="headerlink" title="ZKUI"></a>ZKUI</h3><p>ZKUI是一款简洁易用的Zookeeper信息管理工具。首先从<a href="https://github.com/DeemOpen/zkui" target="_blank" rel="external">Github</a>上克隆工程到本地，这是一个Maven工程，然后<code>mvn clean install</code>，在<code>target</code>目录下打出两个jar包<code>zkui-2.0-SNAPSHOT.jar</code>和<code>zkui-2.0-SNAPSHOT-jar-with-dependencies.jar</code>，将其上传至你的阿里云ECS。因为我们Zookeeper是集群模式，所以首先需要修改<code>config.cfg</code>中的Zookeeper地址：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Comma seperated list of all the zookeeper servers&#10;zkServer=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181</span><br></pre></td></tr></table></figure></p>
<p>然后运行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &#38;</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>成功后，访问<code>http://ECS外网IP:9090</code>即可，默认用户名密码是<code>admin/manager</code>。如果有需要可以自行在<code>config.cfg</code>文件中进行配置。</p>
<blockquote>
<p>注意：ZKUI需要JDK7以上的环境。</p>
</blockquote>
<p>然后登录ZKUI，可以看到如下界面：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576430353.png" alt=""></p>
<p>整个界面分为三部分：</p>
<ul>
<li>顶部一行是快捷操作，比如创建zNode、删除zNode、给zNode添加数据、每个Zookeeper Server的监控信息等。</li>
<li>左侧列出的是含有子zNode的zNode，所以文件夹作为icon。点击后会进入该zNode，整个界面以递归的方式展示。</li>
<li>右侧是不包含子zNode的zNode，所以直接展示zNode名称和存储的数据。</li>
</ul>
<p>从上图可以看到，左侧有名为<code>brokers</code>的zNode，点击进去后显示他的两个zNode，<code>ids</code>和<code>topics</code>：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576454552.png" alt=""></p>
<p>再点进<code>ids</code>可以看到，它还有三个子zNode，分别是Kafka集群中的三个Broker的信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576497231.png" alt=""></p>
<p>如果进入<code>topics</code>，可以看到它下面的子zNode都是我们之前创建的Topic，再进入每个Topic会看到Partition的zNode。充分展示了Zookeeper管理Kafka的方式。</p>
<p>ZKUI可以让我们方便直观的管理Zookeeper中的zNode，大大提高我们的工作效率。</p>
<h3 id="Kafka_Manager"><a href="#Kafka_Manager" class="headerlink" title="Kafka Manager"></a>Kafka Manager</h3><p>Kafka Manager是一款强大的Kafka集群监控工具。首先做一些准备工作：</p>
<ul>
<li>从<a href="https://github.com/yahoo/kafka-manager/releases" target="_blank" rel="external">Github</a>上下载<a href="https://github.com/yahoo/kafka-manager/releases" target="_blank" rel="external"> kafka-manager-1.3.3.22 </a>。</li>
<li><p>为了之后编译速度能快一些，先配置一下sbt的Maven仓库，连接到阿里云ECS，进入root用户目录，使用<code>mkdir .sbt</code>创建<code>.sbt</code>目录，进入该目录，使用<code>vim repositories</code>创建<code>repositories</code>文件，然后编辑如下内容：</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[repositories]&#10;local&#10;aliyun: http://maven.aliyun.com/nexus/content/groups/public&#10;typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly</span><br></pre></td></tr></table></figure>
</li>
<li><p>将<code>kafka-manager-1.3.3.22.zip</code>上传至ECS，解压后进入<code>kafka-manager</code>目录，执行如下命令：</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./sbt clean dist</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>需要等待一会，执行成功后，在<code>target/universal</code>目录下会产生一个<code>kafka-manager-1.3.3.7.zip</code>压缩文件，将其拷贝到要部署Kafka Manager的目录下，执行如下命令启动：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin/kafka-manager &#38;</span><br></pre></td></tr></table></figure></p>
<p>成功后，访问<code>http://ECS外网IP:9000</code>，即可看到Kafka Manager的界面了。如果有需要可以自行在<code>conf</code>目录下的<code>application.conf</code>文件中进行配置，比如端口号、Zookeeper的地址等。</p>
<blockquote>
<p>注意：Kafka Manager需要JDK8以上的环境。</p>
</blockquote>
<p>访问后，我们看到的是Kafka集群的列表列表，首先通过顶部的Add Cluster在Kafka Manager中创建Kafka集群：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576541891.png" alt=""><br>这里需要注意的有六项：</p>
<ul>
<li><code>My_Kafka_Cluster</code>：Kafka集群名称，这里随意输入。</li>
<li><code>Cluster Zookeeper Hosts</code>：Zookeeper Server的地址，如果是集群，则地址以逗号分割。</li>
<li><code>Kafka Version</code>：Kafka版本选择2.0.0。</li>
<li><code>brokerViewThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
<li><code>offsetCacheThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
<li><code>kafkaAdminClientThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
</ul>
<p>然后点击<strong>Save</strong>，Kafka Manager中的Kafka集群就创建好了。然后在Kafka Cluster列表页就能看到我们创建的集群了：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576561520.png" alt=""></p>
<p>点击进入后可以看到集群的基本信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576584316.png" alt=""><br>从上图可以看到，我们的Kafka集群中一共有6个Topic，3个Broker。点击进入Broker列表，可以看到Broker的基本信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576602212.png" alt=""></p>
<p>点击Broker ID可以进入Broker详细信息页面：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576624326.png" alt=""><br>可以看到这个Broker中都有哪些Topic，他们的Partition、ISR、Leader等信息。</p>
<p>我们再来看看Topic列表：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576651485.png" alt=""></p>
<p>从上图可以看到在列表中有一列是<strong>Brokers Spread %</strong>，只有2个Topic达到了100%，其他的都是33%，这是因为<code>my_topic_in_cluster</code>和<code>another_topic_in_cluster</code>这两个Topic是在Kafka集群中创建的，所以它们的Partitions和Replicas被均匀的分配到了三个Broker中。而其他的Topic都是在单机Kafka时创建的，所以他们的Partitions和Replicas都在一个Broker里。可见Kafka并不能自动改变之前已存在的Topic Partitions的分布情况。</p>
<p>我们点击进入之前创建的<code>my_topic_in_cluster</code>Topic看一下它的详情：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576670922.png" alt=""><br>从上图可以看到，从Kafka Manager中可以很清晰的看到Topic Partitions、ISR、Leader在Kafka集群中的分布情况。同时，也提供了对Topic的各种快捷操作，非常方便。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践搭建Zookeeper和Kafka的UI管理工具，通过可视化的视图以及方便的快捷操作能有效的监控Zookeeper和Kafka的状态以及大大提高生产效率。下一章节会对Kafka的重要配置和性能做一些探讨。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节主要介绍Zookeeper和Kafka的UI管理工具。</p>
<h3 id="ZKUI"><a href="#ZKUI" class="headerlink" title="ZKUI"></a>ZKUI</h3><p>ZKUI是一款简洁易用的Zookeeper信息管理工具。首先从<a href="https://github.com/DeemOpen/zkui">Github</a>上克隆工程到本地，这是一个Maven工程，然后<code>mvn clean install</code>，在<code>target</code>目录下打出两个jar包<code>zkui-2.0-SNAPSHOT.jar</code>和<code>zkui-2.0-SNAPSHOT-jar-with-dependencies.jar</code>，将其上传至你的阿里云ECS。因为我们Zookeeper是集群模式，所以首先需要修改<code>config.cfg</code>中的Zookeeper地址：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Comma seperated list of all the zookeeper servers&#10;zkServer=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181</span><br></pre></td></tr></table></figure></p>
<p>然后运行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &#38;</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：启动Kafka集群]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-17/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-17/</id>
    <published>2019-03-14T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.115Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节来真正启动Kafka集群，先给出一份Broker的配置项列表，将以下信息复制三份，分别配置三台阿里云ECS上的Broker配置文件：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;listener.security.protocol.map=EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT&#10;inter.broker.listener.name=INTERNAL&#10;advertised.listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;num.network.threads=3&#10;num.io.threads=8&#10;socket.send.buffer.bytes=102400&#10;socket.receive.buffer.bytes=102400&#10;socket.request.max.bytes=104857600&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;offsets.topic.replication.factor=2&#10;transaction.state.log.replication.factor=1&#10;transaction.state.log.min.isr=1&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>以上列表有两点需要修改的地方：</p>
<ul>
<li><code>broker.id</code>需要修改，不同Broker的ID不能相同。</li>
<li>阿里云ECS的内/外网IP需要配置正确。</li>
</ul>
<p>然后使用如下命令分别启动Kafka Broker：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka_2.12-2.0.0/bin/kafka-server-start.sh kafka_2.12-2.0.0/config/server.properties &#38;</span><br></pre></td></tr></table></figure></p>
<p>三个Broker没有异常信息，大概率说明我们的Kafka集群部署成功了，下面来验证一下。首先我们创建一个Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka_2.12-2.0.0/bin sh kafka-topics.sh --zookeeper zookeeper.server.1:2181 --topic my_topic_in_cluster --create --partitions 3 --replication-factor 2</span><br></pre></td></tr></table></figure></p>
<p>上面的命令有这样几个信息：</p>
<ul>
<li>连接Zookeeper时，连Zookeeper集群中的任意一个Zookeeper即可。</li>
<li>创建的Topic<code>my_topic_in_cluster</code>有三个Partition，每个Partition有两个Replica，也就是每条发送到这个Topic的Message会保存六份。</li>
</ul>
<p>如果Kafka集群是成功的，那么理论上这六个Partition会被两两均匀分配到三个Broker中。</p>
<p>连接到部署Broker-0的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;__consumer_offsets-0   __consumer_offsets-3   __consumer_offsets-6&#10;__consumer_offsets-1   __consumer_offsets-30  __consumer_offsets-7&#10;__consumer_offsets-10  __consumer_offsets-31  __consumer_offsets-8&#10;__consumer_offsets-11  __consumer_offsets-32  __consumer_offsets-9&#10;__consumer_offsets-12  __consumer_offsets-33  &#10;__consumer_offsets-13  __consumer_offsets-34  &#10;__consumer_offsets-14  __consumer_offsets-35  &#10;__consumer_offsets-15  __consumer_offsets-36  cleaner-offset-checkpoint&#10;__consumer_offsets-16  __consumer_offsets-37  configured-topic-0&#10;__consumer_offsets-17  __consumer_offsets-38  configured-topic-1&#10;__consumer_offsets-18  __consumer_offsets-39  configured-topic-2&#10;__consumer_offsets-19  __consumer_offsets-4   first_topic-0&#10;__consumer_offsets-2   __consumer_offsets-40  first_topic-1&#10;__consumer_offsets-20  __consumer_offsets-41  first_topic-2&#10;__consumer_offsets-21  __consumer_offsets-42  log-start-offset-checkpoint&#10;__consumer_offsets-22  __consumer_offsets-43  meta.properties&#10;__consumer_offsets-23  __consumer_offsets-44  my_topic_in_cluster-0&#10;__consumer_offsets-24  __consumer_offsets-45  my_topic_in_cluster-2&#10;__consumer_offsets-25  __consumer_offsets-46  recovery-point-offset-checkpoint&#10;__consumer_offsets-26  __consumer_offsets-47  replication-offset-checkpoint&#10;__consumer_offsets-27  __consumer_offsets-48  with_keys_topic-0&#10;__consumer_offsets-28  __consumer_offsets-49  with_keys_topic-1&#10;__consumer_offsets-29  __consumer_offsets-5   with_keys_topic-2</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-0中分配了<code>my_topic_in_cluster</code>的Partition-0和Partition-2。</p>
<p>同理，连接到部署Broker-1的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;meta.properties   my_topic_in_cluster-0&#10;my_topic_in_cluster-1   cleaner-offset-checkpoint    &#10;recovery-point-offset-checkpoint  log-start-offset-checkpoint &#10;replication-offset-checkpoint</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-1中分配了<code>my_topic_in_cluster</code>的Partition-0和Partition-1。</p>
<p>同理，连接到部署Broker-2的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;meta.properties   my_topic_in_cluster-1&#10;my_topic_in_cluster-2   cleaner-offset-checkpoint    &#10;recovery-point-offset-checkpoint  log-start-offset-checkpoint &#10;replication-offset-checkpoint</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-2中分配了<code>my_topic_in_cluster</code>的Partition-1和Partition-2。</p>
<p>从上面的结果可以说明我们的Kafka集群是部署成功的。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践运行Kafka集群，通过查看每个Broker的Data目录印证之前章节对Partition介绍的内容。下一章节会带大家搭建管理Zookeeper和Kafka的UI工具。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节来真正启动Kafka集群，先给出一份Broker的配置项列表，将以下信息复制三份，分别配置三台阿里云ECS上的Broker配置文件：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;listener.security.protocol.map=EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT&#10;inter.broker.listener.name=INTERNAL&#10;advertised.listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;num.network.threads=3&#10;num.io.threads=8&#10;socket.send.buffer.bytes=102400&#10;socket.receive.buffer.bytes=102400&#10;socket.request.max.bytes=104857600&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;offsets.topic.replication.factor=2&#10;transaction.state.log.replication.factor=1&#10;transaction.state.log.min.isr=1&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：Kafka Listeners]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-16/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-16/</id>
    <published>2019-02-28T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.115Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节主要对和Listener相关的四个配置项做以详细解释。<code>listeners</code>、<code>advertised.listeners</code>、<code>listener.security.protocol.map</code>、<code>inter.broker.listener.name</code>这四个配置项可能是大家最容易混淆和最不容易理解的。</p>
<p>在解释这些配置项之前，我们先来明确几个概念。</p>
<ul>
<li>部署Broker的阿里云ECS称为Host Machine。</li>
<li>在阿里云ECS里启动的Producer或者Consumer，比如使用Kafka CLI启动的称为Internal Client。</li>
<li>在大家的IDEA中使用Java编写的，或者第三方的Producer/Consumer，称为External Client。</li>
<li>Host Machine具有外网IP和内网IP。</li>
<li>Internal Client可以同时和Host Machine的外网IP及内网IP通信。</li>
<li>External Client只能和Host Machine的外网IP通信。</li>
<li>多个阿里云ECS之间可以同时通过外网IP及内网IP通信。<ul>
<li>既在这个特定的场景下，Host Machine之间可以同时通过外网IP及内网IP通信。</li>
<li>再换句话说就是不同Host Machine上的Broker之间可以同时通过外网IP及内网IP通信。</li>
</ul>
</li>
</ul>
<a id="more"></a>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576212167.png" alt=""></p>
<p>如上图所示，是一个很常见的Kafka集群场景，涵盖了上述的概念。图中那些通信虚线箭头就是靠Kafka的Listener建立的，并且是通过Kafka中不同的Listener建立的，这些Listener分为Internal Listener和External Listener。如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576272952.png" alt=""></p>
<p>那么这些Listener的创建以及内外部如何通信都是由上面那四个配置项决定的。</p>
<h3 id="listener-security-protocol-map"><a href="#listener-security-protocol-map" class="headerlink" title="listener.security.protocol.map"></a>listener.security.protocol.map</h3><p>先来看<code>listener.security.protocol.map</code>配置项，在上一章节中介绍过，它是配置监听者的安全协议的，比如<code>PLAINTEXT</code>、<code>SSL</code>、<code>SASL_PLAINTEXT</code>、<code>SASL_SSL</code>。因为它是以Key/Value的形式配置的，所以往往我们也使用该参数给Listener命名：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">listener.security.protocol.map=EXTERNAL_LISTENER_CLIENTS:SSL,INTERNAL_LISTENER_CLIENTS:PLAINTEXT,INTERNAL_LISTENER_BROKER:PLAINTEXT</span><br></pre></td></tr></table></figure></p>
<p>使用Key作为Listener的名称。就如上图所示，Internal Producer、External Producer、Internal Consumer、External Consumer和Broker通信以及Broker之间互相通信时都很有可能使用不同的Listener。这些不同的Listener有监听内网IP的，有监听外网IP的，还有不同安全协议的，所以使用Key来表示更加直观。当然这只是一种非官方的用法，Key本质上还是代表了安全协议，如果只有一个安全协议，多个Listener的话，那么这些Listener所谓的名称肯定都是相同的。</p>
<h3 id="listeners"><a href="#listeners" class="headerlink" title="listeners"></a>listeners</h3><p><code>listeners</code>就是主要用来定义Kafka Broker的Listener的配置项。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">listeners=EXTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093,INTERNAL_LISTENER_BROKER://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9094</span><br></pre></td></tr></table></figure></p>
<p>上面的配置表示，这个Broker定义了三个Listener，一个External Listener，用于External Producer和External Consumer连接使用。也许因为业务场景的关系，Internal Producer和Broker之间使用不同的安全协议进行连接，所以定义了两个不同协议的Internal Listener，分别用于Internal Producer和Broker之间连接使用。</p>
<p>通过之前的章节，我们知道Kafka是由Zookeeper进行管理的，由Zookeeper负责Leader选举，Broker Rebalance等工作。所以External Producer和External Consumer其实是通过Zookeeper中提供的信息和Broker通信交互的。所以<code>listeners</code>中配置的信息都会发布到Zookeeper中，但是这样就会把Broker的所有Listener信息都暴露给了外部Clients，在安全上是存在隐患的，我们希望只把给外部Clients使用的Listener暴露出去，此时就需要用到下面这个配置项了。</p>
<h3 id="advertised-listeners"><a href="#advertised-listeners" class="headerlink" title="advertised.listeners"></a>advertised.listeners</h3><p><code>advertised.listeners</code>参数的作用就是将Broker的Listener信息发布到Zookeeper中，供Clients（Producer/Consumer）使用。如果配置了<code>advertised.listeners</code>，那么就不会将<code>listeners</code>配置的信息发布到Zookeeper中去了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">advertised.listeners=EXTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092</span><br></pre></td></tr></table></figure></p>
<p>这里在Zookeeper中发布了供External Clients（Producer/Consumer）使用的Listener<code>EXTERNAL_LISTENER_CLIENTS</code>。所以<code>advertised.listeners</code>配置项实现了只把给外部Clients使用的Listener暴露出去的需求。</p>
<h3 id="inter-broker-listener-name"><a href="#inter-broker-listener-name" class="headerlink" title="inter.broker.listener.name"></a>inter.broker.listener.name</h3><p>这个配置项从名称就可以看出它的作用了，就是指定一个<code>listener.security.protocol.map</code>配置项中配置的Key，或者说指定一个或一类Listener的名称，将它作为Internal Listener。这个Listener<strong>专门用于Kafka集群中Broker之间的通信</strong>：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">inter.broker.listener.name=INTERNAL_LISTENER_BROKER</span><br></pre></td></tr></table></figure></p>
<h3 id="listener__u548C_advertised-listeners__u7684_u5173_u7CFB"><a href="#listener__u548C_advertised-listeners__u7684_u5173_u7CFB" class="headerlink" title="listener 和 advertised.listeners 的关系"></a>listener 和 advertised.listeners 的关系</h3><p>先来看看<code>KafkaConfig.scala</code>和<code>SocketServer.scala</code>源码中的这几行代码片段：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// KafkaConfig.scala</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> <span class="type">ListenersProp</span> = <span class="string">"listeners"</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dataPlaneListeners</span>:</span> <span class="type">Seq</span>[<span class="type">EndPoint</span>] = &#123;</span><br><span class="line">    <span class="type">Option</span>(getString(<span class="type">KafkaConfig</span>.<span class="type">ControlPlaneListenerNameProp</span>)) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(controlPlaneListenerName) =&gt; listeners.filterNot(_.listenerName.value() == controlPlaneListenerName)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; listeners</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">listeners</span>:</span> <span class="type">Seq</span>[<span class="type">EndPoint</span>] = &#123;</span><br><span class="line">    <span class="type">Option</span>(getString(<span class="type">KafkaConfig</span>.<span class="type">ListenersProp</span>)).map &#123; listenerProp =&gt;</span><br><span class="line">      <span class="type">CoreUtils</span>.listenerListToEndPoints(listenerProp, listenerSecurityProtocolMap)</span><br><span class="line">    &#125;.getOrElse(<span class="type">CoreUtils</span>.listenerListToEndPoints(<span class="string">"PLAINTEXT://"</span> + hostName + <span class="string">":"</span> + port, listenerSecurityProtocolMap))</span><br><span class="line">  &#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment">// SocketServer.scala</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">startup</span>(</span>startupProcessors: <span class="type">Boolean</span> = <span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">      connectionQuotas = <span class="keyword">new</span> <span class="type">ConnectionQuotas</span>(config.maxConnectionsPerIp, config.maxConnectionsPerIpOverrides)</span><br><span class="line">      createControlPlaneAcceptorAndProcessor(config.controlPlaneListener)</span><br><span class="line">      createDataPlaneAcceptorsAndProcessors(config.numNetworkThreads, config.dataPlaneListeners)</span><br><span class="line">      <span class="keyword">if</span> (startupProcessors) &#123;</span><br><span class="line">        startControlPlaneProcessor()</span><br><span class="line">        startDataPlaneProcessors()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createDataPlaneAcceptorsAndProcessors</span>(</span>dataProcessorsPerListener: <span class="type">Int</span>,</span><br><span class="line">                                                    endpoints: <span class="type">Seq</span>[<span class="type">EndPoint</span>]): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">    endpoints.foreach &#123; endpoint =&gt;</span><br><span class="line">      <span class="keyword">val</span> dataPlaneAcceptor = createAcceptor(endpoint)</span><br><span class="line">      addDataPlaneProcessors(dataPlaneAcceptor, endpoint, dataProcessorsPerListener)</span><br><span class="line">      <span class="type">KafkaThread</span>.nonDaemon(s<span class="string">"data-plane-kafka-socket-acceptor-$&#123;endpoint.listenerName&#125;-$&#123;endpoint.securityProtocol&#125;-$&#123;endpoint.port&#125;"</span>, dataPlaneAcceptor).start()</span><br><span class="line">      dataPlaneAcceptor.awaitStartup()</span><br><span class="line">      dataPlaneAcceptors.put(endpoint, dataPlaneAcceptor)</span><br><span class="line">      info(s<span class="string">"Created data-plane acceptor and processors for endpoint : $endpoint"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p><code>startup()</code>方法是Kafka Broker创建启动Socket连接的入口，既用来创建Acceptor线程的入口，该线程负责处理Socket连接。 <code>createDataPlaneAcceptorsAndProcessors()</code>方法的第二个参数<code>config.dataPlaneListeners</code>可以看到取的就是<code>listeners</code>配置项的内容。 </p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line">* Create a server socket to listen for connections on.</span><br><span class="line">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">openServerSocket</span>(</span>host: <span class="type">String</span>, port: <span class="type">Int</span>): <span class="type">ServerSocketChannel</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> socketAddress =</span><br><span class="line">    <span class="keyword">if</span> (host == <span class="literal">null</span> || host.trim.isEmpty)</span><br><span class="line">      <span class="keyword">new</span> <span class="type">InetSocketAddress</span>(port)</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">new</span> <span class="type">InetSocketAddress</span>(host, port)</span><br><span class="line">  <span class="keyword">val</span> serverChannel = <span class="type">ServerSocketChannel</span>.open()</span><br><span class="line">  serverChannel.configureBlocking(<span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">if</span> (recvBufferSize != <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>)</span><br><span class="line">    serverChannel.socket().setReceiveBufferSize(recvBufferSize)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    serverChannel.socket.bind(socketAddress)</span><br><span class="line">    info(<span class="string">"Awaiting socket connections on %s:%d."</span>.format(socketAddress.getHostString, serverChannel.socket.getLocalPort))</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">SocketException</span> =&gt;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Socket server failed to bind to %s:%d: %s."</span>.format(socketAddress.getHostString, port, e.getMessage), e)</span><br><span class="line">  &#125;</span><br><span class="line">  serverChannel</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>跟到里面，可以看到如果没有配置<code>listeners</code>，那么会使用网卡地址创建Socket连接，对于阿里云ECS，就是内网IP。</p>
<p>再来看看<code>KafkaServer.scala</code>源码中的这几行代码片段：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> brokerInfo = createBrokerInfo</span><br><span class="line"><span class="keyword">val</span> brokerEpoch = zkClient.registerBroker(brokerInfo)</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[server] <span class="function"><span class="keyword">def</span> <span class="title">createBrokerInfo</span>:</span> <span class="type">BrokerInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> endPoints = config.advertisedListeners.map(e =&gt; s<span class="string">"$&#123;e.host&#125;:$&#123;e.port&#125;"</span>)</span><br><span class="line">    zkClient.getAllBrokersInCluster.filter(_.id != config.brokerId).foreach &#123; broker =&gt;</span><br><span class="line">      <span class="keyword">val</span> commonEndPoints = broker.endPoints.map(e =&gt; s<span class="string">"$&#123;e.host&#125;:$&#123;e.port&#125;"</span>).intersect(endPoints)</span><br><span class="line">      require(commonEndPoints.isEmpty, s<span class="string">"Configured end points $&#123;commonEndPoints.mkString("</span>,<span class="string">")&#125; in"</span> +</span><br><span class="line">        s<span class="string">" advertised listeners are already registered by broker $&#123;broker.id&#125;"</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> listeners = config.advertisedListeners.map &#123; endpoint =&gt;</span><br><span class="line">      <span class="keyword">if</span> (endpoint.port == <span class="number">0</span>)</span><br><span class="line">        endpoint.copy(port = socketServer.boundPort(endpoint.listenerName))</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        endpoint</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> updatedEndpoints = listeners.map(endpoint =&gt;</span><br><span class="line">      <span class="keyword">if</span> (endpoint.host == <span class="literal">null</span> || endpoint.host.trim.isEmpty)</span><br><span class="line">        endpoint.copy(host = <span class="type">InetAddress</span>.getLocalHost.getCanonicalHostName)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        endpoint</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> jmxPort = <span class="type">System</span>.getProperty(<span class="string">"com.sun.management.jmxremote.port"</span>, <span class="string">"-1"</span>).toInt</span><br><span class="line">    <span class="type">BrokerInfo</span>(<span class="type">Broker</span>(config.brokerId, updatedEndpoints, config.rack), config.interBrokerProtocolVersion, jmxPort)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>从上面的代码可以看到，<code>advertised.listeners</code>主要用于向Zookeeper注册Broker的连接信息，但是不参与创建Socket连接。</p>
<p>所以从这几处源码内容可以得出结论，Kafka Broker真正建立通信连接使用的是<code>listeners</code>配置项里的内容，而<code>advertised.listeners</code>只用于向Zookeeper注册Broker的连接信息，既向Client暴露Broker对外的连接信息（Endpoint）。</p>
<p>另外在<code>KafkaConfig.scala</code>源码中还有有这么几行代码：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> advertisedListenerNames = advertisedListeners.map(_.listenerName).toSet</span><br><span class="line"><span class="keyword">val</span> listenerNames = listeners.map(_.listenerName).toSet</span><br><span class="line"></span><br><span class="line">require(advertisedListenerNames.contains(interBrokerListenerName),</span><br><span class="line">      s<span class="string">"$&#123;KafkaConfig.InterBrokerListenerNameProp&#125; must be a listener name defined in $&#123;KafkaConfig.AdvertisedListenersProp&#125;. "</span> +</span><br><span class="line">      s<span class="string">"The valid options based on currently configured listeners are $&#123;advertisedListenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line">require(advertisedListenerNames.subsetOf(listenerNames),</span><br><span class="line">      s<span class="string">"$&#123;KafkaConfig.AdvertisedListenersProp&#125; listener names must be equal to or a subset of the ones defined in $&#123;KafkaConfig.ListenersProp&#125;. "</span> +</span><br><span class="line">      s<span class="string">"Found $&#123;advertisedListenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;. The valid options based on the current configuration "</span> +</span><br><span class="line">      s<span class="string">"are $&#123;listenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;"</span></span><br></pre></td></tr></table></figure></p>
<p>从上面的代码片段可以得出两个结论：</p>
<ul>
<li><code>advertised.listeners</code>配置项中配置的Listener名称或者说安全协议必须在<code>listeners</code>中存在。因为真正创建连接的是<code>listeners</code>中的信息。</li>
<li><code>inter.broker.listener.name</code>配置项中配置的Listener名称或者说安全协议必须在<code>advertised.listeners</code>中存在。因为Broker之间也是要通过<code>advertised.listeners</code>配置项获取Internal Listener信息的。</li>
</ul>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节主要大家详细解释了Broker几个比较容易混淆和不好理解的配置项，解释了什么是内外部Listener，如何暴露Listener等。这些配置在我们搭建Kafka集群时至关重要。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节主要对和Listener相关的四个配置项做以详细解释。<code>listeners</code>、<code>advertised.listeners</code>、<code>listener.security.protocol.map</code>、<code>inter.broker.listener.name</code>这四个配置项可能是大家最容易混淆和最不容易理解的。</p>
<p>在解释这些配置项之前，我们先来明确几个概念。</p>
<ul>
<li>部署Broker的阿里云ECS称为Host Machine。</li>
<li>在阿里云ECS里启动的Producer或者Consumer，比如使用Kafka CLI启动的称为Internal Client。</li>
<li>在大家的IDEA中使用Java编写的，或者第三方的Producer/Consumer，称为External Client。</li>
<li>Host Machine具有外网IP和内网IP。</li>
<li>Internal Client可以同时和Host Machine的外网IP及内网IP通信。</li>
<li>External Client只能和Host Machine的外网IP通信。</li>
<li>多个阿里云ECS之间可以同时通过外网IP及内网IP通信。<ul>
<li>既在这个特定的场景下，Host Machine之间可以同时通过外网IP及内网IP通信。</li>
<li>再换句话说就是不同Host Machine上的Broker之间可以同时通过外网IP及内网IP通信。</li>
</ul>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：配置Broker]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-15/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-15/</id>
    <published>2019-02-19T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.115Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>接下来几个章节我们开始搭建真正的Kafka集群，服务器还是使用上一节章节搭建Zookeeper使用的三台阿里云ECS。</p>
<p>在<strong>搭建单机Kafka</strong>章节中，在Kafka的<code>/root/kafka_2.12-2.0.0/config/server.properties</code>配置文件中，我们只配置了<code>log.dirs</code>和<code>advertised.listeners</code>这两个配置项，其他配置项都是使用默认值。</p>
<p>Kafka的配置项一共多达140余个，虽然有一部分通常情况下我们不需要修改，使用默认值即可，<strong>但这只是一少部分</strong>。搭建Kafka集群时，光通常情况下需要考虑的配置项就有40余个。</p>
<p>另外，这些配置项要根据具体的业务场景做各种调整，不存在一套配置项通吃所有业务场景的情况，而且基本不可能一次性配置出性能最优、最能满足业务场景的配置项组合，都需要经过调整、测试，反复进行配置才能总结出相对最优的配置项组合。</p>
<a id="more"></a>
<h2 id="Broker_u914D_u7F6E"><a href="#Broker_u914D_u7F6E" class="headerlink" title="Broker配置"></a>Broker配置</h2><p>先展示一份Broker的配置内容（<code>/root/kafka_2.12-2.0.0/config/server.properties</code>），这里给出的是一个平铺的配置项列表，有一些配置项已经作废，有一些配置项之间有会有相互影响：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;# DEPRECATED&#10;host.name=&#38463;&#37324;&#20113;ECS IP&#10;# DEPRECATED&#10;port=9092&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=PLAINTEXT://&#38463;&#37324;&#20113;ECS IP:9092&#10;listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL&#10;advertised.listeners=PLAINTEXT://&#38463;&#37324;&#20113;ECS IP:9092&#10;inter.broker.listener.name=PLAINTEXT&#10;num.network.threads=3&#10;num.io.threads=8&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>
<p>我们逐一了解上面这些配置项：</p>
<h3 id="Broker_Server_u57FA_u7840_u914D_u7F6E"><a href="#Broker_Server_u57FA_u7840_u914D_u7F6E" class="headerlink" title="Broker Server基础配置"></a>Broker Server基础配置</h3><p>Broker Server的基础配置涉及到四个配置项：</p>
<ul>
<li><code>broker.id</code>：整个Kafka集群内标识唯一Broker的ID。整数类型。</li>
<li><code>host.name</code>：部署Broker的服务器IP地址或者域名。该参数已作废。</li>
<li><code>port</code>：Broker开放的端口号。该参数已作废。</li>
<li><code>delete.topic.enable</code>：是否允许删除Topic。</li>
<li><code>auto.create.topics.enable</code>：是否允许在Producer在未指定Topic发送Message时自动创建Topic。</li>
</ul>
<h3 id="Socket_Server_u914D_u7F6E"><a href="#Socket_Server_u914D_u7F6E" class="headerlink" title="Socket Server配置"></a>Socket Server配置</h3><p>传输通信方面的配置涉及到六个配置项：</p>
<ul>
<li><code>listeners</code>：Broker之间，Client与Broker之间通信建立连接时使用的信息。既Broker的监听者，可以以逗号分割配置多个。它的格式为<code>[安全协议]://Hostname/IP:Port</code>。</li>
<li><p><code>listener.security.protocol.map</code>：以Key/Value的形式定义监听者的安全协议，在大多数情况下会将Key认为是监听者的别名。所以会这样设置：</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listeners=LISTENER_BOB://阿里云ECS IP1:<span class="number">9092</span>,LISTENER_JOHN://阿里云ECS IP2:<span class="number">9092</span></span><br><span class="line">listener.security.protocol.map=LISTENER_BOB:PLAINTEXT,LISTENER_JOHN:SSL</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>advertised.listeners</code>：将Broker建立通信的地址发布到Zookeeper中，便于Client（Producer和Consumer）连接。它的格式和<code>listener</code>一致。</p>
</li>
<li><code>inter.broker.listener.name</code>：设置内部通信时使用哪个监听者。可以直接设置<code>listener.security.protocol.map</code>中设置的Key。</li>
<li><code>num.network.threads</code>：Broker Server接收请求及发送响应时启用的线程数量。</li>
<li><code>num.io.threads</code>：Broker Server处理请求、对Message进行I/O操作时启用的线程数。</li>
</ul>
<p>和监听者相关的四个配置项，在下一章节会做详细解释。</p>
<h3 id="u65E5_u5FD7_u57FA_u7840_u914D_u7F6E"><a href="#u65E5_u5FD7_u57FA_u7840_u914D_u7F6E" class="headerlink" title="日志基础配置"></a>日志基础配置</h3><p>Broker Server处理日志的基础配置涉及到五个配置项：</p>
<ul>
<li><code>log.dirs</code>：日志、Message保存的路径。</li>
<li><code>num.partitions</code>：创建Topic时，如果没有指定Partition数量，则使用该配置项设置的Partition数量。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。</li>
<li><code>default.replication.factor</code>：创建Topic时，如果没有指定Partition的Replication Factor数，则使用该配置项设置的Replication Factor数。</li>
<li><code>min.insync.replicas</code>：当<code>acks=all</code>时，至少有多少个Replicas需要确认已持久化数据，包括Leader。</li>
</ul>
<h3 id="u65E5_u5FD7_u4FDD_u7559_u7B56_u7565_u914D_u7F6E"><a href="#u65E5_u5FD7_u4FDD_u7559_u7B56_u7565_u914D_u7F6E" class="headerlink" title="日志保留策略配置"></a>日志保留策略配置</h3><p>Broker Server处理日志保留问题的配置涉及到四个配置项：</p>
<ul>
<li><code>log.retention.hours</code>：Kafka保留Message的时间，默认是168小时，既7天。</li>
<li><code>log.segment.bytes</code>：每个Segment文件的大小，默认是1G。</li>
<li><code>log.retention.check.interval.ms</code>：检测Message是否可以被删除的时间间隔。</li>
<li><code>log.segment.ms</code>：Segment文件关闭的时间。</li>
</ul>
<h3 id="Zookeeper_u76F8_u5173_u914D_u7F6E"><a href="#Zookeeper_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Zookeeper相关配置"></a>Zookeeper相关配置</h3><p>Zookeeper的相关配置涉及到两个配置项：</p>
<ul>
<li><code>zookeeper.connect</code>：设置Zookeeper地址。可用逗号分割配置多个地址，既Zookeeper集群的地址。</li>
<li><code>zookeeper.connection.timeout.ms</code>：等待连接Zookeeper的超时时间。</li>
</ul>
<h3 id="Consumer_Group_u76F8_u5173_u914D_u7F6E"><a href="#Consumer_Group_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Consumer Group相关配置"></a>Consumer Group相关配置</h3><p>Consumer Group相关的配置主要涉及到一个配置项：</p>
<ul>
<li><code>group.initial.rebalance.delay.ms</code>：当Consumer Group新增或减少Consumer时，重新分配Topic Partition的延迟时间。</li>
</ul>
<h3 id="Message_u76F8_u5173_u914D_u7F6E"><a href="#Message_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Message相关配置"></a>Message相关配置</h3><p>Message相关配置涉及到两个配置项：</p>
<ul>
<li><code>message.max.bytes</code>：Broker接收每条Message的最大值，默认是1M。</li>
<li><code>fetch.message.max.bytes</code>：Consumer每次获取Message的大小。</li>
</ul>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节给大家介绍了Broker的详细配置，为搭建Kafka集群做好充分准备。下一章节会对大家比较不容易理解的Listener配置做详细介绍。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>接下来几个章节我们开始搭建真正的Kafka集群，服务器还是使用上一节章节搭建Zookeeper使用的三台阿里云ECS。</p>
<p>在<strong>搭建单机Kafka</strong>章节中，在Kafka的<code>/root/kafka_2.12-2.0.0/config/server.properties</code>配置文件中，我们只配置了<code>log.dirs</code>和<code>advertised.listeners</code>这两个配置项，其他配置项都是使用默认值。</p>
<p>Kafka的配置项一共多达140余个，虽然有一部分通常情况下我们不需要修改，使用默认值即可，<strong>但这只是一少部分</strong>。搭建Kafka集群时，光通常情况下需要考虑的配置项就有40余个。</p>
<p>另外，这些配置项要根据具体的业务场景做各种调整，不存在一套配置项通吃所有业务场景的情况，而且基本不可能一次性配置出性能最优、最能满足业务场景的配置项组合，都需要经过调整、测试，反复进行配置才能总结出相对最优的配置项组合。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：搭建Zookeeper集群]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-14/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-14/</id>
    <published>2019-02-09T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.115Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来真正搭建一个Zookeeper集群。</p>
<h2 id="u642D_u5EFAZookeeper_u96C6_u7FA4"><a href="#u642D_u5EFAZookeeper_u96C6_u7FA4" class="headerlink" title="搭建Zookeeper集群"></a>搭建Zookeeper集群</h2><p>首先要做的就是再租赁两个服务器，参照<strong>搭建单机Kafka</strong>章节中的步骤，租赁阿里云服务器、安装JDK、下载配置Kafka、配置安全组规则。</p>
<h3 id="Zookeeper_u914D_u7F6E_u4FE1_u606F"><a href="#Zookeeper_u914D_u7F6E_u4FE1_u606F" class="headerlink" title="Zookeeper配置信息"></a>Zookeeper配置信息</h3><p>在<strong>搭建单机Kafka</strong>章节中，启动的是单机Zookeeper，所以<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件中只配置了<code>dataDir</code>，也就是存储各种数据、日志、快照的路径。</p>
<p>在搭建Zookeeper时，就需要额外再配置一些参数了。同样打开<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件，额外添加如下内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>逐一解释一下这些配置信息：</p>
<ul>
<li><code>maxClientCnxns</code>：该参数表示允许客户端最大连接数。如果设置为0则表示不做限制。</li>
<li><code>tickTime</code>：该参数表示Zookeeper服务之间进行心跳监测的间隔时间，单位是毫秒。设置为2000，表示每隔2秒，Zookeeper服务器之间会进行一次心跳监测。</li>
<li><code>initLimit</code>：该参数表示Zookeeper集群中的Follower在启动时需要在多少个心跳时间内从Leader同步数据。设置为10，表示要在10个心跳时间内，也就是在20秒内，要完成Leader数据的同步。</li>
<li><code>syncLimit</code>：该参数表示超过多少个心跳时间收不到Follower的响应，Leader就认为此Follower已经下线。设置为5，表示在5个心跳时间内，也就是判断Follower是否存活的响应时间是10秒。</li>
</ul>
<h3 id="Zookeeper_u96C6_u7FA4_u8282_u70B9_u5217_u8868"><a href="#Zookeeper_u96C6_u7FA4_u8282_u70B9_u5217_u8868" class="headerlink" title="Zookeeper集群节点列表"></a>Zookeeper集群节点列表</h3><p>首先节点列表的配置规则为<code>server.N=IP:Port1:Port2</code>：</p>
<ul>
<li><code>N</code>表示Zookeeper节点编号。</li>
<li><code>IP</code>表示Zookeeper节点的服务器IP，既阿里云ECS的外网IP。</li>
<li><code>Port1</code>表示该Zookeeper集群中的Follower节点与Leader节点通讯时使用的端口。作为Leader时监听该端口。</li>
<li><code>Port2</code>表示选举新的Leader时，Zookeeper节点之间互相通信的端口，比如当Leader挂掉时，其余服务器会互相通信，选出新的Leader。Leader和Follower都会监听该端口。</li>
</ul>
<p>这里的节点编号是数字类型，需要我们在<code>/root/kafka_2.12-2.0.0/data/zookeeper</code>目录下创建名为<code>myid</code>的文件，然后将编号配置在里面。<code>server.N</code>这里的<code>N</code>要和<code>myid</code>文件中配置的编号保持一致。</p>
<p>另外还需要注意的是，如果要在一台服务器上搭建伪集群，那么每个<code>Port1</code>和每个<code>Port2</code>要不一样才可以，因为<code>IP</code>都是一样的。这里我们是分别用三台不同的阿里云ECS，所以<code>IP</code>肯定是不一样的，而每个<code>Port1</code>是一致的，每个<code>Port2</code>也是一致的。</p>
<p>为了方便起见，我们可以在服务器的<code>/etc/hosts</code>文件中设置一下域名映射，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&#38463;&#37324;&#20113;ECS-1 IP] zookeeper.server.1&#10;[&#38463;&#37324;&#20113;ECS-2 IP] zookeeper.server.2&#10;[&#38463;&#37324;&#20113;ECS-3 IP] zookeeper.server.3</span><br></pre></td></tr></table></figure></p>
<p>这样在配置Zookeeper集群节点列表时就可以写成如下形式了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>
<h3 id="u963F_u91CC_u4E91ECS_u670D_u52A1_u76D1_u542C_u6240_u6709_u7F51_u5361"><a href="#u963F_u91CC_u4E91ECS_u670D_u52A1_u76D1_u542C_u6240_u6709_u7F51_u5361" class="headerlink" title="阿里云ECS服务监听所有网卡"></a>阿里云ECS服务监听所有网卡</h3><p>如果现在通过<code>/root/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh config/zookeeper.properties</code>启动Zookeeper，肯定会报一大堆错误，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[myid:0] - WARN  [WorkerSender[myid=0]:QuorumCnxManager@588] - Cannot open channel to 1 at election address /zookeeper.server.1:3888&#10;java.net.ConnectException: Connection refused&#10;&#160; &#160; &#160; &#160; at java.net.PlainSocketImpl.socketConnect(Native Method)&#10;&#160; &#160; &#160; &#160; at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)&#10;.......</span><br></pre></td></tr></table></figure></p>
<p>这是因为阿里云ECS都是采用虚拟化技术创建的服务器实例，而虚拟机中并没有物理网卡，所以Zookeeper服务启动后，进程并没有监听到<code>3888</code>端口，而是会随机生成一个端口进行监听。所以会报上面的错。解决的办法就是让Zookeeper服务进程监听<code>0.0.0.0</code>的IP地址，也就是监听所有网卡。那么就需要在<code>zookeeper.properties</code>配置文件加入<code>quorumListenOnAllIPs=true</code>配置信息，来保证Zookeeper服务进程能监听到我们设定的<code>3888</code>端口。</p>
<h3 id="Zookeeper_u96C6_u7FA4_u914D_u7F6E_u603B_u7ED3"><a href="#Zookeeper_u96C6_u7FA4_u914D_u7F6E_u603B_u7ED3" class="headerlink" title="Zookeeper集群配置总结"></a>Zookeeper集群配置总结</h3><p>在启动Zookeeper集群前，先来总结一下配置工作：</p>
<ul>
<li>租赁三台阿里云ECS，下载JDK、Kafka、配置安全组规则。</li>
<li>在<code>/root/kafka_2.12-2.0.0/data/zookeeper</code>目录下创建名为<code>myid</code>的文件，配置Zookeeper节点编号。</li>
<li>在服务器的<code>/etc/hosts</code>文件中设置一下域名映射：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&#38463;&#37324;&#20113;ECS-1 IP] zookeeper.server.1&#10;[&#38463;&#37324;&#20113;ECS-2 IP] zookeeper.server.2&#10;[&#38463;&#37324;&#20113;ECS-3 IP] zookeeper.server.3</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>在<code>/root/kafka_2.12-2.0.0/config/zookeeper.properties</code>配置文件中添加如下配置（<code>server.N</code>中的<code>N</code>要和<code>myid</code>中配置的节点编号保持一致）：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>在三台阿里云ECS中都完成上述工作后，就可以逐一启动Zookeeper了，命令如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh config/zookeeper.properties &#38;</span><br></pre></td></tr></table></figure></p>
<h2 id="u68C0_u9A8CZookeeper_u96C6_u7FA4"><a href="#u68C0_u9A8CZookeeper_u96C6_u7FA4" class="headerlink" title="检验Zookeeper集群"></a>检验Zookeeper集群</h2><p>三个Zookeeper节点都启动后，我们可以通过下面两个方法对Zookeeper集群进行基础的验证。</p>
<h3 id="u67E5_u770B_u7AEF_u53E3_u76D1_u542C_u72B6_u6001"><a href="#u67E5_u770B_u7AEF_u53E3_u76D1_u542C_u72B6_u6001" class="headerlink" title="查看端口监听状态"></a>查看端口监听状态</h3><p>我们可以使用<code>nc</code>命令看看端口都有没有被成功监听，选择任意一台服务器，通过下面的命令查看：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nc -vz zookeeper.server.1 2181&#10;Connection to zookeeper.server.1 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.1 3888&#10;Connection to zookeeper.server.1 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.1 2888&#10;nc: connect to zookeeper.server.1 port 2888 (tcp) failed: Connection refused&#10;&#10;nc -vz zookeeper.server.2 2181&#10;Connection to zookeeper.server.2 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.2 3888&#10;Connection to zookeeper.server.2 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.2 2888&#10;nc: connect to zookeeper.server.2 port 2888 (tcp) failed: Connection refused&#10;&#10;nc -vz zookeeper.server.3 2181&#10;Connection to zookeeper.server.3 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.3 3888&#10;Connection to zookeeper.server.3 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.3 2888&#10;Connection to zookeeper.server.3 2888 port [tcp/*] succeeded!</span><br></pre></td></tr></table></figure></p>
<p>从上面的信息中可以看出，三个Zookeeper都成功启动了，并且可以知道<code>zookeeper.server.1</code>和<code>zookeeper.server.2</code>是Follower，<code>zookeeper.server.3</code>是Leader，因为前两个节点并没有监听<code>2888</code>端口。</p>
<h3 id="u901A_u8FC7Zookeeper_CLI_u9A8C_u8BC1"><a href="#u901A_u8FC7Zookeeper_CLI_u9A8C_u8BC1" class="headerlink" title="通过Zookeeper CLI验证"></a>通过Zookeeper CLI验证</h3><p>我们还可以通过Zookeeper Client连接到集群来检验。我们选择任意一台服务器，首先连接<code>zookeeper.server.1</code>节点：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.1:2181</span><br></pre></td></tr></table></figure></p>
<p>连接成功后，我们创建一个zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_zNode &#34;some data&#34;&#10;Created /my_zNode</span><br></pre></td></tr></table></figure></p>
<p>查看<code>zookeeper.server.1</code>节点中所有的zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;[cluster, brokers, my_zNode, zookeeper, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>我们看到了刚才创建的<code>my_zNode</code>。然后退出连接，再连接<code>zookeeper.server.2</code>节点：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.2:2181</span><br></pre></td></tr></table></figure></p>
<p>然后查看<code>zookeeper.server.2</code>节点中的所有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;[cluster, controller_epoch, brokers, my_zNode, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>我们同样发现了<code>my_zNode</code>。查看<code>my_zNode</code>中的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /my_zNode&#10;some data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x500000009&#10;mtime = Wed Jan 09 15:38:39 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>看到是在<code>zookeeper.server.1</code>节点中创建时添加的<code>some data</code>数据。</p>
<p>同样我们再连接<code>zookeeper.server.3</code>节点查看zNode情况：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.3:2181&#10;&#10;ls /&#10;[cluster, controller_epoch, brokers, my_zNode, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]&#10;&#10;get /my_zNode&#10;some data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x500000009&#10;mtime = Wed Jan 09 15:38:39 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>我们在<code>zookeeper.server.3</code>节点中修改<code>my_zNode</code>中的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_zNode &#34;new data&#34;&#10;&#10;get /my_zNode&#10;new data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x50000000e&#10;mtime = Wed Jan 09 15:46:29 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>然后再连接<code>zookeeper.server.1</code>节点查看<code>my_zNode</code>的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.1:2181&#10;&#10;get /my_zNode&#10;new data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x50000000e&#10;mtime = Wed Jan 09 15:46:29 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>看到<code>zookeeper.server.1</code>节点中<code>my_zNode</code>的数据也变成了<code>new data</code>。</p>
<p>上面的过程虽然比较繁琐，但是充分说明了我们的Zookeeper集群是搭建成功的。无论从哪个Zookeeper节点创建的zNode，都可以同步到集群中的其他节点。无论从哪个Zookeeper节点修改的zNode中的数据，也可以同步到起群中的其他节点。</p>
<h2 id="Zookeeper_The_Four_Letter_Words_Commands"><a href="#Zookeeper_The_Four_Letter_Words_Commands" class="headerlink" title="Zookeeper The Four Letter Words Commands"></a>Zookeeper The Four Letter Words Commands</h2><p>Zookeeper提供了一些能够查看节点Server状态、Client连接Server的状态、节点健康状态的命令。因为命令大多都是四个字母的简写，所以称为<a href="https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_zkCommands" target="_blank" rel="external">The Four Letter Words Commands</a>，我称为四字真言。</p>
<p>首先来看看整体的命令格式：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;xxxx&#34; | nc IP Port</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>xxxx</code>就是四字真言命令。</li>
<li><code>IP</code>是Zookeeper节点的IP。</li>
<li><code>Port</code>自然是Zookeeper监听的2181端口。</li>
</ul>
<p>下面来具体看看这些命令。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u914D_u7F6E"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u914D_u7F6E" class="headerlink" title="查看Zookeeper节点配置"></a>查看Zookeeper节点配置</h3><p>该命令可以查看指定节点的配置信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;conf&#34; | nc zookeeper.server.1 2181&#10;&#10;clientPort=2181&#10;dataDir=/root/kafka_2.12-2.0.0/data/zookeeper/version-2&#10;dataLogDir=/root/kafka_2.12-2.0.0/data/zookeeper/version-2&#10;tickTime=2000&#10;maxClientCnxns=0&#10;minSessionTimeout=4000&#10;maxSessionTimeout=40000&#10;serverId=1&#10;initLimit=10&#10;syncLimit=5&#10;electionAlg=3&#10;electionPort=3888&#10;quorumPort=2888&#10;peerType=0</span><br></pre></td></tr></table></figure></p>
<p>这个命令可以很方便的查看Zookeeper节点<code>zookeeper.properties</code>中的配置信息，以及默认的配置信息。</p>
<h3 id="u67E5_u770B_u8FDE_u63A5_u5230Zookeeper_u8282_u70B9_u7684Client_u4FE1_u606F"><a href="#u67E5_u770B_u8FDE_u63A5_u5230Zookeeper_u8282_u70B9_u7684Client_u4FE1_u606F" class="headerlink" title="查看连接到Zookeeper节点的Client信息"></a>查看连接到Zookeeper节点的Client信息</h3><p>该命令可以查看连接到指定Zookeeper节点的Client信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;cons&#34; | nc zookeeper.server.1 2181&#10;&#10;/[Client IP]:35764[1](queued=0,recved=1,sent=1,sid=0x10000b81b7d0003,lop=SESS,est=1547024407028,to=30000,lcxid=0x0,lzxid=0x500000012,lresp=22061060,llat=11,minlat=0,avglat=11,maxlat=11)&#10; /[Zookeeper Server IP]:42946[0](queued=0,recved=1,sent=0)</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BSession_u53CA_u4E34_u65F6_u8282_u70B9_u4FE1_u606F"><a href="#u67E5_u770BSession_u53CA_u4E34_u65F6_u8282_u70B9_u4FE1_u606F" class="headerlink" title="查看Session及临时节点信息"></a>查看Session及临时节点信息</h3><p>该命令可以查看指定Zookeeper节点建立Session的信息以及临时节点的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;dump&#34; | nc zookeeper.server.3 2181&#10;&#10;SessionTracker dump:&#10;Session Sets (3):&#10;0 expire at Fri Jan 02 07:13:54 CST 1970:&#10;0 expire at Fri Jan 02 07:14:04 CST 1970:&#10;1 expire at Fri Jan 02 07:14:14 CST 1970:&#10;&#9;0x10000b81b7d0003&#10;ephemeral nodes dump:&#10;Sessions with Ephemerals (0):</span><br></pre></td></tr></table></figure></p>
<p>该命令只有指定了Leader节点才有效。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u73AF_u5883_u53D8_u91CF"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u73AF_u5883_u53D8_u91CF" class="headerlink" title="查看Zookeeper节点的环境变量"></a>查看Zookeeper节点的环境变量</h3><p>该命令可以查看指定Zookeeper节点的环境变量信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;envi&#34; | nc zookeeper.server.3 2181</span><br></pre></td></tr></table></figure></p>
<h3 id="u76D1_u6D4BZookeeper_u8282_u70B9_u53EF_u7528_u72B6_u6001"><a href="#u76D1_u6D4BZookeeper_u8282_u70B9_u53EF_u7528_u72B6_u6001" class="headerlink" title="监测Zookeeper节点可用状态"></a>监测Zookeeper节点可用状态</h3><p>该命令可以查看指定Zookeeper节点是否正常：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;ruok&#34; | nc zookeeper.server.3 2181&#10;&#10;imok</span><br></pre></td></tr></table></figure></p>
<p>如果节点正常则返回<code>imok</code>，如果不正常则没有任何响应。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的信息"></a>查看Zookeeper节点的信息</h3><p>该命令可以查看指定Zookeeper节点的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;srvr&#34; | nc zookeeper.server.3 2181&#10;&#10;Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;Latency min/avg/max: 0/1/8&#10;Received: 34&#10;Sent: 33&#10;Connections: 1&#10;Outstanding: 0&#10;Zxid: 0x500000012&#10;Mode: leader&#10;Node count: 164&#10;Proposal sizes last/min/max: 36/32/90</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F_u4EE5_u53CA_u8FDE_u63A5Client_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F_u4EE5_u53CA_u8FDE_u63A5Client_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的信息以及连接Client信息"></a>查看Zookeeper节点的信息以及连接Client信息</h3><p>该命令可以查看指定Zookeeper节点的信息，以及连接该节点的Client信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;stat&#34; | nc zookeeper.server.1 2181&#10;&#10;Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;Clients:&#10; /[Client IP]:35764[1](queued=0,recved=54,sent=54)&#10; /[Zookeeper Server IP]:42956[0](queued=0,recved=1,sent=0)&#10;&#10;Latency min/avg/max: 0/0/17&#10;Received: 223&#10;Sent: 222&#10;Connections: 2&#10;Outstanding: 0&#10;Zxid: 0x500000012&#10;Mode: follower&#10;Node count: 164</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u76D1_u63A7_u72B6_u6001_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u76D1_u63A7_u72B6_u6001_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的监控状态信息"></a>查看Zookeeper节点的监控状态信息</h3><p>该命令可以查看指定Zookeeper节点的监控状态信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;mntr&#34; | nc zookeeper.server.1 2181&#10;&#10;zk_version&#9;3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;zk_avg_latency&#9;0&#10;zk_max_latency&#9;17&#10;zk_min_latency&#9;0&#10;zk_packets_received&#9;236&#10;zk_packets_sent&#9;235&#10;zk_num_alive_connections&#9;2&#10;zk_outstanding_requests&#9;0&#10;zk_server_state&#9;follower&#10;zk_znode_count&#9;164&#10;zk_watch_count&#9;0&#10;zk_ephemerals_count&#9;0&#10;zk_approximate_data_size&#9;13322&#10;zk_open_file_descriptor_count&#9;116&#10;zk_max_file_descriptor_count&#9;65535&#10;zk_fsync_threshold_exceed_count&#9;0</span><br></pre></td></tr></table></figure></p>
<p>我们可以使用以上这些命令方便的查看Zookeeper节点以及Client的各种信息，提高效率。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践搭建了真正的Zookeeper集群，为之后搭建Kafka集群打基础，同时还复习了Zookeeper CLI的使用方式以及很重要的Zookeeper四字真言。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来真正搭建一个Zookeeper集群。</p>
<h2 id="u642D_u5EFAZookeeper_u96C6_u7FA4"><a href="#u642D_u5EFAZookeeper_u96C6_u7FA4" class="headerlink" title="搭建Zookeeper集群"></a>搭建Zookeeper集群</h2><p>首先要做的就是再租赁两个服务器，参照<strong>搭建单机Kafka</strong>章节中的步骤，租赁阿里云服务器、安装JDK、下载配置Kafka、配置安全组规则。</p>
<h3 id="Zookeeper_u914D_u7F6E_u4FE1_u606F"><a href="#Zookeeper_u914D_u7F6E_u4FE1_u606F" class="headerlink" title="Zookeeper配置信息"></a>Zookeeper配置信息</h3><p>在<strong>搭建单机Kafka</strong>章节中，启动的是单机Zookeeper，所以<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件中只配置了<code>dataDir</code>，也就是存储各种数据、日志、快照的路径。</p>
<p>在搭建Zookeeper时，就需要额外再配置一些参数了。同样打开<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件，额外添加如下内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Zookeeper CLI：CRUD zNode]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-13/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-13/</id>
    <published>2019-01-27T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.115Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看Zookeeper的命令行工具。</p>
<h2 id="Zookeeper_CLI"><a href="#Zookeeper_CLI" class="headerlink" title="Zookeeper CLI"></a>Zookeeper CLI</h2><p>在第七章节搭建单机Kafka中，我们已经发现了，Kafka是自带Zookeeper的，而且在启动Kafka之前，要先启动Zookeeper，相当于启动了单机Zookeeper，所以我们先说Zookeeper CLI，后面说Zookeeper集群时再具体说配置参数。</p>
<h3 id="u5C55_u793AzNode"><a href="#u5C55_u793AzNode" class="headerlink" title="展示zNode"></a>展示zNode</h3><p>首先打开终端，连接至我们的服务器，进入<code>/root/kafka_2.12-2.0.0/bin</code>目录，执行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh zookeeper-shell.sh 127.0.0.1:2181</span><br></pre></td></tr></table></figure></p>
<p>这是Zookeeper CLI Client连接Zookeeper的命令，当看到如下信息时，说明连接成功：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Connecting to 127.0.0.1:2181&#10;Welcome to ZooKeeper!&#10;JLine support is disabled</span><br></pre></td></tr></table></figure></p>
<p>先来来看看目前Zookeeper里都有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;&#10;[cluster, controller_epoch, controller, brokers, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p><code>ls</code>命令和Linux中的作用一样，在Zookeeper中是展示某个zNode下的所有zNode。这里的<code>/</code>表示根zNode。可以看到已经有很多zNode注册在了Zookeeper。再来看看<code>brokers</code>下还有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers&#10;&#10;[ids, topics, seqid]</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>再来看看有哪些Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers/topics&#10;&#10;[with_keys_topic, first_topic, __consumer_offsets, configured-topic]</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BzNode_u5B58_u50A8_u7684_u6570_u636E"><a href="#u67E5_u770BzNode_u5B58_u50A8_u7684_u6570_u636E" class="headerlink" title="查看zNode存储的数据"></a>查看zNode存储的数据</h3><p>在上一章节中说过，Zookeeper中的zNode是可以存储数据的，那么我们来看看如何查看zNode中存储的数据，比如我们来看看<code>/brokers/ids</code>里保存了什么数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /brokers/ids&#10;&#10;null&#10;cZxid = 0x5&#10;ctime = Wed Dec 19 23:46:53 CST 2018&#10;mZxid = 0x5&#10;mtime = Wed Dec 19 23:46:53 CST 2018&#10;pZxid = 0x43d&#10;cversion = 51&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 0&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p><code>get</code>命令用于查看zNode中存储的数据，从上面的结果看到，<code>/brokers/ids</code>这个zNode里的数据是<code>null</code>，那么看看是否<code>/brokers/ids</code>下还有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers/ids&#10;&#10;[0]</span><br></pre></td></tr></table></figure></p>
<p>果然，<code>/brokers/ids</code>下还有zNode，这个zNode很明显是以Broker ID命名的。那再来看看<code>/brokers/ids/0</code>里存储了什么样的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /brokers/ids/0&#10;&#10;&#123;&#34;listener_security_protocol_map&#34;:&#123;&#34;PLAINTEXT&#34;:&#34;PLAINTEXT&#34;&#125;,&#34;endpoints&#34;:[&#34;PLAINTEXT://ECS&#22806;&#32593;IP:9092&#34;],&#34;jmx_port&#34;:-1,&#34;host&#34;:&#34;ECS&#22806;&#32593;IP&#34;,&#34;timestamp&#34;:&#34;1546570570448&#34;,&#34;port&#34;:9092,&#34;version&#34;:4&#125;&#10;cZxid = 0x43d&#10;ctime = Fri Jan 04 10:56:10 CST 2019&#10;mZxid = 0x43d&#10;mtime = Fri Jan 04 10:56:10 CST 2019&#10;pZxid = 0x43d&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x100363316d3004a&#10;dataLength = 192&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>从上面的结果可以看到，第一行显示的就是zNode存储的数据，<code>/brokers/ids/0</code>这个zNode存储了Broker的IP、端口、注册时间戳、JMX端口等信息。这一行之后的信息都是zNode的标准属性了，有各种时间戳、版本号、数据长度、子节点数等。</p>
<h3 id="u521B_u5EFAzNode"><a href="#u521B_u5EFAzNode" class="headerlink" title="创建zNode"></a>创建zNode</h3><p>我们可以使用Zookeeper CLI自行创建zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;some data&#34;&#10;&#10;Created /my_node&#10;&#10;ls /&#10;&#10;[cluster, controller, brokers, zookeeper, my_node, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>使用<code>create</code>命令创建zNode。这里要注意的是，在创建zNode时必须要带着存储数据，哪怕是空也可以：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;&#34;</span><br></pre></td></tr></table></figure></p>
<p>否则是无法创建zNode的。</p>
<p>在创建zNode时不可以一次性创建多级zNode，如果还没有创建<code>my_node</code>，直接创建<code>deeper_node</code>是不可以的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node/deeper_node &#34;some data&#34;&#10;Node does not exist: /my_node/deeper_node</span><br></pre></td></tr></table></figure></p>
<p>所以Zookeeper要一层一层创建zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;some data&#34;&#10;Created /my_node&#10;create /my_node/deeper_node &#34;some data&#34;&#10;Created /my_node/deeper_node&#10;&#10;get /my_node/deeper_node&#10;some data&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x454&#10;mtime = Mon Jan 07 19:12:20 CST 2019&#10;pZxid = 0x454&#10;cversion = 0</span><br></pre></td></tr></table></figure></p>
<h2 id="u66F4_u65B0zNode_u7684_u6570_u636E"><a href="#u66F4_u65B0zNode_u7684_u6570_u636E" class="headerlink" title="更新zNode的数据"></a>更新zNode的数据</h2><p>我们可以通过<code>set</code>命令更新zNode中存储的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node &#34;new data&#34;&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x455&#10;mtime = Mon Jan 07 19:14:04 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 1&#10;&#10;get /my_node&#10;new data&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x455&#10;mtime = Mon Jan 07 19:14:04 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p>可以看到<code>dataVersion</code>和<code>cversion</code>从0变成了1。这里注意一下，每当更新zNode存储的数据时，<code>dataVersion</code>会递增，之所以<code>cversion</code>也递增了是因为更新数据本身也是对zNode的修改，如果我们再更新一次数据，就只有<code>dataVersion</code>会递增了，因为第一次和第二次都是对zNode存储的数据的修改，只算作一次zNode的改变，所以<code>cversion</code>不会再更新：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node &#34;again new data&#34;&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x456&#10;mtime = Mon Jan 07 19:16:24 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 2&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 14&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p>如果想让<code>cversion</code>变化，那么给<code>my_node</code>再增加一个zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node/another_node &#34;some data&#34;&#10;Created /my_node/another_node&#10;get /my_node&#10;again new data&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x456&#10;mtime = Mon Jan 07 19:16:24 CST 2019&#10;pZxid = 0x457&#10;cversion = 2&#10;dataVersion = 2&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 14&#10;numChildren = 2</span><br></pre></td></tr></table></figure></p>
<p>可以看到<code>cversion</code>和<code>numChildren</code>都变了。</p>
<h3 id="u6DFB_u52A0zNode_Watcher"><a href="#u6DFB_u52A0zNode_Watcher" class="headerlink" title="添加zNode Watcher"></a>添加zNode Watcher</h3><p>上一章节同样说过，Zookeeper中的zNode的所有变更都可以被监控到。来看看如何通过CLI给zNode添加Watcher。我们给<code>/my_node/deeper_node</code>添加Watcher：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /my_node/deeper_node true&#10;some data&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x454&#10;mtime = Mon Jan 07 19:12:20 CST 2019&#10;pZxid = 0x454&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>通过<code>get /zNode true</code>给zNode添加Watcher。当<code>/my_node/deeper_node</code>修改数据时，就会收到监听事件了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node/deeper_node &#34;new data&#34;&#10;&#10;WATCHER::&#10;&#10;WatchedEvent state:SyncConnected type:NodeDataChanged path:/my_node/deeper_node&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x458&#10;mtime = Mon Jan 07 19:24:05 CST 2019&#10;pZxid = 0x454&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<h3 id="u5220_u9664zNode"><a href="#u5220_u9664zNode" class="headerlink" title="删除zNode"></a>删除zNode</h3><p>可以通过<code>rmr</code>命令删除zNode，该命令是递归删除，既可以删除指定zNode以及该zNode下的所有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rmr /my_node&#10;ls /&#10;[cluster, controller, brokers, zookeeper, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践了如何使用Zookeeper CLI操作Zookeeper，通过增删改查zNode进一步认知Zookeeper的结构，对之后认知Kafka集群做以铺垫。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看Zookeeper的命令行工具。</p>
<h2 id="Zookeeper_CLI"><a href="#Zookeeper_CLI" class="headerlink" title="Zookeeper CLI"></a>Zookeeper CLI</h2><p>在第七章节搭建单机Kafka中，我们已经发现了，Kafka是自带Zookeeper的，而且在启动Kafka之前，要先启动Zookeeper，相当于启动了单机Zookeeper，所以我们先说Zookeeper CLI，后面说Zookeeper集群时再具体说配置参数。</p>
<h3 id="u5C55_u793AzNode"><a href="#u5C55_u793AzNode" class="headerlink" title="展示zNode"></a>展示zNode</h3><p>首先打开终端，连接至我们的服务器，进入<code>/root/kafka_2.12-2.0.0/bin</code>目录，执行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh zookeeper-shell.sh 127.0.0.1:2181</span><br></pre></td></tr></table></figure></p>
<p>这是Zookeeper CLI Client连接Zookeeper的命令，当看到如下信息时，说明连接成功：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Connecting to 127.0.0.1:2181&#10;Welcome to ZooKeeper!&#10;JLine support is disabled</span><br></pre></td></tr></table></figure></p>
<p>先来来看看目前Zookeeper里都有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;&#10;[cluster, controller_epoch, controller, brokers, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p><code>ls</code>命令和Linux中的作用一样，在Zookeeper中是展示某个zNode下的所有zNode。这里的<code>/</code>表示根zNode。可以看到已经有很多zNode注册在了Zookeeper。再来看看<code>brokers</code>下还有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers&#10;&#10;[ids, topics, seqid]</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-初步认知：Zookeeper]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-12/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-12/</id>
    <published>2019-01-06T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.114Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来认识一下在Kafka中有着超然地位的Zookeeper。</p>
<h2 id="Zookeeper_u521D_u8BC6"><a href="#Zookeeper_u521D_u8BC6" class="headerlink" title="Zookeeper初识"></a>Zookeeper初识</h2><p>ZooKeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。简化分布式应用协调及其管理的难度，提供高性能的分布式服务。ZooKeeper的目标就是封装好复杂、易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
<p>Zookeeper有以下一些特点：</p>
<ul>
<li>Zookeeper的内部数据结构是树状结构的。</li>
<li>每个节点称为zNode。</li>
<li>每个zNode都有一个唯一路径（path）。</li>
<li>zNode分长久存在的和临时存在的。</li>
<li>每个zNode都可以存储数据。</li>
<li>zNode不能重命名。</li>
<li>每个zNode的任何变化都可以被监控。</li>
</ul>
<a id="more"></a>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/1/7/1546826442789.png" alt=""></p>
<p>所以Zookeeper作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，Zookeeper作用主要是用来维护和监控存储的数据的状态变化，通过监控这些数据状态的变化，从而达到基于数据的集群管理，可以说，Zookeeper相当于带有通知机制的文件系统。</p>
<h2 id="Role_of_Zookeeper_in_Kafka"><a href="#Role_of_Zookeeper_in_Kafka" class="headerlink" title="Role of Zookeeper in Kafka"></a>Role of Zookeeper in Kafka</h2><p>Zookeeper在Kafka中的地位是超然的。它的主要作用有以下几点：</p>
<ul>
<li>Zookeeper管理着Kafka集群中的若干个Broker，保存着一份完整的Broker列表。</li>
<li>维护Topic信息，比如Partitions、Replication Factor、ISR等。</li>
<li>Zookeeper帮助选举Partition的Leader.</li>
<li>当有任何变动时，由Zookeeper给Kafka发送通知，比如添加一个新的Topic、Broker挂掉了、删除Topic等等。</li>
<li>Zookeeper集群中也有Leader和Follower的概念。Leader负责写数据，Follower负责读数据.</li>
<li>存储Kafka集群ID。</li>
<li>存储访问控制列表（ACL，Access Control List）。控制Topic、Consumer Group、User等访问权限。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575649583.png" alt=""></p>
<h2 id="Size_of_Zookeeper"><a href="#Size_of_Zookeeper" class="headerlink" title="Size of Zookeeper"></a>Size of Zookeeper</h2><p>Zookeeper对于Kafka有一个很重要的投票选举功能。所以通常情况下Zookeeper集群最少使用三个Server。如果增加更多Server，那最好是奇数个Server（3，5，7，9，2N+1）。因为Zookeeper有一个特性，就是集群中只要有过半的机器是正常工作的，那么整个集群对外就是可用的。也就是说如果有2个Zookeeper Server，那么只要有1个Zookeeper Server宕机，整个集群就不能用了，因为1没有过半，所以我们要搭建奇数个Server，这样就可以保证最大允许1，2，3，4，N个Server宕机，而保证整个系统不受影响。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家初步认知了Zookeeper是什么，以及他在Kafka中为何具有超然的地位。和Kafka CLI一样，Zookeeper也有命令行工具，下一章节将会进行Zookeeper CLI的介绍，希望可以给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来认识一下在Kafka中有着超然地位的Zookeeper。</p>
<h2 id="Zookeeper_u521D_u8BC6"><a href="#Zookeeper_u521D_u8BC6" class="headerlink" title="Zookeeper初识"></a>Zookeeper初识</h2><p>ZooKeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。简化分布式应用协调及其管理的难度，提供高性能的分布式服务。ZooKeeper的目标就是封装好复杂、易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
<p>Zookeeper有以下一些特点：</p>
<ul>
<li>Zookeeper的内部数据结构是树状结构的。</li>
<li>每个节点称为zNode。</li>
<li>每个zNode都有一个唯一路径（path）。</li>
<li>zNode分长久存在的和临时存在的。</li>
<li>每个zNode都可以存储数据。</li>
<li>zNode不能重命名。</li>
<li>每个zNode的任何变化都可以被监控。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：Kafka Java Consumer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-11/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-11/</id>
    <published>2018-12-31T16:00:00.000Z</published>
    <updated>2021-10-05T16:46:43.811Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>



<p>这一节来看看如何使用Java编写Kafka Consumer。</p>
<h2 id="Java_Consumer"><a href="#Java_Consumer" class="headerlink" title="Java Consumer"></a>Java Consumer</h2><p>首先创建Consumer需要的配置信息，最基本的有五个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。</li>
<li>指定Consumer Group。</li>
<li>指定拉取Message范围的策略。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"consumer_group_1"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"latest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<p>然后传入上面实例化好的配置信息，实例化Consumer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br></pre></td></tr></table></figure></p>
<p>然后通过Consumer的<code>subscribe(Collection&lt;String&gt; topics)</code>方法订阅Topic：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">consumer.subscribe(Arrays.asList(<span class="string">"first_topic"</span>));</span><br></pre></td></tr></table></figure></p>
<p>最后获取Topic里的Message，将Message信息输出到日志中：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">	ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">	<span class="keyword">for</span>(ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">		logger.info(<span class="string">"Key: "</span> + record.key() + <span class="string">", Value: "</span> + record.value());</span><br><span class="line">		logger.info(<span class="string">"Partition: "</span> + record.partition() + <span class="string">", Offset: "</span> + record.offset());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Consumer的<code>poll(Duration timeout)</code>方法可以设置获取数据的时间间隔，同时回忆一下在之前Consumer章节的<strong>Consumer Poll Options</strong>小节中，说过关于Consumer获取Message的四个配置项，都可以在Properties里进行设置。</p>
<p>启动Java Consumer后，在控制台可以看到如下信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[main] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Discovered group coordinator IP:9092 (id: 2147483647 rack: null)&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions []&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 1&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-0, first_topic-1, first_topic-2]&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-0 to offset 23.&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-1 to offset 24.&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-2 to offset 21.</span><br></pre></td></tr></table></figure></p>
<p>在上面的信息中，可以看到<code>Setting newly assigned partitions [first_topic-0, first_topic-1, first_topic-2]</code>这句话，说明当前这个Consumer会获取<code>first_topic</code>这个Topic中全部Partition中的Message。</p>
<p>如果我们再启动一个Consumer，这个Consumer和第一个在同一个组里，看看会有什么输出信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[main] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Discovered group coordinator IP:9092 (id: 2147483647 rack: null)&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions []&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 2&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-2]</span><br></pre></td></tr></table></figure></p>
<p>可以看到新启动的Consumer会输出<code>Setting newly assigned partitions [first_topic-2]</code>这句话，说明新的这个Consumer只会获取<code>first_topic</code>这个Topic的一个Partition中的Message。</p>
<p>再回去看看第一个Consumer的控制台：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Attempt to heartbeat failed since group is rebalancing&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions [first_topic-0, first_topic-1, first_topic-2]&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 2&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-0, first_topic-1]</span><br></pre></td></tr></table></figure></p>
<p>第一个Consumer新输出在控制台中的信息很关键，首先看到<code>Attempt to heartbeat failed since group is rebalancing</code>这句话，说明Kafka会自动重新给Consumer Group里的Consumer分配Topic的Partition。</p>
<p>再看<code>Setting newly assigned partitions [first_topic-0, first_topic-1]</code>这句，说明第一个Consumer不会再获取<code>first_topic-2</code>这个Partition里的Message了。这也印证了在Consumer章节的<strong>Consumer Group</strong>小节里讲过的概念。</p>
<h3 id="Java_Consumer_with_Assign_and_Seek"><a href="#Java_Consumer_with_Assign_and_Seek" class="headerlink" title="Java Consumer with Assign and Seek"></a>Java Consumer with Assign and Seek</h3><p>如果我们有一个临时的Consumer，不想加入任何一个Consumer Group，而且需要指定Topic的Partition，以及指定从哪个Message Offset开始获取数据，怎么办？所幸，Kafka提供了这样的API。</p>
<p>首先我们在实例化配置信息时，就不需要指定Consumer Group了：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KafkaConstant.BOOTSTRAP_SERVER);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure></p>
<p>然后实例化<code>TopicPartition</code>，指定Topic和Partition序号。使用Consumer的<code>assign(Collection&lt;TopicPartition&gt; partitions)</code>方法，分配给该Consumer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">TopicPartition topicPartition = <span class="keyword">new</span> TopicPartition(<span class="string">"first_topic"</span>, <span class="number">0</span>);</span><br><span class="line">consumer.assign(Arrays.asList(topicPartition));</span><br></pre></td></tr></table></figure></p>
<p>再然后指定Message Offset：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> offset = <span class="number">21L</span>;</span><br><span class="line">consumer.seek(topicPartition, offset);</span><br></pre></td></tr></table></figure></p>
<p>运行该Consumer，可以看到如下输出信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=] Fetch offset 21 is out of range for partition first_topic-0, resetting offset&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=] Resetting offset for partition first_topic-0 to offset 22.&#10;[main] INFO com.devtalking.jacefu.kafka.tutorial.ConsumerDemoAssignSeek - Key: null, Value: hello world!&#10;[main] INFO com.devtalking.jacefu.kafka.tutorial.ConsumerDemoAssignSeek - Partition: 0, Offset: 22</span><br></pre></td></tr></table></figure></p>
<p>如果我们使用Consumer Group CLI查看，会发现这种操作其实也是临时创建了一个Consumer Group：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@iZ2ze2booskait1cxxyrljZ:~# kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;consumer_group_1&#10;KMOffsetCache-iZ2ze2booskait1cxxyrljZ</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践如何使用Kafka提供的API编写Java Consumer。上一节和这一节主要介绍了Kafka Java Client（Producer和Consumer）的使用方式，相比Kafka CLI，Java Client在实际的开发中可能使用的更加频繁，希望能给使用Java语言的小伙伴们带来帮助。</p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>



<p>这一节来看看如何使用Java编写Kafka Consumer。</p>
<h2 id="Java_Consumer"><a href="#Java_Consumer" class="headerlink" title="Java Consumer"></a>Java Consumer</h2><p>首先创建Consumer需要的配置信息，最基本的有五个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。</li>
<li>指定Consumer Group。</li>
<li>指定拉取Message范围的策略。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"consumer_group_1"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"latest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：Kafka Java Producer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-10/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-10/</id>
    <published>2018-12-14T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.114Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Producer。</p>
<h2 id="Create_Kafka_Project"><a href="#Create_Kafka_Project" class="headerlink" title="Create Kafka Project"></a>Create Kafka Project</h2><p>创建Maven工程，在POM文件中加入如下两个依赖：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>slf4j-simple<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>第一个是Kafka的依赖包，用于创建Producer、ProducerRecord、Consumer等。第二个是Log4J的依赖包，用于输出日志。</p>
<a id="more"></a>
<h2 id="Java_Producer"><a href="#Java_Producer" class="headerlink" title="Java Producer"></a>Java Producer</h2><p>首先创建Producer需要的配置信息，最基本的有三个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>然后传入上面实例化好的配置信息，实例化Producer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br></pre></td></tr></table></figure></p>
<p>然后实例化Record对象，该对象承载了要往哪个Topic发送以及Message内容的信息：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first_topic"</span>, <span class="string">"hello world!"</span>);</span><br></pre></td></tr></table></figure></p>
<p>再然后发送Record：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.send(producerRecord);</span><br></pre></td></tr></table></figure></p>
<p>最后刷新和关闭Producer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.flush();</span><br><span class="line">kafkaProducer.close();</span><br></pre></td></tr></table></figure></p>
<p>以上就是最简单的Kafka Java Producer的编写方法。运行一下，可以看到类似如下的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.&#10;&#10;Process finished with exit code 0</span><br></pre></td></tr></table></figure></p>
<h3 id="Java_Producer_with_Callback"><a href="#Java_Producer_with_Callback" class="headerlink" title="Java Producer with Callback"></a>Java Producer with Callback</h3><p>如果我们希望在发送Message后，能监控发送状态，或者在发送异常时对异常进行处理。那么我们就可以使用带有Callback的发送方法：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.send(producerRecord, <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">			logger.info(<span class="string">"Received new metadata. \n"</span> +</span><br><span class="line">                            <span class="string">"Topic: "</span> + recordMetadata.topic()  + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Partition: "</span> + recordMetadata.partition() + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Offset: "</span> + recordMetadata.offset() + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Timestamp: "</span> + recordMetadata.timestamp());</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			logger.error(<span class="string">"Error while producing: "</span>, e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p>这样每次发送Message后，都会进入<code>onCompletion</code>这个方法中，然后可以使用<code>RecordMetadata</code>中记录的各种元数据做一些跟踪和监控的事情，同时如果发送异常了，也可以对异常进行处理。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[kafka-producer-network-thread | producer-1] INFO com.devtalking.jacefu.kafka.tutorial1.ProducerDemoWithCallback - Received new metadata. &#10;Topic: first_topic&#10;Partition: 0&#10;Offset: 22&#10;Timestamp: 1546421392063&#10;[main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.&#10;&#10;Process finished with exit code 0</span><br></pre></td></tr></table></figure></p>
<h3 id="Java_Producer_with_Keys"><a href="#Java_Producer_with_Keys" class="headerlink" title="Java Producer with Keys"></a>Java Producer with Keys</h3><p>在前文中，Partition的Compaction Cleanup Policy一节中介绍到，在压缩策略时，就涉及到了Message的Key和Value。我们来看看如何在发送Message时带着Key。</p>
<p>首先来看看<code>ProducerRecord</code>的另一个构造函数：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(topic, (Integer)<span class="keyword">null</span>, (Long)<span class="keyword">null</span>, key, value, (Iterable)<span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到，刚才我们只使用了<code>topic</code>和<code>value</code>两个参数，其中还有一个<code>key</code>，所以我们在实例化<code>ProducerRecord</code>时传入Key就可以了：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first_topic"</span>, <span class="string">"This is the key"</span>, <span class="string">"hello world!"</span>);</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>之前三个章节介绍了如何使用Kafka CLI操作Kafka，其中包括Producer CLI和Consumer CLI。这一章节主要带大家实践如何使用Kafka提供的API编写Java Producer，希望可以给使用Java语言的小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Producer。</p>
<h2 id="Create_Kafka_Project"><a href="#Create_Kafka_Project" class="headerlink" title="Create Kafka Project"></a>Create Kafka Project</h2><p>创建Maven工程，在POM文件中加入如下两个依赖：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>slf4j-simple<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>第一个是Kafka的依赖包，用于创建Producer、ProducerRecord、Consumer等。第二个是Log4J的依赖包，用于输出日志。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Reseting Offset & Config CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-9/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-9/</id>
    <published>2018-11-30T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.116Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Reseting_Offset"><a href="#Reseting_Offset" class="headerlink" title="Reseting Offset"></a>Reseting Offset</h2><p>在实际的业务场景中，经常需要重复消费Topic中的Message，所以来看看如何重置Offset。</p>
<p>首先重置Offset可以通过如下的命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --reset-offsets [options] --execute --topic xxxx</span><br></pre></td></tr></table></figure></p>
<p>Kafka为我们提供了6种重置Offset的方式，也就是命令中的<code>options</code>：</p>
<ul>
<li><code>--to-earliest</code>：重置到最早的Offset。</li>
<li><code>--to-latest</code>：重置到最后的Offset。</li>
<li><code>--to-offset &lt;Long: offset&gt;</code>：重置到指定的Offset。</li>
<li><code>--to-current</code>：重置到当前的Offset。</li>
<li><code>--to-datetime &lt;String: datetime&gt;</code>：重置到指定时间的Offset，时间格式为<code>YYYY-MM-DDTHH:mm:SS.sss</code>。</li>
<li><code>--shift-by &lt;Long: number-of-offsets&gt;</code>：左移或右移Offset。</li>
</ul>
<a id="more"></a>
<p>举个例子来看看：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --topic first_topic --reset-offsets --shift-by -2 --execute&#10;&#10;TOPIC                          PARTITION  NEW-OFFSET&#10;first_topic                    2          15&#10;first_topic                    1          17&#10;first_topic                    0          15</span><br></pre></td></tr></table></figure></p>
<p>上面的命令将<code>consumer_group_1</code>消费<code>first_topic</code>的三个Partitions的Offset向左移了2位。如此之后，相当于<code>consumer_group_1</code>还有6条Message没有消费。我们启动Consumer看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --topic first_topic&#10;&#10;C&#10;F&#10;E&#10;this is another message.&#10;A&#10;D</span><br></pre></td></tr></table></figure></p>
<p>可以看到启动Consumer后，消费了6条Message。其他的Reset Options用法是一样的。这使得我们可以非常灵活的控制Consumer消费Message。</p>
<h2 id="Config_CLI"><a href="#Config_CLI" class="headerlink" title="Config CLI"></a>Config CLI</h2><p>我们再来看看如何通过命令进行Kafka的配置。用到的命令是<code>kafka-config.sh</code>，该命令可以对Topic、Broker、Client进行配置。关键的属性有以下三个：</p>
<ul>
<li><code>--entity-type</code>：这个属性设置要对什么进行配置，可选值为<code>topics</code>、<code>brokers</code>、<code>clients</code>、<code>users</code>。</li>
<li><code>--entity-name</code>：这个属性设置对应Type的名称，比如Topic名称、Broker Id、Client Id、User name。</li>
<li><code>--alter</code>：确认修改。</li>
</ul>
<p>首先我们创建一个Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181 --create --topic configured-topic --partitions 3 --replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>看看新创建的Topic的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic configured-topic --describe&#10;&#10;Topic:configured-topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:&#10;Topic: configured-topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>可以看到打印信息中的Configs是空的，说明这个Topic没有做额外的配置。或者也可以使用如下命令查看Topic的配置：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --describe&#10;&#10;Configs for topic &#39;configured-topic&#39; are</span><br></pre></td></tr></table></figure></p>
<p>看到打印信息只有<code>Configs for topic &#39;configured-topic&#39; are</code>，同样说明该Topic还没有额外配置信息。</p>
<p>接下来该这个Topic设置<code>min.insync.replicas</code>属性：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --add-config min.insync.replicas=2 --alter&#10;&#10;Completed Updating config for entity: topic &#39;configured-topic&#39;.</span><br></pre></td></tr></table></figure></p>
<p>再来查看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --describe&#10;&#10;Configs for topic &#39;configured-topic&#39; are min.insync.replicas=2&#10;&#10;kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic configured-topic --describe&#10;&#10;Topic:configured-topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:min.insync.replicas=2&#10;Topic: configured-topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>两种方式都可以看到刚才更新的配置信息。</p>
<p>将<code>--add-config</code>换成<code>--delete-config</code>就可以删除配置项：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --add-config min.insync.replicas=2 --alter&#10;&#10;Completed Updating config for entity: topic &#39;configured-topic&#39;.</span><br></pre></td></tr></table></figure></p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节进一步介绍了如何通过Kafka CLI操作Consumer Offset，以及如何使用Config CLI对Kafka进行配置。下一章节会介绍如何使用Kafka API编写Kafka Java Client。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Reseting_Offset"><a href="#Reseting_Offset" class="headerlink" title="Reseting Offset"></a>Reseting Offset</h2><p>在实际的业务场景中，经常需要重复消费Topic中的Message，所以来看看如何重置Offset。</p>
<p>首先重置Offset可以通过如下的命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --reset-offsets [options] --execute --topic xxxx</span><br></pre></td></tr></table></figure></p>
<p>Kafka为我们提供了6种重置Offset的方式，也就是命令中的<code>options</code>：</p>
<ul>
<li><code>--to-earliest</code>：重置到最早的Offset。</li>
<li><code>--to-latest</code>：重置到最后的Offset。</li>
<li><code>--to-offset &lt;Long: offset&gt;</code>：重置到指定的Offset。</li>
<li><code>--to-current</code>：重置到当前的Offset。</li>
<li><code>--to-datetime &lt;String: datetime&gt;</code>：重置到指定时间的Offset，时间格式为<code>YYYY-MM-DDTHH:mm:SS.sss</code>。</li>
<li><code>--shift-by &lt;Long: number-of-offsets&gt;</code>：左移或右移Offset。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Consumer CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-8/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-8/</id>
    <published>2018-11-30T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.116Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Consumer_CLI"><a href="#Consumer_CLI" class="headerlink" title="Consumer CLI"></a>Consumer CLI</h2><p>这一节来看看使用命令行启动Consumer接收消息，通过如下的命令启动Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-consumer.sh</code>是启动Consumer的命令。</li>
<li><code>--bootstrap-server</code>指定要连接的Broker地址。</li>
<li><code>--topic</code>指定Topic名称，既要从哪个Topic里读数据。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575057414.png" alt=""></p>
<a id="more"></a>
<p>如上图所示，左边启动的是Consumer，右边启动的是Producer。Producer发送的消息可以实时的被Consumer接收到。但是有一个问题，那就是在上一节中，我们已经给<code>first_topic</code>这个Topic发送了一些数据。但是现在Consumer启动后并没有收到。这是因为通过上面的命令启动的Consumer接收的是最新的消息，如果想接收所有的消息，还需要带一个参数：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning</span><br></pre></td></tr></table></figure></p>
<p><code>--from-beginning</code>表示启动的Consumer要接收所有的消息。</p>
<p>前文中说过，Consumer一般都是以组的形式存在，所以可以再加一个参数来创建一个Consumer Group：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --group consumer_group_1</span><br></pre></td></tr></table></figure></p>
<p><code>--group</code>可以指定Consumer Group的名称。</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575079452.png" alt=""></p>
<p>如上图所示，左边启动了三个Consumer，这三个Consumer都在同一个名为<code>consumer_group_1</code>的组里。因为<code>first_topic</code>这个Topic有三个Partitions，所以当一个Consumer Group中有三个Consumer时，他们的收到的信息不会重复。</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575103168.png" alt=""></p>
<p>又如上图所示，左边启动了三个Consumer，但是前两个在<code>consumer_group_1</code>的组里，最后一个在<code>consumer_group_2</code>的组里，所以前两个Consumer是以轮询的方式收到消息的，而最后一个Consumer可以收到全部的消息。</p>
<p>上面两个示例也充分证明了前文中所说的，<strong>不同的Consumer Group可以消费同一个Topic中相同的Partition的消息，但是Consumer Group内的Consumer不能消费同一个Topic中相同的Partition的消息</strong>。</p>
<p>上面的命令是显示的创建Consumer Group。上文中说到过，Kafka中，Consumer都是以组的形式连接Broker消费数据的。那么如果只有一个Consumer的情况下，是否有Consumer Group呢？其实，当只有一个Consumer时，也会自动创建一个Consumer Group。我们可以通过另外一组Consumer Group CLI来看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;console-consumer-40439&#10;console-consumer-81216&#10;consumer_group_1c&#10;console-consumer-14387&#10;consumer_group_2&#10;consumer_group_1&#10;console-consumer-40563</span><br></pre></td></tr></table></figure></p>
<p>可以看到，已经存在的Consumer Group中，除了我们之前创建的，还有以<code>console-consumer-xxxxx</code>这种命名格式存在的Consumer Group。这就是当我们只启动一个Consumer时Kafka自动为这个Consumer创建的Consumer Group。这里可以做个实验，先启动一个Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<p>然后再来看看Consumer Group是否有增加：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;console-consumer-96752&#10;console-consumer-40439&#10;console-consumer-81216&#10;consumer_group_1c&#10;console-consumer-14387&#10;consumer_group_2&#10;consumer_group_1&#10;console-consumer-40563</span><br></pre></td></tr></table></figure></p>
<p>我们看到增加了一个Consumer Group<code>console-consumer-96752</code>。</p>
<p>Consumer Group列表看完了，再来看看某一个Consumer Group的详细信息，比如查看<code>consumer_group_1</code>的详细信息。可以使用如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;Consumer group &#39;consumer_group_1&#39; has no active members.&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               -               -               -&#10;first_topic     2          17              17              0               -               -               -&#10;first_topic     1          18              18              0               -               -</span><br></pre></td></tr></table></figure></p>
<p>首先会告诉我们该Consumer Group中是否有正在活跃的Consumer，目前没有启动任何Consumer，所以提示我们<code>Consumer group &#39;consumer_group_1&#39; has no active members.</code></p>
<p>然后会列出该Consumer Group消费的Topic、Partition情况、Offset情况、延迟（LAG）情况、处于活跃状态的Consumer信息。</p>
<p>可以看到<code>consumer_group_1</code>这个Consumer Group正在消费<code>first_topic</code>这个Topic中的Message，一共从三个Partition中消费了52条Messages，并且目前已经消费了全部的数据，因为每个Partition的延迟都是0，说明没有还未接收的Message。</p>
<p>现在我们再往<code>first_topic</code>中发送一条Message，再来看看情况如何：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1&#10;&#62;this is another message.&#10;&#10;kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;Consumer group &#39;consumer_group_1&#39; has no active members.&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               -               -               -&#10;first_topic     2          17              17              0               -               -               -&#10;first_topic     1          18              19              1               -               -               -</span><br></pre></td></tr></table></figure></p>
<p>可以看到Partition 1 的<code>LOG-END-OFFSET</code>是19，而<code>CURRENT-OFFSET</code>是18，并且Partition 1 的<code>LAG</code>是1，说明现在<code>first-topic</code>一共接收到了19条Message，而<code>consumer-group-1</code>只消费了18条，有1条延迟。</p>
<p>我们再启动<code>consumer_group_1</code>中的Consumer，然后再看看数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning --group consumer_group_1&#10;&#10;this is another message.&#10;&#10;kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1&#10;first_topic     1          19              19              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1&#10;first_topic     2          17              17              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1</span><br></pre></td></tr></table></figure></p>
<p>可以看到，目前有一个处于活跃的Consumer，并且Messages全部被消费。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节主要介绍了如何使用Kafka的Consumer CLI接收Producer生产的Message。同时能更直观的印证之前介绍概念时提到的内容，比如Consumer Group的机制、Offset机制等。下一章节进一步介绍Offset的操作以及Config CLI。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Consumer_CLI"><a href="#Consumer_CLI" class="headerlink" title="Consumer CLI"></a>Consumer CLI</h2><p>这一节来看看使用命令行启动Consumer接收消息，通过如下的命令启动Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-consumer.sh</code>是启动Consumer的命令。</li>
<li><code>--bootstrap-server</code>指定要连接的Broker地址。</li>
<li><code>--topic</code>指定Topic名称，既要从哪个Topic里读数据。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575057414.png" alt=""></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Topic CLI & Producer CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-7/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-7/</id>
    <published>2018-11-14T16:00:00.000Z</published>
    <updated>2019-04-20T16:38:12.116Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Kafka CLI是Kafka Command Line Interface。其实就是Kafka的命令行工具，可以让我们在终端里方面的进行Kafka的操作，比如创建Topic、Partition、Replication、Produce data、Consume data等等。后续的几个章节主要来介绍如何使用Kafka CLI。</p>
<h2 id="Topic_CLI"><a href="#Topic_CLI" class="headerlink" title="Topic CLI"></a>Topic CLI</h2><p>首先我们可以通过下面的命令创建Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh &#8212;zookeeper 127.0.0.1:2181 &#8212;topic xxxx_topic &#8212;create &#8212;partitions 3 &#8212;replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，<code>replication-factor</code>不能大于Broker的数量，这个很好理解，前文中有过阐述。成功后可以看<code>Created topic &quot;first_topic&quot;.</code>这样的提示。</p>
<a id="more"></a>
<p>可以通过如下命令查看当前有哪些Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --list</span><br></pre></td></tr></table></figure></p>
<p>可以通过如下命令查看某个Topic的具体信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --topic first_topic --describe</span><br></pre></td></tr></table></figure></p>
<p>显示该Topic的Partition信息、Leader信息、ISR信息、Replication信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Topic:first_topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:&#10;Topic: first_topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: first_topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: first_topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>这里注意，Partition后面的数字是序号，因为我们设置了三个Partition。Leader、Replicas、Isr后面的数字是Broker的ID，在<code>server.properties</code>配置文件中可以配置Broker的ID，默认从0开始。</p>
<p>可以通过如下命令删除Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --topic second_topic --delete</span><br></pre></td></tr></table></figure></p>
<p>这里要注意，Broker有一个配置项<code>delete.topic.enable</code>，如果设为<code>false</code>，那么删除Topic时并非立即删除，只是会被打上删除的标记，以减少Topic突然删除给业务带来的冲击。如果设为<code>true</code>，那么就是立即删除，默认是<code>true</code>。</p>
<p>现在大家可以到<code>/kafka_2.12-2.0.0/data/kafka</code>目录中看一下，可以看到Partition的目录，和一些Checkpoint的文件。</p>
<h2 id="Producer_CLI"><a href="#Producer_CLI" class="headerlink" title="Producer CLI"></a>Producer CLI</h2><p>再来看看如何通过CLI启动Producer发送消息，命令如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-producer.sh</code>是启动Producer的命令。</li>
<li><code>--broker-list</code>设置连接的Broker地址，指定要连接哪个Broker。端口号9092是默认的，在<code>server.properties</code>文件中可以通过<code>port</code>属性更改，IP地址可以通过<code>host.name</code>属性更改。</li>
<li><code>--topic</code>设置Topic名称，指定要往哪个Topic里发送消息。</li>
<li><code>--producer-property</code>配置Producer的参数，这里要指定ACK的策略。</li>
</ul>
<p>然后就可以发送消息了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1&#10;&#62;hello this is a producer&#10;&#62;I am JaceFu&#10;&#62;Kafka is a awesome MQ system</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，如果在命令中指定的Topic不存在，则Kafka会自动创建这个Topic，Partition数量会根据<code>server.properties</code>中配置的<code>num.partitions</code>数创建。但建议应该提前创建好Topic再发送消息。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节介绍了如何使用Kafka的Topic CLI创建Topic、查看Topic信息。然后使用Producer CLI生产Message。结合之前对它们概念的介绍，能让我们有更直观的认知。下一章节会介绍如何使用Consumer CLI。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Kafka CLI是Kafka Command Line Interface。其实就是Kafka的命令行工具，可以让我们在终端里方面的进行Kafka的操作，比如创建Topic、Partition、Replication、Produce data、Consume data等等。后续的几个章节主要来介绍如何使用Kafka CLI。</p>
<h2 id="Topic_CLI"><a href="#Topic_CLI" class="headerlink" title="Topic CLI"></a>Topic CLI</h2><p>首先我们可以通过下面的命令创建Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh &#8212;zookeeper 127.0.0.1:2181 &#8212;topic xxxx_topic &#8212;create &#8212;partitions 3 &#8212;replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，<code>replication-factor</code>不能大于Broker的数量，这个很好理解，前文中有过阐述。成功后可以看<code>Created topic &quot;first_topic&quot;.</code>这样的提示。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
</feed>
