<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[程序员说]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://www.devtalking.com/"/>
  <updated>2021-02-03T16:09:48.619Z</updated>
  <id>http://www.devtalking.com/</id>
  
  <author>
    <name><![CDATA[DevTalking]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Serverless在SaaS领域中的实践]]></title>
    <link href="http://www.devtalking.com//articles/serverless-saas/"/>
    <id>http://www.devtalking.com//articles/serverless-saas/</id>
    <published>2020-05-19T16:00:00.000Z</published>
    <updated>2021-02-03T16:09:48.619Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p>随着互联网人口红利逐渐减弱，基于流量的增长已经放缓，互联网行业迫切需要找到一片足以承载自身持续增长的新蓝海。产业互联网正是这一宏大背景下的新趋势。我们看到互联网浪潮正在席卷传统行业，云计算、大数据、人工智能开始大规模融入到金融、制造、物流、零售、文娱、教育、医疗等行业的生产环节中，这种融合称为产业互联网。而在产业互联网中，有一块不可小觑的领域是SaaS领域，它是ToB赛道的中间力量。比如CRM、HRM、费控系统、财务系统、协同办公等等。</p>
<h2 id="SaaS_u7CFB_u7EDF_u9762_u4E34_u7684_u6311_u6218"><a href="#SaaS_u7CFB_u7EDF_u9762_u4E34_u7684_u6311_u6218" class="headerlink" title="SaaS系统面临的挑战"></a>SaaS系统面临的挑战</h2><p>在消费互联网时代，大家是<strong>搜</strong>我想要的东西，各个厂商在云计算、大数据、人工智能等技术基座之上建立流量最大化的服务与生态，基于海量内容分发与流量共享为逻辑构建系统。而到了产业互联网时代，供给关系发生了变化，大家是<strong>定制</strong>我想要的东西，需要从供给与需求两侧出发进行双向建设，这个时候系统的灵活性和扩展性面临着前所未有的挑战，尤其是ToB的SaaS领域。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%201.png" alt=""></p>
<p>尤其当下的经济环境，SaaS厂商要明白，不能再通过烧钱的方式，只关注在自己的用户数量上，而更多的要思考如何帮助客户降低成本、增加效率，所以需要将更多的精力放在自己产品的定制化能力上。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%202.png" alt=""></p>
<h2 id="u5982_u4F55_u5E94_u5BF9_u6311_u6218"><a href="#u5982_u4F55_u5E94_u5BF9_u6311_u6218" class="headerlink" title="如何应对挑战"></a>如何应对挑战</h2><p>SaaS领域中的佼佼者Salesforce，将CRM的概念扩展到Marketing、Sales、Service，而这三块领域中只有Sales有专门的SaaS产品，其他两个领域都是各个ISV在不同行业的行业解决方案，靠的是什么？毋庸置疑，是Salesforce强大的aPaaS平台。ISV、内部实施、客户均可以在各自维度通过aPaaS平台构建自己行业、自己领域的SaaS系统，建立完整的生态。所以在我看来，现在的Salesforce已经由一家SaaS公司升华为一家aPaaS平台公司了。这种演进的过程也印证了消费互联网和产业互联网的转换逻辑以及后者的核心诉求。</p>
<p>然而不是所有SaaS公司都有财力和时间去孵化和打磨自己的aPaaS平台，但市场的变化、用户的诉求是实实在在存在的，若要生存，就要求变。这个变的核心就是能够让自己目前的SaaS系统变的灵活起来。相对建设困难的aPaaS平台，我们其实可以选择轻量且有效的Serverless方案来提升现有系统的灵活性和可扩展性，从而实现用户不同的定制需求。</p>
<h2 id="Serverless_u5DE5_u4F5C_u6D41"><a href="#Serverless_u5DE5_u4F5C_u6D41" class="headerlink" title="Serverless工作流"></a>Serverless工作流</h2><p>在上一篇文章<a href="http://www.devtalking.com/articles/serverless-online-coding/">《资源成本双优化！看Serverless颠覆编程教育的创新实践》</a>中，已经对Serverless的概念做过阐述了，并且也介绍了Serverless函数计算（FC）的概念和实践。这篇文章中介绍一下构建系统灵活性的核心要素服务编排，Serverless工作流。</p>
<p>Serverless 工作流（FnF）是一个用来协调多个分布式任务执行的全托管云服务。在 Serverless工作流中，可以用顺序、分支、并行等方式来编排分布式任务，Serverless工作流会按照设定好的步骤可靠地协调任务执行，跟踪每个任务的状态转换，并在必要时执行您定义的重试逻辑，以确保工作流顺利完成。Serverless工作流通过提供日志记录和审计来监视工作流的执行，可以轻松地诊断和调试应用。</p>
<a id="more"></a>
<p>下面这张图描述了Serverless工作流如何协调分布式任务，这些任务可以是函数、已集成云服务API、运行在虚拟机或容器上的程序。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%203.png" alt=""></p>
<p>看完Serverless工作流的介绍，大家可能已经多少有点思路了吧。系统灵活性和可扩展性的核心是服务可编排，无论是以前的BPM还是现在的aPaaS。所以基于Serverless工作流重构SaaS系统灵活性方案的核心思路，是将系统内用户最希望定制的功能进行梳理、拆分、抽离，再配合函数计算（FC）提供无状态的能力，通过Serverless工作流进行这些功能点的编排，从而实现不同的业务流程。</p>
<h2 id="u901A_u8FC7Serverless_u51FD_u6570_u8BA1_u7B97_u548CServerless_u5DE5_u4F5C_u6D41_u642D_u5EFA_u7075_u6D3B_u7684_u8BA2_u9910_u6A21_u5757"><a href="#u901A_u8FC7Serverless_u51FD_u6570_u8BA1_u7B97_u548CServerless_u5DE5_u4F5C_u6D41_u642D_u5EFA_u7075_u6D3B_u7684_u8BA2_u9910_u6A21_u5757" class="headerlink" title="通过Serverless函数计算和Serverless工作流搭建灵活的订餐模块"></a>通过Serverless函数计算和Serverless工作流搭建灵活的订餐模块</h2><p>订餐场景相信大家都不会陌生，在家叫外卖或者在餐馆点餐，都涉及到这个场景。当下也有很多提供点餐系统的SaaS服务厂商，有很多不错的SaaS点餐系统。随着消费互联网向产业互联网转换，这些SaaS点餐系统面临的定制化的需求也越来越多，其中有一个需求是不同的商家在支付时会显示不同的支付方式，比如从A商家点餐后付款时显示支付宝、微信支付、银联支付，从B商家点餐后付款时显示支付宝、京东支付。突然美团又冒出来了美团支付，此时B商家接了美团支付，那么从B商家点餐后付款时显示支付宝、京东支付、美团支付。诸如此类的定制化需求越来越多，这些SaaS产品如果没有PaaS平台，那么就会疲于不断的通过硬代码增加条件判断来实现不同商家的需求，这显然不是一个可持续发展的模式。</p>
<p>那么我们来看看通过Serverless函数计算和Serverless工作流如何优雅的解决这个问题。先来看看这个点餐流程：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%204.png" alt=""></p>
<h3 id="u901A_u8FC7Serverless_u5DE5_u4F5C_u6D41_u521B_u5EFA_u6D41_u7A0B"><a href="#u901A_u8FC7Serverless_u5DE5_u4F5C_u6D41_u521B_u5EFA_u6D41_u7A0B" class="headerlink" title="通过Serverless工作流创建流程"></a>通过Serverless工作流创建流程</h3><p>首选我需要将上面用户侧的流程转变为程序侧的流程，此时就需要使用Serverless工作流来担任此任务了。</p>
<p>打开<a href="https://fnf.console.aliyun.com/fnf/cn-hangzhou/flows" target="_blank" rel="external">Serverless控制台</a>，创建订餐流程，这里Serverless工作流使用流程定义语言FDL创建工作流，如何使用FDL创建工作流请参阅<a href="https://help.aliyun.com/document_detail/122492.html?spm=a2c4g.11186623.6.575.464c2d0eKxcO5d" target="_blank" rel="external">文档</a>。流程图如下图所示：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%205.png" alt=""></p>
<p>FDL代码为：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">version: v1beta1</span><br><span class="line">type: flow</span><br><span class="line">timeoutSeconds: <span class="number">3600</span></span><br><span class="line">steps:</span><br><span class="line">  - type: task</span><br><span class="line">    name: generateInfo</span><br><span class="line">    timeoutSeconds: <span class="number">300</span></span><br><span class="line">    resourceArn: acs:mns:::/topics/generateInfo-fnf-demo-jiyuan/messages</span><br><span class="line">    pattern: waitForCallback</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $context.task.token</span><br><span class="line">      - target: products</span><br><span class="line">        source: $input.products</span><br><span class="line">      - target: supplier</span><br><span class="line">        source: $input.supplier</span><br><span class="line">      - target: address</span><br><span class="line">        source: $input.address</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $input.orderNum</span><br><span class="line">      - target: type</span><br><span class="line">        source: $context.step.name </span><br><span class="line">    outputMappings:</span><br><span class="line">      - target: paymentcombination</span><br><span class="line">        source: $local.paymentcombination</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">    serviceParams:</span><br><span class="line">      MessageBody: $</span><br><span class="line">      Priority: <span class="number">1</span></span><br><span class="line">    catch:</span><br><span class="line">      - errors:</span><br><span class="line">          - FnF.TaskTimeout</span><br><span class="line">        goto: orderCanceled</span><br><span class="line">  - type: task</span><br><span class="line">    name: payment</span><br><span class="line">    timeoutSeconds: <span class="number">300</span></span><br><span class="line">    resourceArn: acs:mns:::/topics/payment-fnf-demo-jiyuan/messages</span><br><span class="line">    pattern: waitForCallback</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $context.task.token</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: paymentcombination</span><br><span class="line">        source: $local.paymentcombination</span><br><span class="line">      - target: type</span><br><span class="line">        source: $context.step.name </span><br><span class="line">    outputMappings:</span><br><span class="line">      - target: paymentMethod</span><br><span class="line">        source: $local.paymentMethod</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: price</span><br><span class="line">        source: $local.price</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $input.taskToken</span><br><span class="line">    serviceParams:</span><br><span class="line">      MessageBody: $</span><br><span class="line">      Priority: <span class="number">1</span></span><br><span class="line">    catch:</span><br><span class="line">      - errors:</span><br><span class="line">          - FnF.TaskTimeout</span><br><span class="line">        goto: orderCanceled</span><br><span class="line">  - type: choice</span><br><span class="line">    name: paymentCombination</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: paymentMethod</span><br><span class="line">        source: $local.paymentMethod</span><br><span class="line">      - target: price</span><br><span class="line">        source: $local.price</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $local.taskToken</span><br><span class="line">    choices:</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"zhifubao"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: zhifubao</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan/functions/zhifubao-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">              - target: price</span><br><span class="line">                source: $input.price             </span><br><span class="line">              - target: orderNum</span><br><span class="line">                source: $input.orderNum </span><br><span class="line">              - target: paymentMethod</span><br><span class="line">                source: $input.paymentMethod</span><br><span class="line">              - target: taskToken</span><br><span class="line">                source: $input.taskToken</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"weixin"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: weixin</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/weixin-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">            - target: price</span><br><span class="line">              source: $input.price             </span><br><span class="line">            - target: orderNum</span><br><span class="line">              source: $input.orderNum</span><br><span class="line">            - target: paymentMethod</span><br><span class="line">              source: $input.paymentMethod</span><br><span class="line">            - target: taskToken</span><br><span class="line">              source: $input.taskToken</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"unionpay"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: unionpay</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/union-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">            - target: price</span><br><span class="line">              source: $input.price             </span><br><span class="line">            - target: orderNum</span><br><span class="line">              source: $input.orderNum </span><br><span class="line">            - target: paymentMethod</span><br><span class="line">              source: $input.paymentMethod</span><br><span class="line">            - target: taskToken</span><br><span class="line">              source: $input.taskToken</span><br><span class="line">    default:</span><br><span class="line">      goto: orderCanceled</span><br><span class="line">  - type: task</span><br><span class="line">    name: orderCompleted</span><br><span class="line">    resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/orderCompleted</span><br><span class="line">    end: true</span><br><span class="line">  - type: task</span><br><span class="line">    name: orderCanceled</span><br><span class="line">    resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/cancerOrder</span><br></pre></td></tr></table></figure></p>
<p>在解析整个流程之前，我先要说明的一点是，我们不是完全通过Serverless函数计算和Serverless工作流来搭建订餐模块，只是用它来解决灵活性的问题，所以这个示例的主体应用是Java编写的，然后结合了Serverless函数计算和Serverless工作流。下面我们来详细解析这个流程。</p>
<h3 id="u542F_u52A8_u6D41_u7A0B"><a href="#u542F_u52A8_u6D41_u7A0B" class="headerlink" title="启动流程"></a>启动流程</h3><p>按常理，开始点餐时流程就应该启动了，所以在这个示例中，我的设计是当我们选择完商品、商家、填完地址后启动流程：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%206.png" alt=""></p>
<p>这里我们通过Serverless工作流提供的OpenAPI来启动流程。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%207.png" alt=""></p>
<h4 id="Java_u542F_u52A8_u6D41_u7A0B"><a href="#Java_u542F_u52A8_u6D41_u7A0B" class="headerlink" title="Java启动流程"></a>Java启动流程</h4><p>这个示例我使用Serverless工作流的Java SDK，首先在POM文件中添加依赖：<br><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.aliyun&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;[4.3.2,5.0.0)&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.aliyun&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;aliyun-java-sdk-fnf&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;[1.0.0,5.0.0)&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p>
<p>然后创建初始化Java SDK的Config类：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="annotation">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FNFConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="annotation">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> IAcsClient <span class="title">createDefaultAcsClient</span><span class="params">()</span></span>&#123;</span><br><span class="line">        DefaultProfile profile = DefaultProfile.getProfile(</span><br><span class="line">                <span class="string">"cn-xxx"</span>,          <span class="comment">// 地域ID</span></span><br><span class="line">                <span class="string">"ak"</span>,      <span class="comment">// RAM 账号的AccessKey ID</span></span><br><span class="line">                <span class="string">"sk"</span>); <span class="comment">// RAM 账号Access Key Secret</span></span><br><span class="line">        IAcsClient client = <span class="keyword">new</span> DefaultAcsClient(profile);</span><br><span class="line">        <span class="keyword">return</span> client;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>再来看Controller中的<code>startFNF</code>方法，该方法暴露GET方式的接口，传入三个参数：</p>
<ol>
<li><code>fnfname</code>：要启动的流程名称。</li>
<li><code>execuname</code>：流程启动后的流程实例名称。</li>
<li><code>input</code>：启动输入参数，比如业务参数。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="annotation">@GetMapping</span>(<span class="string">"/startFNF/&#123;fnfname&#125;/&#123;execuname&#125;/&#123;input&#125;"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> StartExecutionResponse <span class="title">startFNF</span><span class="params">(@PathVariable(<span class="string">"fnfname"</span>)</span> String fnfName,</span><br><span class="line">                                       @<span class="title">PathVariable</span><span class="params">(<span class="string">"execuname"</span>)</span> String execuName,</span><br><span class="line">                                       @<span class="title">PathVariable</span><span class="params">(<span class="string">"input"</span>)</span> String inputStr) <span class="keyword">throws</span> ClientException </span>&#123;</span><br><span class="line">    JSONObject jsonObject = <span class="keyword">new</span> JSONObject();</span><br><span class="line">    jsonObject.put(<span class="string">"fnfname"</span>, fnfName);</span><br><span class="line">    jsonObject.put(<span class="string">"execuname"</span>, execuName);</span><br><span class="line">    jsonObject.put(<span class="string">"input"</span>, inputStr);</span><br><span class="line">    <span class="keyword">return</span> fnfService.startFNF(jsonObject);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再来看Service中的<code>startFNF</code>方法，该方法分两部分，第一个部分是启动流程，第二部分是创建订单对象，并模拟入库（示例中是放在Map里了）：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> StartExecutionResponse <span class="title">startFNF</span><span class="params">(JSONObject jsonObject)</span> <span class="keyword">throws</span> ClientException </span>&#123;</span><br><span class="line">    StartExecutionRequest request = <span class="keyword">new</span> StartExecutionRequest();</span><br><span class="line">    String orderNum = jsonObject.getString(<span class="string">"execuname"</span>);</span><br><span class="line">    request.setFlowName(jsonObject.getString(<span class="string">"fnfname"</span>));</span><br><span class="line">    request.setExecutionName(orderNum);</span><br><span class="line">    request.setInput(jsonObject.getString(<span class="string">"input"</span>));</span><br><span class="line"></span><br><span class="line">    JSONObject inputObj = jsonObject.getJSONObject(<span class="string">"input"</span>);</span><br><span class="line">    Order order = <span class="keyword">new</span> Order();</span><br><span class="line">    order.setOrderNum(orderNum);</span><br><span class="line">    order.setAddress(inputObj.getString(<span class="string">"address"</span>));</span><br><span class="line">    order.setProducts(inputObj.getString(<span class="string">"products"</span>));</span><br><span class="line">    order.setSupplier(inputObj.getString(<span class="string">"supplier"</span>));</span><br><span class="line">    orderMap.put(orderNum, order);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> iAcsClient.getAcsResponse(request);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>启动流程时，流程名称和启动流程实例的名称是需要传入的参数，这里我将每次的订单编号作为启动流程的实例名称。至于Input，可以根据需求构造JSON字符串传入。这里我将商品、商家、地址、订单号构造了JSON字符串在流程启动时传入流程中。</p>
<p>另外，创建了此次订单的<code>Order</code>实例，并存在<code>Map</code>中，模拟入库，后续环节还会查询该订单实例更新订单属性。</p>
<h4 id="VUE_u9009_u62E9_u5546_u54C1/_u5546_u5BB6_u9875_u9762"><a href="#VUE_u9009_u62E9_u5546_u54C1/_u5546_u5BB6_u9875_u9762" class="headerlink" title="VUE选择商品/商家页面"></a>VUE选择商品/商家页面</h4><p>前端我使用VUE搭建，当点击选择商品和商家页面中的下一步后，通过GET方式调用HTTP协议的接口<code>/startFNF/{fnfname}/{execuname}/{input}</code>。和上面的Java方法对应。</p>
<ol>
<li><code>fnfname</code>：要启动的流程名称。</li>
<li><code>execuname</code>：随机生成uuid，作为订单的编号，也作为启动流程实例的名称。</li>
<li><code>input</code>：将商品、商家、订单号、地址构建为JSON字符串传入流程。<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">submitOrder()&#123;</span><br><span class="line">    <span class="keyword">const</span> orderNum = uuid.v1()</span><br><span class="line">    <span class="keyword">this</span>.$axios.$get(<span class="string">'/startFNF/OrderDemo-Jiyuan/'</span>+orderNum+<span class="string">'/&#123;\n'</span> +</span><br><span class="line">        <span class="string">'  "products": "'</span>+<span class="keyword">this</span>.products+<span class="string">'",\n'</span> +</span><br><span class="line">        <span class="string">'  "supplier": "'</span>+<span class="keyword">this</span>.supplier+<span class="string">'",\n'</span> +</span><br><span class="line">        <span class="string">'  "orderNum": "'</span>+orderNum+<span class="string">'",\n'</span> +</span><br><span class="line">        <span class="string">'  "address": "'</span>+<span class="keyword">this</span>.address+<span class="string">'"\n'</span> +</span><br><span class="line">        <span class="string">'&#125;'</span> ).then((response) =&gt; &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(response)</span><br><span class="line">        <span class="keyword">if</span>(response.message == <span class="string">"success"</span>)&#123;</span><br><span class="line">            <span class="keyword">this</span>.$router.push(<span class="string">'/orderdemo/'</span> + orderNum)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="generateInfo_u8282_u70B9"><a href="#generateInfo_u8282_u70B9" class="headerlink" title="generateInfo节点"></a>generateInfo节点</h3><p>第一个节点<code>generateInfo</code>，先来看看FDL的含义：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">- type: task</span><br><span class="line">  name: generateInfo</span><br><span class="line">  timeoutSeconds: <span class="number">300</span></span><br><span class="line">  resourceArn: acs:mns:::/topics/generateInfo-fnf-demo-jiyuan/messages</span><br><span class="line">  pattern: waitForCallback</span><br><span class="line">  inputMappings:</span><br><span class="line">    - target: taskToken</span><br><span class="line">      source: $context.task.token</span><br><span class="line">    - target: products</span><br><span class="line">      source: $input.products</span><br><span class="line">    - target: supplier</span><br><span class="line">      source: $input.supplier</span><br><span class="line">    - target: address</span><br><span class="line">      source: $input.address</span><br><span class="line">    - target: orderNum</span><br><span class="line">      source: $input.orderNum</span><br><span class="line">    - target: type</span><br><span class="line">      source: $context.step.name </span><br><span class="line">  outputMappings:</span><br><span class="line">    - target: paymentcombination</span><br><span class="line">      source: $local.paymentcombination</span><br><span class="line">    - target: orderNum</span><br><span class="line">      source: $local.orderNum</span><br><span class="line">  serviceParams:</span><br><span class="line">    MessageBody: $</span><br><span class="line">    Priority: <span class="number">1</span></span><br><span class="line">  <span class="keyword">catch</span>:</span><br><span class="line">    - errors:</span><br><span class="line">        - FnF.TaskTimeout</span><br><span class="line">      goto: orderCanceled</span><br></pre></td></tr></table></figure></p>
<ol>
<li><code>name</code>：节点名称。</li>
<li><code>timeoutSeconds</code>：超时时间。该节点等待的时长，超过时间后会跳转到<code>goto</code>分支指向的<code>orderCanceled</code>节点。</li>
<li><code>pattern</code>：设置为<code>waitForCallback</code>，表示需要等待确认。<code>inputMappings</code>：该节点入参。<ul>
<li><code>taskToken</code>：Serverless工作流自动生成的Token。</li>
<li><code>products</code>：选择的商品。</li>
<li><code>supplier</code>：选择的商家。</li>
<li><code>address</code>：送餐地址。</li>
<li><code>orderNum</code>：订单号。</li>
</ul>
</li>
<li><code>outputMappings</code>：该节点的出参。<ul>
<li><code>paymentcombination</code>：该商家支持的支付方式。</li>
<li><code>orderNum</code>：订单号。</li>
</ul>
</li>
<li><code>catch</code>：捕获异常，跳转到其他分支。</li>
</ol>
<p>这里<code>resourceArn</code>和<code>serviceParams</code>需要拿出来单独解释。Serverless工作流支持与多个云服务集成，即将其他服务作为任务步骤的执行单元。服务集成方式由FDL语言表达，在任务步骤中，可以使用<code>resourceArn</code>来定义集成的目标服务，使用<code>pattern</code>定义集成模式。所以可以看到在<code>resourceArn</code>中配置<code>acs:mns:::/topics/generateInfo-fnf-demo-jiyuan/messages</code>信息，即在<code>generateInfo</code>节点中集成了MNS消息队列服务，当<code>generateInfo</code>节点触发后会向<code>generateInfo-fnf-demo-jiyuan</code>Topic中发送一条消息。那么消息正文和参数则在<code>serviceParams</code>对象中指定。<code>MessageBody</code>是消息正文，配置<code>$</code>表示通过输入映射<code>inputMappings</code>产生消息正文。</p>
<p>看完第一个节点的示例，大家可以看到，在Serverless工作流中，节点之间的信息传递可以通过集成MNS发送消息来传递，也是使用比较广泛的方式之一。</p>
<h3 id="generateInfo-fnf-demo_u51FD_u6570"><a href="#generateInfo-fnf-demo_u51FD_u6570" class="headerlink" title="generateInfo-fnf-demo函数"></a>generateInfo-fnf-demo函数</h3><p>向<code>generateInfo-fnf-demo-jiyuan</code>Topic中发送的这条消息包含了商品信息、商家信息、地址、订单号，表示一个下订单流程的开始，既然有发消息，那么必然有接受消息进行后续处理。所以打开<a href="https://fc.console.aliyun.com/fc/overview/cn-hangzhou" target="_blank" rel="external">函数计算控制台</a>，创建服务，在服务下创建名为<code>generateInfo-fnf-demo</code>的事件触发器函数，这里选择Python Runtime：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%208.png" alt=""></p>
<p>创建MNS触发器，选择监听<code>generateInfo-fnf-demo-jiyuan</code>Topic。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%209.png" alt=""></p>
<p>打开<a href="https://mns.console.aliyun.com/?spm=5176.10695662.J_8058803260.1265.1de04783MJKJ82#/Mnstheme?regionId=cn-hangzhou" target="_blank" rel="external">消息服务MNS控制台</a>，创建<code>generateInfo-fnf-demo-jiyuan</code>Topic：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2010.png" alt=""></p>
<p>做好函数的准备工作，我们来开始写代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.client <span class="keyword">import</span> AcsClient</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.acs_exception.exceptions <span class="keyword">import</span> ServerException</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskSucceededRequest</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskFailedRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(event, context)</span>:</span></span><br><span class="line">	<span class="comment"># 1. 构建Serverless工作流Client</span></span><br><span class="line">    region = <span class="string">"cn-hangzhou"</span></span><br><span class="line">    account_id = <span class="string">"XXXX"</span></span><br><span class="line">    ak_id = <span class="string">"XXX"</span></span><br><span class="line">    ak_secret = <span class="string">"XXX"</span></span><br><span class="line">    fnf_client = AcsClient(</span><br><span class="line">        ak_id,</span><br><span class="line">        ak_secret,</span><br><span class="line">        region</span><br><span class="line">    )</span><br><span class="line">    logger = logging.getLogger()</span><br><span class="line">	<span class="comment"># 2. event内的信息即接受到Topic generateInfo-fnf-demo-jiyuan中的消息内容，将其转换为Json对象</span></span><br><span class="line">    bodyJson = json.loads(event)</span><br><span class="line">    logger.info(<span class="string">"products:"</span> + bodyJson[<span class="string">"products"</span>])</span><br><span class="line">    logger.info(<span class="string">"supplier:"</span> + bodyJson[<span class="string">"supplier"</span>])</span><br><span class="line">    logger.info(<span class="string">"address:"</span> + bodyJson[<span class="string">"address"</span>])</span><br><span class="line">    logger.info(<span class="string">"taskToken:"</span> + bodyJson[<span class="string">"taskToken"</span>])</span><br><span class="line">    supplier = bodyJson[<span class="string">"supplier"</span>]</span><br><span class="line">    taskToken = bodyJson[<span class="string">"taskToken"</span>]</span><br><span class="line">    orderNum = bodyJson[<span class="string">"orderNum"</span>]</span><br><span class="line">	<span class="comment"># 3. 判断什么商家使用什么样的支付方式组合，这里的示例比较简单粗暴，正常情况下，应该使用元数据配置的方式获取</span></span><br><span class="line">    paymentcombination = <span class="string">""</span></span><br><span class="line">    <span class="keyword">if</span> supplier == <span class="string">"haidilao"</span>:</span><br><span class="line">        paymentcombination = <span class="string">"zhifubao,weixin"</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        paymentcombination = <span class="string">"zhifubao,weixin,unionpay"</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 4. 调用Java服务暴露的接口，更新订单信息，主要是更新支付方式</span></span><br><span class="line">    url = <span class="string">"http://xx.xx.xx.xx:8080/setPaymentCombination/"</span> + orderNum + <span class="string">"/"</span> + paymentcombination + <span class="string">"/0"</span></span><br><span class="line">    x = requests.get(url)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 5. 给予generateInfo节点响应，并返回数据，这里返回了订单号和支付方式</span></span><br><span class="line">    output = <span class="string">"&#123;\"orderNum\": \"%s\", \"paymentcombination\":\"%s\" "</span> \</span><br><span class="line">                         <span class="string">"&#125;"</span> % (orderNum, paymentcombination)</span><br><span class="line">    request = ReportTaskSucceededRequest.ReportTaskSucceededRequest()</span><br><span class="line">    request.set_Output(output)</span><br><span class="line">    request.set_TaskToken(taskToken)</span><br><span class="line">    resp = fnf_client.do_action_with_exception(request)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure></p>
<p>因为<code>generateInfo-fnf-demo</code>函数配置了MNS触发器，所以当Topic<code>generateInfo-fnf-demo-jiyuan</code>有消息后就会触发执行<code>generateInfo-fnf-demo</code>函数。</p>
<p>整个代码分五部分：</p>
<ol>
<li>构建Serverless工作流Client。</li>
<li>event内的信息即接受到Topic<code>generateInfo-fnf-demo-jiyuan</code>中的消息内容，将其转换为Json对象。</li>
<li>判断什么商家使用什么样的支付方式组合，这里的示例比较简单粗暴，正常情况下，应该使用元数据配置的方式获取。比如在系统内有商家信息的配置功能，通过在界面上配置该商家支持哪些支付方式，形成元数据配置信息，提供查询接口，在这里进行查询。</li>
<li>调用Java服务暴露的接口，更新订单信息，主要是更新支付方式。</li>
<li>给予<code>generateInfo</code>节点响应，并返回数据，这里返回了订单号和支付方式。因为该节点的<code>pattern</code>是<code>waitForCallback</code>，所以需要等待响应结果。</li>
</ol>
<h3 id="payment_u8282_u70B9"><a href="#payment_u8282_u70B9" class="headerlink" title="payment节点"></a>payment节点</h3><p>我们再来看第二个节点<code>payment</code>，先来看FDL代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- type: task</span><br><span class="line">    name: payment</span><br><span class="line">    timeoutSeconds: <span class="number">300</span></span><br><span class="line">    resourceArn: acs:mns:::/topics/payment-fnf-demo-jiyuan/messages</span><br><span class="line">    pattern: waitForCallback</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $context.task.token</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: paymentcombination</span><br><span class="line">        source: $local.paymentcombination</span><br><span class="line">      - target: type</span><br><span class="line">        source: $context.step.name </span><br><span class="line">    outputMappings:</span><br><span class="line">      - target: paymentMethod</span><br><span class="line">        source: $local.paymentMethod</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: price</span><br><span class="line">        source: $local.price</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $input.taskToken</span><br><span class="line">    serviceParams:</span><br><span class="line">      MessageBody: $</span><br><span class="line">      Priority: <span class="number">1</span></span><br><span class="line">    catch:</span><br><span class="line">      - errors:</span><br><span class="line">          - FnF.TaskTimeout</span><br><span class="line">        goto: orderCanceled</span><br></pre></td></tr></table></figure></p>
<p>当流程流转到<code>payment</code>节点后，意味着用户进入了支付页面。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2011.png" alt=""></p>
<p>这时<code>payment</code>节点会向MNS的Topic<code>payment-fnf-demo-jiyuan</code>发送消息，会触发<code>payment-fnf-demo</code>函数。</p>
<h3 id="payment-fnf-demo_u51FD_u6570"><a href="#payment-fnf-demo_u51FD_u6570" class="headerlink" title="payment-fnf-demo函数"></a>payment-fnf-demo函数</h3><p><code>payment-fnf-demo</code>函数的创建方式和<code>generateInfo-fnf-demo</code>函数类似，这里不再累赘。我们直接来看代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.client <span class="keyword">import</span> AcsClient</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.acs_exception.exceptions <span class="keyword">import</span> ServerException</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.client <span class="keyword">import</span> AcsClient</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskSucceededRequest</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskFailedRequest</span><br><span class="line"><span class="keyword">from</span> mns.account <span class="keyword">import</span> Account  <span class="comment"># pip install aliyun-mns</span></span><br><span class="line"><span class="keyword">from</span> mns.queue <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(event, context)</span>:</span></span><br><span class="line">    logger = logging.getLogger()</span><br><span class="line">    region = <span class="string">"xxx"</span></span><br><span class="line">    account_id = <span class="string">"xxx"</span></span><br><span class="line">    ak_id = <span class="string">"xxx"</span></span><br><span class="line">    ak_secret = <span class="string">"xxx"</span></span><br><span class="line">    mns_endpoint = <span class="string">"http://your_account_id.mns.cn-hangzhou.aliyuncs.com/"</span></span><br><span class="line">    queue_name = <span class="string">"payment-queue-fnf-demo"</span></span><br><span class="line">    my_account = Account(mns_endpoint, ak_id, ak_secret)</span><br><span class="line">    my_queue = my_account.get_queue(queue_name)</span><br><span class="line">    <span class="comment"># my_queue.set_encoding(False)</span></span><br><span class="line">    fnf_client = AcsClient(</span><br><span class="line">        ak_id,</span><br><span class="line">        ak_secret,</span><br><span class="line">        region</span><br><span class="line">    )</span><br><span class="line">    eventJson = json.loads(event)</span><br><span class="line"></span><br><span class="line">    isLoop = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">while</span> isLoop:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            recv_msg = my_queue.receive_message(<span class="number">30</span>)</span><br><span class="line">            isLoop = <span class="keyword">False</span></span><br><span class="line">            <span class="comment"># body = json.loads(recv_msg.message_body)</span></span><br><span class="line">            logger.info(<span class="string">"recv_msg.message_body:======================"</span> + recv_msg.message_body)</span><br><span class="line">            msgJson = json.loads(recv_msg.message_body)</span><br><span class="line">            my_queue.delete_message(recv_msg.receipt_handle)</span><br><span class="line">            <span class="comment"># orderCode = int(time.time())</span></span><br><span class="line">            task_token = eventJson[<span class="string">"taskToken"</span>]</span><br><span class="line">            orderNum = eventJson[<span class="string">"orderNum"</span>]</span><br><span class="line">            output = <span class="string">"&#123;\"orderNum\": \"%s\", \"paymentMethod\": \"%s\", \"price\": \"%s\" "</span> \</span><br><span class="line">                         <span class="string">"&#125;"</span> % (orderNum, msgJson[<span class="string">"paymentMethod"</span>], msgJson[<span class="string">"price"</span>])</span><br><span class="line">            request = ReportTaskSucceededRequest.ReportTaskSucceededRequest()</span><br><span class="line">            request.set_Output(output)</span><br><span class="line">            request.set_TaskToken(task_token)</span><br><span class="line">            resp = fnf_client.do_action_with_exception(request)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            logger.info(<span class="string">"new loop"</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure></p>
<p>该函数的核心思路是等待用户在支付页面选择某个支付方式确认支付。所以这里使用了MNS的队列来模拟等待。循环等待接收队列<code>payment-queue-fnf-demo</code>中的消息，当收到消息后将订单号和用户选择的具体支付方式以及金额返回给<code>payment</code>节点。</p>
<h3 id="VUE_u9009_u62E9_u652F_u4ED8_u65B9_u5F0F_u9875_u9762"><a href="#VUE_u9009_u62E9_u652F_u4ED8_u65B9_u5F0F_u9875_u9762" class="headerlink" title="VUE选择支付方式页面"></a>VUE选择支付方式页面</h3><p>因为经过<code>generateInfo</code>节点后，该订单的支付方式信息已经有了，所以对于用户而言，当填完商品、商家、地址后，跳转到的页面就是该确认支付页面，并且包含了该商家支持的支付方式。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2012.png" alt=""></p>
<p>当进入该页面后，会请求Java服务暴露的接口，获取订单信息，根据支付方式在页面上显示不同的支付方式。代码片段如下：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2013.png" alt=""></p>
<p>当用户选定某个支付方式点击提交订单按钮后，向<code>payment-queue-fnf-demo</code>队列发送消息，即通知<code>payment-fnf-demo</code>函数继续后续的逻辑。</p>
<p>这里我使用了一个HTTP触发器类型的函数，用于实现向MNS发消息的逻辑，<code>paymentMethod-fnf-demo</code>函数代码如下。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> mns.account <span class="keyword">import</span> Account  <span class="comment"># pip install aliyun-mns</span></span><br><span class="line"><span class="keyword">from</span> mns.queue <span class="keyword">import</span> *</span><br><span class="line">HELLO_WORLD = <span class="string">b'Hello world!\n'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(environ, start_response)</span>:</span></span><br><span class="line">    logger = logging.getLogger()  </span><br><span class="line">    context = environ[<span class="string">'fc.context'</span>]</span><br><span class="line">    request_uri = environ[<span class="string">'fc.request_uri'</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> environ.items():</span><br><span class="line">      <span class="keyword">if</span> k.startswith(<span class="string">'HTTP_'</span>):</span><br><span class="line">        <span class="comment"># process custom request headers</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">try</span>:        </span><br><span class="line">        request_body_size = int(environ.get(<span class="string">'CONTENT_LENGTH'</span>, <span class="number">0</span>))    </span><br><span class="line">    <span class="keyword">except</span> (ValueError):        </span><br><span class="line">        request_body_size = <span class="number">0</span>   </span><br><span class="line">    request_body = environ[<span class="string">'wsgi.input'</span>].read(request_body_size)  </span><br><span class="line">    paymentMethod = urllib.parse.unquote(request_body.decode(<span class="string">"GBK"</span>))</span><br><span class="line">    logger.info(paymentMethod)</span><br><span class="line">    paymentMethodJson = json.loads(paymentMethod)</span><br><span class="line"></span><br><span class="line">    region = <span class="string">"cn-xxx"</span></span><br><span class="line">    account_id = <span class="string">"xxx"</span></span><br><span class="line">    ak_id = <span class="string">"xxx"</span></span><br><span class="line">    ak_secret = <span class="string">"xxx"</span></span><br><span class="line">    mns_endpoint = <span class="string">"http://your_account_id.mns.cn-hangzhou.aliyuncs.com/"</span></span><br><span class="line">    queue_name = <span class="string">"payment-queue-fnf-demo"</span></span><br><span class="line">    my_account = Account(mns_endpoint, ak_id, ak_secret)</span><br><span class="line">    my_queue = my_account.get_queue(queue_name)</span><br><span class="line">    output = <span class="string">"&#123;\"paymentMethod\": \"%s\", \"price\":\"%s\" "</span> \</span><br><span class="line">                         <span class="string">"&#125;"</span> % (paymentMethodJson[<span class="string">"paymentMethod"</span>], paymentMethodJson[<span class="string">"price"</span>])</span><br><span class="line">    msg = Message(output)</span><br><span class="line">    my_queue.send_message(msg)</span><br><span class="line">    </span><br><span class="line">    status = <span class="string">'200 OK'</span></span><br><span class="line">    response_headers = [(<span class="string">'Content-type'</span>, <span class="string">'text/plain'</span>)]</span><br><span class="line">    start_response(status, response_headers)</span><br><span class="line">    <span class="keyword">return</span> [HELLO_WORLD]</span><br></pre></td></tr></table></figure></p>
<p>该函数的逻辑很简单，就是向MNS的队列<code>payment-queue-fnf-demo</code>发送用户选择的支付方式和金额。</p>
<p>VUE代码片段如下：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2014.png" alt=""></p>
<h3 id="paymentCombination_u8282_u70B9"><a href="#paymentCombination_u8282_u70B9" class="headerlink" title="paymentCombination节点"></a>paymentCombination节点</h3><p><code>paymentCombination</code>节点是一个路由节点，通过判断某个参数路由到不同的节点，这里自然使用<code>paymentMethod</code>作为判断条件。FDL代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- type: choice</span><br><span class="line">    name: paymentCombination</span><br><span class="line">    inputMappings:</span><br><span class="line">      - target: orderNum</span><br><span class="line">        source: $local.orderNum</span><br><span class="line">      - target: paymentMethod</span><br><span class="line">        source: $local.paymentMethod</span><br><span class="line">      - target: price</span><br><span class="line">        source: $local.price</span><br><span class="line">      - target: taskToken</span><br><span class="line">        source: $local.taskToken</span><br><span class="line">    choices:</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"zhifubao"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: zhifubao</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan/functions/zhifubao-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">              - target: price</span><br><span class="line">                source: $input.price             </span><br><span class="line">              - target: orderNum</span><br><span class="line">                source: $input.orderNum </span><br><span class="line">              - target: paymentMethod</span><br><span class="line">                source: $input.paymentMethod</span><br><span class="line">              - target: taskToken</span><br><span class="line">                source: $input.taskToken</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"weixin"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: weixin</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/weixin-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">            - target: price</span><br><span class="line">              source: $input.price             </span><br><span class="line">            - target: orderNum</span><br><span class="line">              source: $input.orderNum</span><br><span class="line">            - target: paymentMethod</span><br><span class="line">              source: $input.paymentMethod</span><br><span class="line">            - target: taskToken</span><br><span class="line">              source: $input.taskToken</span><br><span class="line">      - condition: $.paymentMethod == <span class="string">"unionpay"</span></span><br><span class="line">        steps:</span><br><span class="line">          - type: task</span><br><span class="line">            name: unionpay</span><br><span class="line">            resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan.LATEST/functions/union-fnf-demo</span><br><span class="line">            inputMappings:</span><br><span class="line">            - target: price</span><br><span class="line">              source: $input.price             </span><br><span class="line">            - target: orderNum</span><br><span class="line">              source: $input.orderNum </span><br><span class="line">            - target: paymentMethod</span><br><span class="line">              source: $input.paymentMethod</span><br><span class="line">            - target: taskToken</span><br><span class="line">              source: $input.taskToken</span><br><span class="line">    default:</span><br><span class="line">      goto: orderCanceled</span><br></pre></td></tr></table></figure></p>
<p>这里的流程是，用户选择支付方式后，通过消息发送给<code>payment-fnf-demo</code>函数，然后将支付方式返回，于是流转到<code>paymentCombination</code>节点通过判断支付方式流转到具体处理支付逻辑的节点和函数。</p>
<h3 id="zhifubao_u8282_u70B9"><a href="#zhifubao_u8282_u70B9" class="headerlink" title="zhifubao节点"></a>zhifubao节点</h3><p>我们具体来看一个<code>zhifubao</code>节点：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">choices:</span><br><span class="line">  - condition: $.paymentMethod == <span class="string">"zhifubao"</span></span><br><span class="line">    steps:</span><br><span class="line">      - type: task</span><br><span class="line">        name: zhifubao</span><br><span class="line">        resourceArn: acs:fc:cn-hangzhou:your_account_id:services/FNFDemo-jiyuan/functions/zhifubao-fnf-demo</span><br><span class="line">        inputMappings:</span><br><span class="line">          - target: price</span><br><span class="line">            source: $input.price             </span><br><span class="line">          - target: orderNum</span><br><span class="line">            source: $input.orderNum </span><br><span class="line">          - target: paymentMethod</span><br><span class="line">            source: $input.paymentMethod</span><br><span class="line">          - target: taskToken</span><br><span class="line">            source: $input.taskToken</span><br></pre></td></tr></table></figure></p>
<p>这个节点的<code>resourceArn</code>和之前两个节点的不同，这里配置的是函数计算中函数的ARN，也就是说当流程流转到这个节点时会触发<code>zhifubao-fnf-demo</code>函数，该函数是一个事件触发函数，但不需要创建任何触发器。流程将订单金额、订单号、支付方式传给<code>zhifubao-fnf-demo</code>函数。</p>
<h3 id="zhifubao-fnf-demo_u51FD_u6570"><a href="#zhifubao-fnf-demo_u51FD_u6570" class="headerlink" title="zhifubao-fnf-demo函数"></a>zhifubao-fnf-demo函数</h3><p>来看<code>zhifubao-fnf-demo</code>函数的代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.client <span class="keyword">import</span> AcsClient</span><br><span class="line"><span class="keyword">from</span> aliyunsdkcore.acs_exception.exceptions <span class="keyword">import</span> ServerException</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskSucceededRequest</span><br><span class="line"><span class="keyword">from</span> aliyunsdkfnf.request.v20190315 <span class="keyword">import</span> ReportTaskFailedRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(event, context)</span>:</span></span><br><span class="line">  region = <span class="string">"cn-xxx"</span></span><br><span class="line">  account_id = <span class="string">"xxx"</span></span><br><span class="line">  ak_id = <span class="string">"xxx"</span></span><br><span class="line">  ak_secret = <span class="string">"xxx"</span></span><br><span class="line">  fnf_client = AcsClient(</span><br><span class="line">    ak_id,</span><br><span class="line">    ak_secret,</span><br><span class="line">    region</span><br><span class="line">  )</span><br><span class="line">  logger = logging.getLogger()</span><br><span class="line">  logger.info(event)</span><br><span class="line">  bodyJson = json.loads(event)</span><br><span class="line">  price = bodyJson[<span class="string">"price"</span>]</span><br><span class="line">  taskToken = bodyJson[<span class="string">"taskToken"</span>]</span><br><span class="line">  orderNum = bodyJson[<span class="string">"orderNum"</span>]</span><br><span class="line">  paymentMethod = bodyJson[<span class="string">"paymentMethod"</span>]</span><br><span class="line">  logger.info(<span class="string">"price:"</span> + price)</span><br><span class="line">  newPrice = int(price) * <span class="number">0.8</span></span><br><span class="line">  logger.info(<span class="string">"newPrice:"</span> + str(newPrice))</span><br><span class="line">  url = <span class="string">"http://xx.xx.xx.xx:8080/setPaymentCombination/"</span> + orderNum + <span class="string">"/"</span> + paymentMethod + <span class="string">"/"</span> + str(newPrice)</span><br><span class="line">  x = requests.get(url)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> &#123;<span class="string">"Status"</span>:<span class="string">"ok"</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>示例中的代码逻辑很简单，接收到金额后，将金额打8折，然后将价格更新回订单。其他支付方式的节点和函数如法炮制，变更实现逻辑就可以，在这个示例中，微信支付打了5折，银联支付打7折。</p>
<h3 id="u5B8C_u6574_u6D41_u7A0B"><a href="#u5B8C_u6574_u6D41_u7A0B" class="headerlink" title="完整流程"></a>完整流程</h3><p>流程中的<code>orderCompleted</code>和<code>orderCanceled</code>节点没做什么逻辑，大家可以自行发挥，思路和之前的节点一样。所以完整的流程是这样：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2015.png" alt=""><br>从Serverless工作流中看到的节点流转是这样的：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%2016.png" alt=""></p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>到此，我们基于Serverless工作流和Serverless函数计算构建的订单模块示例就算完成了，在示例中，有两个点需要大家注意：</p>
<ol>
<li>配置商家和支付方式的元数据规则。</li>
<li>确认支付页面的元数据规则。<br>因为在实际生产中，我们需要将可定制的部分都抽象为元数据描述，需要有配置界面制定商家的支付方式即更新元数据规则，然后前端页面基于元数据信息展示相应的内容。</li>
</ol>
<p>所以如果之后需要接入其他的支付方式，只需在<code>paymentCombination</code>路由节点中确定好路由规则，然后增加对应的支付方式函数即可。通过增加元数据配置项，就可以在页面显示新加的支付方式，并且路由到处理新支付方式的函数中。</p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p>随着互联网人口红利逐渐减弱，基于流量的增长已经放缓，互联网行业迫切需要找到一片足以承载自身持续增长的新蓝海。产业互联网正是这一宏大背景下的新趋势。我们看到互联网浪潮正在席卷传统行业，云计算、大数据、人工智能开始大规模融入到金融、制造、物流、零售、文娱、教育、医疗等行业的生产环节中，这种融合称为产业互联网。而在产业互联网中，有一块不可小觑的领域是SaaS领域，它是ToB赛道的中间力量。比如CRM、HRM、费控系统、财务系统、协同办公等等。</p>
<h2 id="SaaS_u7CFB_u7EDF_u9762_u4E34_u7684_u6311_u6218"><a href="#SaaS_u7CFB_u7EDF_u9762_u4E34_u7684_u6311_u6218" class="headerlink" title="SaaS系统面临的挑战"></a>SaaS系统面临的挑战</h2><p>在消费互联网时代，大家是<strong>搜</strong>我想要的东西，各个厂商在云计算、大数据、人工智能等技术基座之上建立流量最大化的服务与生态，基于海量内容分发与流量共享为逻辑构建系统。而到了产业互联网时代，供给关系发生了变化，大家是<strong>定制</strong>我想要的东西，需要从供给与需求两侧出发进行双向建设，这个时候系统的灵活性和扩展性面临着前所未有的挑战，尤其是ToB的SaaS领域。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%201.png" alt=""></p>
<p>尤其当下的经济环境，SaaS厂商要明白，不能再通过烧钱的方式，只关注在自己的用户数量上，而更多的要思考如何帮助客户降低成本、增加效率，所以需要将更多的精力放在自己产品的定制化能力上。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_saas/%E5%9B%BE%E7%89%87%202.png" alt=""></p>
<h2 id="u5982_u4F55_u5E94_u5BF9_u6311_u6218"><a href="#u5982_u4F55_u5E94_u5BF9_u6311_u6218" class="headerlink" title="如何应对挑战"></a>如何应对挑战</h2><p>SaaS领域中的佼佼者Salesforce，将CRM的概念扩展到Marketing、Sales、Service，而这三块领域中只有Sales有专门的SaaS产品，其他两个领域都是各个ISV在不同行业的行业解决方案，靠的是什么？毋庸置疑，是Salesforce强大的aPaaS平台。ISV、内部实施、客户均可以在各自维度通过aPaaS平台构建自己行业、自己领域的SaaS系统，建立完整的生态。所以在我看来，现在的Salesforce已经由一家SaaS公司升华为一家aPaaS平台公司了。这种演进的过程也印证了消费互联网和产业互联网的转换逻辑以及后者的核心诉求。</p>
<p>然而不是所有SaaS公司都有财力和时间去孵化和打磨自己的aPaaS平台，但市场的变化、用户的诉求是实实在在存在的，若要生存，就要求变。这个变的核心就是能够让自己目前的SaaS系统变的灵活起来。相对建设困难的aPaaS平台，我们其实可以选择轻量且有效的Serverless方案来提升现有系统的灵活性和可扩展性，从而实现用户不同的定制需求。</p>
<h2 id="Serverless_u5DE5_u4F5C_u6D41"><a href="#Serverless_u5DE5_u4F5C_u6D41" class="headerlink" title="Serverless工作流"></a>Serverless工作流</h2><p>在上一篇文章<a href="http://www.devtalking.com/articles/serverless-online-coding/">《资源成本双优化！看Serverless颠覆编程教育的创新实践》</a>中，已经对Serverless的概念做过阐述了，并且也介绍了Serverless函数计算（FC）的概念和实践。这篇文章中介绍一下构建系统灵活性的核心要素服务编排，Serverless工作流。</p>
<p>Serverless 工作流（FnF）是一个用来协调多个分布式任务执行的全托管云服务。在 Serverless工作流中，可以用顺序、分支、并行等方式来编排分布式任务，Serverless工作流会按照设定好的步骤可靠地协调任务执行，跟踪每个任务的状态转换，并在必要时执行您定义的重试逻辑，以确保工作流顺利完成。Serverless工作流通过提供日志记录和审计来监视工作流的执行，可以轻松地诊断和调试应用。</p>]]>
    
    </summary>
    
      <category term="Serverless" scheme="http://www.devtalking.com/tags/Serverless/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Serverless在编程教育中的实践]]></title>
    <link href="http://www.devtalking.com//articles/serverless-online-coding/"/>
    <id>http://www.devtalking.com//articles/serverless-online-coding/</id>
    <published>2020-04-19T16:00:00.000Z</published>
    <updated>2021-02-03T16:01:52.369Z</updated>
    <content type="html"><![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>说起Serverless这个词，我想大家应该都不陌生，那么Serverless这个词到底是什么意思？Serverless到底能解决什么问题？可能很多朋友还没有深刻的体会和体感。这篇文章我就和大家一起聊聊Serverless。</p>
<h2 id="u4EC0_u4E48_u662FServerless"><a href="#u4EC0_u4E48_u662FServerless" class="headerlink" title="什么是Serverless"></a>什么是Serverless</h2><p>我们先将Serverless这个词拆开来看。Server，大家都知道是服务器的意思，说明Serverless解决的问题范围在服务端。Less，大家肯定也知道它的意思是较少的。那么Serverless连起来，再稍加修饰，那就是较少的关心服务器的意思。</p>
<h3 id="Serverfull_u65F6_u4EE3"><a href="#Serverfull_u65F6_u4EE3" class="headerlink" title="Serverfull时代"></a>Serverfull时代</h3><p>我们都知道，在研发侧都会有研发人员和运维人员两个角色，要开发一个新系统的时候，研发人员根据产品经理的PRD开始写代码开发功能，当功能开发、测试完之后，要发布到服务器。这个时候开始由运维人员规划服务器规格、服务器数量、每个服务部署的节点数量、服务器的扩缩容策略和机制、发布服务过程、服务优雅上下线机制等等。这种模式是研发和运维隔离，服务端运维都由专门的运维人员处理，而且很多时候是靠纯人力处理，也就是Serverfull时代。</p>
<h3 id="DevOps_u65F6_u4EE3"><a href="#DevOps_u65F6_u4EE3" class="headerlink" title="DevOps时代"></a>DevOps时代</h3><p>互联网公司里最辛苦的是谁？我相信大多数都是运维同学。白天做各种网络规划、环境规划、数据库规划等等，晚上熬夜发布新版本，做上线保障，而且很多事情是重复性的工作。然后慢慢就有了赋能研发这样的声音，运维同学帮助研发同学做一套运维控制台，可以让研发同学在运维控制台上自行发布服务、查看日志、查询数据。这样一来，运维同学主要维护这套运维控制台系统，并且不断完善功能，轻松了不少。这就是研发兼运维的DevOps时代。</p>
<h3 id="Serverless_u65F6_u4EE3"><a href="#Serverless_u65F6_u4EE3" class="headerlink" title="Serverless时代"></a>Serverless时代</h3><p>渐渐的，研发同学和运维同学的关注点都在运维控制台了，运维控制台的功能越来越强大，比如根据运维侧的需求增加了自动弹性扩缩、性能监控的功能，根据研发侧的需求增加了自动化发布的流水线功能。因为有了这套系统，代码质量检测、单元测试、打包编译、部署、集成测试、灰度发布、弹性扩缩、性能监控、应用防护这一系列服务端的工作基本上不需要人工参与处理了。这就是NoOps，Serverless时代。</p>
<a id="more"></a>
<h2 id="Serverless_u5728_u7F16_u7A0B_u6559_u80B2_u4E2D_u7684_u5E94_u7528"><a href="#Serverless_u5728_u7F16_u7A0B_u6559_u80B2_u4E2D_u7684_u5E94_u7528" class="headerlink" title="Serverless在编程教育中的应用"></a>Serverless在编程教育中的应用</h2><p>2020年注定是不平凡的一年，疫情期间，多少家企业如割韭菜般倒下，又有多少家企业如雨后春笋般茁壮成长，比如在线教育行业。</p>
<p>没错，在线教育行业是这次疫情的最大受益者，在在线教育在这个行业里，有一个细分市场是在线编程教育，尤其是少儿编程教育和面向非专业人士的编程教育，比如编程猫、斑马AI、小象学院等。这些企业的在线编程系统都有一些共同的特点和诉求：</p>
<ul>
<li>屏幕一侧写代码，执行代码，另一侧显示运行结果。</li>
<li>根据题目编写的代码都是代码块，每道题的代码量不会很大。</li>
<li>运行代码的速度要快。</li>
<li>支持多种编程语言。</li>
<li>能支撑不可预计的流量洪峰冲击。</li>
</ul>
<p>例如小象学院的编程课界面：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%201.png" alt=""></p>
<p>结合上述这些特点和诉求，不难看出，构建这样一套在线编程系统的核心在于有一个支持多种编程语言的、健壮高可用的代码运行环境。</p>
<p>那么我们先来看看传统的实现架构：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%202.png" alt=""></p>
<p>从High Level的架构来看，前端只需要将代码片段和编程语言的标识传给Server端即可，然后等待响应展示结果。所以整个Server端要负责对不同语言的代码进行分类、预处理然后传给不同编程语言的Runtime。这种架构有以下几个比较核心的问题。</p>
<h3 id="u5DE5_u4F5C_u91CF_u5927_uFF0C_u7075_u6D3B_u6027_u5DEE"><a href="#u5DE5_u4F5C_u91CF_u5927_uFF0C_u7075_u6D3B_u6027_u5DEE" class="headerlink" title="工作量大，灵活性差"></a>工作量大，灵活性差</h3><p>首先是研发和运维工作量的问题，当市场有新的需求，或者洞察到新业务模式时需要增加编程语言，此时研发侧需要增加编程代码分类和预处理的逻辑，另外需要构建对应编程语言的Runtime。在运维侧需要规划支撑新语言的服务器规格以及数量，还有整体的CICD流程等。所以支持新的编程语言这个需求要落地，需要研发、运维花费不少的时间来实现，再加上黑/白盒测试和CICD流程测试的时间，对市场需求的支撑不能快速的响应，灵活性相对较差。</p>
<h3 id="u9AD8_u53EF_u7528_u81EA_u5DF1_u515C_u5E95"><a href="#u9AD8_u53EF_u7528_u81EA_u5DF1_u515C_u5E95" class="headerlink" title="高可用自己兜底"></a>高可用自己兜底</h3><p>其次整个在线编程系统的稳定性是重中之重。所以所有Server端服务的高可用架构都需要自己搭建，用以保证流量高峰场景和稳态场景下的系统稳定。高可用一方面是代码逻辑编写的是否优雅和完善，另一方面是部署服务的集群，无论是ECS集群还是K8s集群，都需要研发和运维同学一起规划，那么对于对编程语言进行分类和预处理的服务来讲，尚能给定一个节点数，但是对于不同语言的Runtime服务来讲，市场需求随时会变，所以不好具体衡量每个服务的节点数。另外很重要的一点是所以服务的扩容，缩容机制都需要运维同学来实时手动操作，即便是通过脚本实现自动化，那么ECS弹起的速度也是远达不到业务预期的。</p>
<h3 id="u6210_u672C_u63A7_u5236_u7C92_u5EA6_u7C97"><a href="#u6210_u672C_u63A7_u5236_u7C92_u5EA6_u7C97" class="headerlink" title="成本控制粒度粗"></a>成本控制粒度粗</h3><p>再次是整个IaaS资源的成本控制，我们都知道这种在线教育是有明显的流量潮汐的，比如上午10点到12点，下午3点到5点，晚上8点到10点这几个时段是流量比较大的时候，其他时间端流量比较小，而且夜晚更是没什么流量。所以在这种情况下，传统的部署架构无法做到IaaS资源和流量的贴合。举个例子，加入为了应对流量高峰时期，需要20台ECS搭建集群来承载流量冲击，此时每台ECS的资源使用率可能在70%以上，利用率较高，但是在流量小的时候和夜晚，每台ECS的资源使用率可能就是百分之十几甚至更低，这就是一种资源浪费。</p>
<h3 id="Serverless_u67B6_u6784"><a href="#Serverless_u67B6_u6784" class="headerlink" title="Serverless架构"></a>Serverless架构</h3><p>那么我们来看看如何使用Serverless架构来实现同样的功能，并且解决上述几个问题。在选择Serverless产品时，在国内自然而然优先想到的就是阿里云的产品。阿里云有两款Serverless架构的产品Serverless 应用引擎和函数计算，这里我们使用函数计算来实现编程教育的场景。</p>
<p>函数计算（Function Compute）是事件驱动的全托管计算服务，简称FC。使用函数计算，我们无需采购与管理服务器等基础设施，只需编写并上传代码。函数计算为您准备好计算资源，弹性地、可靠地运行任务，并提供日志查询、性能监控和报警等功能。</p>
<p>这里不对FC的含义做过多赘述，只举一个例子。FC中有两个概念，一个是服务，一个是函数。一个服务包含多个函数：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%203.png" alt=""></p>
<p>这里拿Java微服务架构来对应，可以理解为，FC中的服务是Java中的一个类，FC中的函数是Java类中的一个方法：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%204.png" alt=""></p>
<p>但是Java类中的方法固然只能是Java代码，而FC中的函数可以设置不同语言的Runtime来运行不同的编程语言：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%205.png" alt=""></p>
<p>这个结构理解清楚之后，我们来看看如何调用FC的函数，这里会引出一个触发器的概念。我们最常使用的HTTP请求协议其实就是一种类型的触发器，在FC里称为HTTP触发器，除了HTTP触发器以外，还提供了OSS（对象存储）触发器、SLS（日志服务）触发器、定时触发器、MNS触发器、CDN触发器等。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%206.png" alt=""></p>
<p>从上图可以大概理解，我们可以通过多种途径调用FC中的函数。举例两个场景，比如每当我在指定的OSS Bucket的某个目录下上传一张图片后，就可以触发FC中的函数，函数的逻辑是将刚刚上传的图片下载下来，然后对图片做处理，然后再上传回OSS。再比如向MNS的某个队列发送一条消息，然后触发FC中的函数来处理针对这条消息的逻辑。</p>
<p>最后我们再来看看FC的高可用。每一个函数在运行代码时底层肯定还是IaaS资源，但我们只需要给每个函数设置运行代码时需要的内存数即可，最小128M，最大3G，对使用者而言，不需要考虑多少核数，也不需要知道代码运行在什么样的服务器上，不需要关心启动了多少个函数实例，也不需要关心弹性扩缩的问题等，这些都由FC来处理。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%207.png" alt=""></p>
<p>从上图可以看到，高可用有两种策略：</p>
<ul>
<li>给函数设置并发实例数，假如设置为3，那么有三个请求进来时，该函数只启一个实例，但是会启三个线程来运行逻辑。</li>
<li>线程数达到上限后，会再拉起一个函数实例。</li>
</ul>
<p>大家看到这里，可能已经大概对基于FC实现在线编程教育系统的架构有了一个大概的轮廓。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%208.png" alt=""></p>
<p>上图是基于FC实现的在线编程教育系统的架构图，在这个架构下来看看上述那三个核心问题怎么解：</p>
<ul>
<li>工作量和灵活性：我们只需要关注在如何执行代码的业务逻辑上，如果要加新语言，只需要创建一个对应语言Runtime的FC函数即可。</li>
<li>高可用：多线程运行业务逻辑和多实例运行业务逻辑两层高可用保障，并且函数实例的扩缩完全都是FC自动处理，不需要研发和运维同学做任何配置。</li>
<li>成本优化：当没有请求的时候，函数实例是不会被拉起的，此时也不会计费，所以在流量低谷期或者夜间时，整个FC的成本消耗是非常低的。可以做到函数实例个数、计费粒度和流量完美的贴合。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%209.png" alt=""></p>
<h2 id="Python_u7F16_u7A0B_u8BED_u8A00_u793A_u4F8B"><a href="#Python_u7F16_u7A0B_u8BED_u8A00_u793A_u4F8B" class="headerlink" title="Python编程语言示例"></a>Python编程语言示例</h2><p>下面以运行Python代码为例来看看如何用FC实现Python在线编程Demo。</p>
<h3 id="u521B_u5EFA_u670D_u52A1_u548C_u51FD_u6570"><a href="#u521B_u5EFA_u670D_u52A1_u548C_u51FD_u6570" class="headerlink" title="创建服务和函数"></a>创建服务和函数</h3><p>打开函数计算（FC）<a href="https://fc.console.aliyun.com/fc/overview/cn-hangzhou" target="_blank" rel="external">控制台</a>，选择对应的Region，选择左侧服务/函数，然后新建服务：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2010.png" alt=""></p>
<p>输出服务名称，创建服务。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2011.png" alt=""></p>
<p>进入新创建的服务，然后创建函数，选择HTTP函数，即可配置HTTP触发器的函数：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2012.png" alt=""></p>
<p>设置函数的各个参数：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2013.png" alt=""></p>
<p>几个需要的注意的参数这里做以说明：</p>
<ul>
<li>运行环境：这个很好理解，这里选择Python3</li>
<li>函数实例类型：这里有弹性实例和性能实例两种，前者最大支持2C3G规格的实例，后者支持更大的规格，最大到8C16G。</li>
<li>函数入口：详细参见<a href="https://help.aliyun.com/document_detail/74756.html?spm=a2c4g.11186623.6.572.195359cdselnzR" target="_blank" rel="external">文档</a></li>
<li>HTTP触发器认证方式：anonymous为不需要鉴权，function是需要鉴权的。</li>
</ul>
<h3 id="u4EE3_u7801_u89E3_u6790"><a href="#u4EE3_u7801_u89E3_u6790" class="headerlink" title="代码解析"></a>代码解析</h3><p>函数创建好，进入函数，可以看到概述、代码执行、触发器、日志查询等页签，我们先看触发器，会看到这个函数自动创建了一个HTTP触发器，有调用该函数对应的HTTP路径：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2014.png" alt=""></p>
<p>然后我们选择代码执行，直接在线写入我们的代码：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2015.png" alt=""></p>
<p>具体代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handler</span><span class="params">(environ, start_response)</span>:</span></span><br><span class="line">    context = environ[<span class="string">'fc.context'</span>]</span><br><span class="line">    request_uri = environ[<span class="string">'fc.request_uri'</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> environ.items():</span><br><span class="line">      <span class="keyword">if</span> k.startswith(<span class="string">'HTTP_'</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">try</span>:        </span><br><span class="line">        request_body_size = int(environ.get(<span class="string">'CONTENT_LENGTH'</span>, <span class="number">0</span>))    </span><br><span class="line">    <span class="keyword">except</span> (ValueError):        </span><br><span class="line">        request_body_size = <span class="number">0</span>   </span><br><span class="line">    <span class="comment"># 获取用户传入的code</span></span><br><span class="line">    request_body = environ[<span class="string">'wsgi.input'</span>].read(request_body_size)  </span><br><span class="line">    codeStr = urllib.parse.unquote(request_body.decode(<span class="string">"GBK"</span>))</span><br><span class="line">    <span class="comment"># 因为body里的对象里有code和input两个属性，这里分别获取用户code和用户输入</span></span><br><span class="line">    codeArr = codeStr.split(<span class="string">'&amp;'</span>)</span><br><span class="line">    code = codeArr[<span class="number">0</span>][<span class="number">5</span>:]</span><br><span class="line">    inputStr = codeArr[<span class="number">1</span>][<span class="number">6</span>:]</span><br><span class="line">    <span class="comment"># 将用户code保存为py文件，放/tmp目录下，以时间戳为文件名</span></span><br><span class="line">    fileName = <span class="string">'/tmp/'</span> + str(int(time.time())) + <span class="string">'.py'</span></span><br><span class="line">    f = open(fileName, <span class="string">"w"</span>)</span><br><span class="line">    <span class="comment"># 这里预置引入了time库</span></span><br><span class="line">    f.write(<span class="string">'import time \r\n'</span>)</span><br><span class="line">    f = open(fileName, <span class="string">"a"</span>)</span><br><span class="line">    f.write(code)</span><br><span class="line">    f.close()</span><br><span class="line">    <span class="comment"># 创建子进程，执行刚才保存的用户code py文件</span></span><br><span class="line">    p = subprocess.Popen(<span class="string">"python "</span> + fileName, stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE, shell=<span class="keyword">True</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment"># 通过标准输入传入用户的input输入</span></span><br><span class="line">    <span class="keyword">if</span> inputStr != <span class="string">''</span> :</span><br><span class="line">        p.stdin.write(inputStr + <span class="string">"\n"</span>)</span><br><span class="line">        p.stdin.flush()</span><br><span class="line">    <span class="comment"># 通过标准输出获取代码执行结果</span></span><br><span class="line">    r = p.stdout.read()</span><br><span class="line">    status = <span class="string">'200 OK'</span></span><br><span class="line">    response_headers = [(<span class="string">'Content-type'</span>, <span class="string">'text/plain'</span>)]</span><br><span class="line">    start_response(status, response_headers)</span><br><span class="line">    <span class="keyword">return</span> [r.encode(<span class="string">'UTF-8'</span>)]</span><br></pre></td></tr></table></figure></p>
<p>整个代码思路如下：</p>
<ul>
<li>从前端传入代码片段，格式是字符串。</li>
<li>在FC函数中获取到传入的代码字符串，截取code内容和input的内容。因为这里简单实现了Python中input交互的能力。</li>
<li>将代码保存为一个Python文件，以时间戳为文件名，保存在FC函数的/tmp目录下。（每个FC函数都有独立的/tmp目录，可以存放临时文件）</li>
<li>然后在文件中追加了引入time库的代码，应对sleep这种交互场景。</li>
<li>通过subprocess创建子进程，以Shell的方式通过Python命令执行保存在/tmp目录下的Python文件。如果有用户输入的信息，则通过标准输入输出写入子进程。</li>
<li>最后读取执行结果返回给前端。</li>
</ul>
<h3 id="u524D_u7AEF_u4EE3_u7801"><a href="#u524D_u7AEF_u4EE3_u7801" class="headerlink" title="前端代码"></a>前端代码</h3><p>前端我使用VUE写了简单的页面，这里解析两个简单的方法：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2016.png" alt=""></p>
<p>页面加载时初始化HTTP请求对象，调用的HTTP路径就是方才函数的HTTP触发器的路径。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2017.png" alt=""></p>
<p>这个方法就是调用FC中的PythonRuntime函数，将前端页面的代码片段传给该函数。这里处理input交互的思路是，扫描整个代码片段，以包含input代码为标识将整个代码段分成多段。没有包含input代码的直接送给FC函数执行，包含input代码的，请求用户的输入，然后代码片段带着用户输入的信息一起送给FC函数执行。<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/%E5%9B%BE%E7%89%87%2018.png" alt=""></p>
<p>演示如下：<br><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/2020/serverless_online_coding/lagoudemo.gif" alt=""></p>
<h2 id="u7ED3_u675F_u8BED"><a href="#u7ED3_u675F_u8BED" class="headerlink" title="结束语"></a>结束语</h2><p>这篇文章洋洋洒洒给大家介绍了Serverless，阿里云的Serverless产品函数计算（FC）以及基于函数计算（FC）实现的在线编程系统的Demo。大家应该有所体感，基于函数计算（FC）实现在线编程系统时，研发同学只需要专注在如何执行由前端传入的代码即可，整个Server端的各个环节都不需要研发同学和运维同学去关心，基本体现了Serverless的精髓。</p>
]]></content>
    <summary type="html">
    <![CDATA[<script data-ad-client="ca-pub-4115205380866695" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<p>说起Serverless这个词，我想大家应该都不陌生，那么Serverless这个词到底是什么意思？Serverless到底能解决什么问题？可能很多朋友还没有深刻的体会和体感。这篇文章我就和大家一起聊聊Serverless。</p>
<h2 id="u4EC0_u4E48_u662FServerless"><a href="#u4EC0_u4E48_u662FServerless" class="headerlink" title="什么是Serverless"></a>什么是Serverless</h2><p>我们先将Serverless这个词拆开来看。Server，大家都知道是服务器的意思，说明Serverless解决的问题范围在服务端。Less，大家肯定也知道它的意思是较少的。那么Serverless连起来，再稍加修饰，那就是较少的关心服务器的意思。</p>
<h3 id="Serverfull_u65F6_u4EE3"><a href="#Serverfull_u65F6_u4EE3" class="headerlink" title="Serverfull时代"></a>Serverfull时代</h3><p>我们都知道，在研发侧都会有研发人员和运维人员两个角色，要开发一个新系统的时候，研发人员根据产品经理的PRD开始写代码开发功能，当功能开发、测试完之后，要发布到服务器。这个时候开始由运维人员规划服务器规格、服务器数量、每个服务部署的节点数量、服务器的扩缩容策略和机制、发布服务过程、服务优雅上下线机制等等。这种模式是研发和运维隔离，服务端运维都由专门的运维人员处理，而且很多时候是靠纯人力处理，也就是Serverfull时代。</p>
<h3 id="DevOps_u65F6_u4EE3"><a href="#DevOps_u65F6_u4EE3" class="headerlink" title="DevOps时代"></a>DevOps时代</h3><p>互联网公司里最辛苦的是谁？我相信大多数都是运维同学。白天做各种网络规划、环境规划、数据库规划等等，晚上熬夜发布新版本，做上线保障，而且很多事情是重复性的工作。然后慢慢就有了赋能研发这样的声音，运维同学帮助研发同学做一套运维控制台，可以让研发同学在运维控制台上自行发布服务、查看日志、查询数据。这样一来，运维同学主要维护这套运维控制台系统，并且不断完善功能，轻松了不少。这就是研发兼运维的DevOps时代。</p>
<h3 id="Serverless_u65F6_u4EE3"><a href="#Serverless_u65F6_u4EE3" class="headerlink" title="Serverless时代"></a>Serverless时代</h3><p>渐渐的，研发同学和运维同学的关注点都在运维控制台了，运维控制台的功能越来越强大，比如根据运维侧的需求增加了自动弹性扩缩、性能监控的功能，根据研发侧的需求增加了自动化发布的流水线功能。因为有了这套系统，代码质量检测、单元测试、打包编译、部署、集成测试、灰度发布、弹性扩缩、性能监控、应用防护这一系列服务端的工作基本上不需要人工参与处理了。这就是NoOps，Serverless时代。</p>]]>
    
    </summary>
    
      <category term="Serverless" scheme="http://www.devtalking.com/tags/Serverless/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：重要配置和性能探讨]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-19/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-19/</id>
    <published>2019-04-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>最后这一章节总结Kafka中需要特别关注的重要配置以及影响Kafka性能的因素。</p>
<h3 id="u91CD_u8981_u914D_u7F6E"><a href="#u91CD_u8981_u914D_u7F6E" class="headerlink" title="重要配置"></a>重要配置</h3><ul>
<li><code>auto.create.topics.enable</code>：该配置项默认值是<code>true</code>，但在生产环境最好设置为<code>false</code>。这样可以控制创建Topic的人以及创建时间。</li>
<li><code>background.threads</code>：该配置项默认值是10，既整个Kafka在执行各种任务时会启动的线程数。如果你的CPU很强劲，那么可以将线程数设大一点。</li>
<li><code>delete.topic.enable</code>：该配置项默认值是<code>false</code>，可以根据实际需求改变，在生产环境还是建议保持默认值，这样至少不会出现Topic被误删的情况。</li>
<li><code>log.flush.interval.messages</code>：该配置项最好保持默认值，把这个任务交给操作系统的文件系统去处理。</li>
<li><code>log.retention.hours</code>：日志文件保留的时间默认是168小时，既7天。这个配置可以根据具体业务需求而定。</li>
<li><code>message.max.bytes</code>：每条Message或一批次Message的大小默认是1MB。这个配置也要根据具体需求而定，比如带宽的情况。</li>
<li><code>min.insync.replicas</code>：该配置项的默认值是1，既在acks=all时，最少得有一个Replica进行确认回执。建议在生产环境配置为2，保证数据的完整性。</li>
<li><code>num.io.threads</code>：处理I/O操作的线程数，默认是8个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.network.threads</code>：处理网络请求和响应的线程数，默认是3个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。默认值是1，根据实际情况配置数据目录数，从而判断该配置项应该如何设置。</li>
<li><code>num.replica.fetchers</code>：该配置项影响Replicas同步数据的速度，默认值是1，如果发现Replicas同步延迟较大，可以提升该配置项。</li>
<li><code>offsets.retention.minutes</code>：Offset保留的时间，默认值是1440，既24小时。在生产环境建议将该配置项设大一点，比如设置为1个月，保证消费数据的完整性。</li>
<li><code>unclean.leader.election.enable</code>：该配置项的作用是，指定是否可以将非ISR的Replicas选举为Leader，默认值为<code>false</code>。在生产环境建议保持默认值，防止数据丢失。</li>
<li><code>zookeeper.session.timeout.ms</code>：Zookeeper会话超时时间，默认值为6000。按实际情况而定，通常情况下保持60秒即可。</li>
<li><code>default.replication.factor</code>：默认Replication Factor为1，建议设置为2或者3，以保证数据完整性和整个集群的健壮性。</li>
<li><code>num.partitions</code>：Topic默认的Partition数，默认是1，建议设置为3或者6，以保证数据完整性和整个集群的健壮性。</li>
</ul>
<a id="more"></a>
<p>以上是比较重要，需要我们根据实际情况额外关注的配置项。</p>
<h3 id="u5F71_u54CD_u6027_u80FD_u7684_u56E0_u7D20"><a href="#u5F71_u54CD_u6027_u80FD_u7684_u56E0_u7D20" class="headerlink" title="影响性能的因素"></a>影响性能的因素</h3><p>影响Kafka性能大概有五个因素。</p>
<h4 id="u78C1_u76D8I/O"><a href="#u78C1_u76D8I/O" class="headerlink" title="磁盘I/O"></a>磁盘I/O</h4><p>我们知道Kafka是将大多数数据保存在磁盘上的。所以磁盘的读写性能很大程度上会影响Kafka系统的性能。所以我们可以注意以下几点：</p>
<ul>
<li>使用性能比较好的XFS日志文档系统，既Linux中的文件系统。</li>
<li>如果发现在I/O操作方面出现了瓶颈，那么可以通过扩充磁盘来改善。Broker配置文件中的<code>log.dirs</code>配置项可以配置多个数据目录路径。</li>
<li>设置合理的数据清理时间，也就是配置文件中的<code>log.retention.hours</code>配置项。如果已经消费的数据长时间保留在磁盘中，既没有意义又会对Kafka读写性能造成影响。</li>
<li>及时监控部署Kafka服务器的磁盘情况。</li>
</ul>
<h4 id="u7F51_u7EDC"><a href="#u7F51_u7EDC" class="headerlink" title="网络"></a>网络</h4><p>数据传输的延迟性是任何MQ系统都要关注的问题，Kafka也不例外，在这方面我们要注意以下几点：</p>
<ul>
<li>确保部署Kafka的服务器和部署Zookeeper的服务器在一个内网内，服务器之间的物理距离不要太远，比如一个在北京，一个在上海。</li>
<li>确保部署不同Kafka Broker的服务器在一个内网内，服务器之间的物理距离不要太远。</li>
<li>保证服务器有比较好的网络带宽配置。</li>
</ul>
<h4 id="RAM"><a href="#RAM" class="headerlink" title="RAM"></a>RAM</h4><p>Kafka的高性能特性离不开对计算机内存的使用技术，对内存的使用大体分Java堆内存的使用和操作系统（Linux）Page Cache的使用：</p>
<ul>
<li>在启动Kafka Broker时，可以通过环境变量<code>KAFKA_HEAP_OPTS</code>设置对Java堆内存的使用大小。比如<code>export KAFKA_HEAP_OPTS=“-Xmx4g”</code>。</li>
<li>Broker中的Partition数量会影响对Java堆内存的使用大小。Partition越多，堆内存使用的越多。</li>
<li>对于Page Cache/文件Cache，我们不用做任何设置：<blockquote>
<p>Page Cache：当应用程序需要读取文件中的数据时，操作系统先分配一些内存，将数据从存储设备读入到这些内存中，然后再将数据分发给应用程序；当需要往文件中写数据时，操作系统先分配内存接收用户数据，然后再将数据从内存写到磁盘上。文件 Cache 管理指的就是对这些由操作系统分配，并用来存储文件数据的内存的管理。</p>
</blockquote>
</li>
</ul>
<h4 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h4><p>因为Kafka在Message传输的整个过程中，不会对Message进行任何计算，所以CPU通常不会成为Kafka性能的主要瓶颈。但是在一些情况下，也会对Kafka的性能产生影响：</p>
<ul>
<li>Message加密/解密的过程中会增加CPU的负载。</li>
<li>Message压缩/解压的过程中会增加CPU的负载。</li>
<li>在GC堆内存时会增加CPU的负载。</li>
</ul>
<h4 id="u64CD_u4F5C_u7CFB_u7EDF"><a href="#u64CD_u4F5C_u7CFB_u7EDF" class="headerlink" title="操作系统"></a>操作系统</h4><p>通常优先推荐使用Linux系统，尤其在高性能计算领域，Linux已经成为一个占主导地位的操作系统。其次也可以使用Solaris系统。Windows系统是不推荐使用的。另外，尽量保证运行Kafka Broker的操作系统中，不要运行其他的应用程序，避免和Kafka产生资源竞争，从而影响性能。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这是本小册的最后一章节，探讨了Kafka的一些重要配置和影响Kafka性能的关键因素。整个小册从最基本的认知到核心概念的诠释再到实践，帮助小伙伴渡过Kafka和Zookeeper的萌新阶段。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>最后这一章节总结Kafka中需要特别关注的重要配置以及影响Kafka性能的因素。</p>
<h3 id="u91CD_u8981_u914D_u7F6E"><a href="#u91CD_u8981_u914D_u7F6E" class="headerlink" title="重要配置"></a>重要配置</h3><ul>
<li><code>auto.create.topics.enable</code>：该配置项默认值是<code>true</code>，但在生产环境最好设置为<code>false</code>。这样可以控制创建Topic的人以及创建时间。</li>
<li><code>background.threads</code>：该配置项默认值是10，既整个Kafka在执行各种任务时会启动的线程数。如果你的CPU很强劲，那么可以将线程数设大一点。</li>
<li><code>delete.topic.enable</code>：该配置项默认值是<code>false</code>，可以根据实际需求改变，在生产环境还是建议保持默认值，这样至少不会出现Topic被误删的情况。</li>
<li><code>log.flush.interval.messages</code>：该配置项最好保持默认值，把这个任务交给操作系统的文件系统去处理。</li>
<li><code>log.retention.hours</code>：日志文件保留的时间默认是168小时，既7天。这个配置可以根据具体业务需求而定。</li>
<li><code>message.max.bytes</code>：每条Message或一批次Message的大小默认是1MB。这个配置也要根据具体需求而定，比如带宽的情况。</li>
<li><code>min.insync.replicas</code>：该配置项的默认值是1，既在acks=all时，最少得有一个Replica进行确认回执。建议在生产环境配置为2，保证数据的完整性。</li>
<li><code>num.io.threads</code>：处理I/O操作的线程数，默认是8个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.network.threads</code>：处理网络请求和响应的线程数，默认是3个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。默认值是1，根据实际情况配置数据目录数，从而判断该配置项应该如何设置。</li>
<li><code>num.replica.fetchers</code>：该配置项影响Replicas同步数据的速度，默认值是1，如果发现Replicas同步延迟较大，可以提升该配置项。</li>
<li><code>offsets.retention.minutes</code>：Offset保留的时间，默认值是1440，既24小时。在生产环境建议将该配置项设大一点，比如设置为1个月，保证消费数据的完整性。</li>
<li><code>unclean.leader.election.enable</code>：该配置项的作用是，指定是否可以将非ISR的Replicas选举为Leader，默认值为<code>false</code>。在生产环境建议保持默认值，防止数据丢失。</li>
<li><code>zookeeper.session.timeout.ms</code>：Zookeeper会话超时时间，默认值为6000。按实际情况而定，通常情况下保持60秒即可。</li>
<li><code>default.replication.factor</code>：默认Replication Factor为1，建议设置为2或者3，以保证数据完整性和整个集群的健壮性。</li>
<li><code>num.partitions</code>：Topic默认的Partition数，默认是1，建议设置为3或者6，以保证数据完整性和整个集群的健壮性。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：搭建Kafka相关的UI工具]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-18/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-18/</id>
    <published>2019-03-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节主要介绍Zookeeper和Kafka的UI管理工具。</p>
<h3 id="ZKUI"><a href="#ZKUI" class="headerlink" title="ZKUI"></a>ZKUI</h3><p>ZKUI是一款简洁易用的Zookeeper信息管理工具。首先从<a href="https://github.com/DeemOpen/zkui" target="_blank" rel="external">Github</a>上克隆工程到本地，这是一个Maven工程，然后<code>mvn clean install</code>，在<code>target</code>目录下打出两个jar包<code>zkui-2.0-SNAPSHOT.jar</code>和<code>zkui-2.0-SNAPSHOT-jar-with-dependencies.jar</code>，将其上传至你的阿里云ECS。因为我们Zookeeper是集群模式，所以首先需要修改<code>config.cfg</code>中的Zookeeper地址：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Comma seperated list of all the zookeeper servers&#10;zkServer=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181</span><br></pre></td></tr></table></figure></p>
<p>然后运行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &#38;</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>成功后，访问<code>http://ECS外网IP:9090</code>即可，默认用户名密码是<code>admin/manager</code>。如果有需要可以自行在<code>config.cfg</code>文件中进行配置。</p>
<blockquote>
<p>注意：ZKUI需要JDK7以上的环境。</p>
</blockquote>
<p>然后登录ZKUI，可以看到如下界面：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576430353.png" alt=""></p>
<p>整个界面分为三部分：</p>
<ul>
<li>顶部一行是快捷操作，比如创建zNode、删除zNode、给zNode添加数据、每个Zookeeper Server的监控信息等。</li>
<li>左侧列出的是含有子zNode的zNode，所以文件夹作为icon。点击后会进入该zNode，整个界面以递归的方式展示。</li>
<li>右侧是不包含子zNode的zNode，所以直接展示zNode名称和存储的数据。</li>
</ul>
<p>从上图可以看到，左侧有名为<code>brokers</code>的zNode，点击进去后显示他的两个zNode，<code>ids</code>和<code>topics</code>：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576454552.png" alt=""></p>
<p>再点进<code>ids</code>可以看到，它还有三个子zNode，分别是Kafka集群中的三个Broker的信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576497231.png" alt=""></p>
<p>如果进入<code>topics</code>，可以看到它下面的子zNode都是我们之前创建的Topic，再进入每个Topic会看到Partition的zNode。充分展示了Zookeeper管理Kafka的方式。</p>
<p>ZKUI可以让我们方便直观的管理Zookeeper中的zNode，大大提高我们的工作效率。</p>
<h3 id="Kafka_Manager"><a href="#Kafka_Manager" class="headerlink" title="Kafka Manager"></a>Kafka Manager</h3><p>Kafka Manager是一款强大的Kafka集群监控工具。首先做一些准备工作：</p>
<ul>
<li>从<a href="https://github.com/yahoo/kafka-manager/releases" target="_blank" rel="external">Github</a>上下载<a href="https://github.com/yahoo/kafka-manager/releases" target="_blank" rel="external"> kafka-manager-1.3.3.22 </a>。</li>
<li><p>为了之后编译速度能快一些，先配置一下sbt的Maven仓库，连接到阿里云ECS，进入root用户目录，使用<code>mkdir .sbt</code>创建<code>.sbt</code>目录，进入该目录，使用<code>vim repositories</code>创建<code>repositories</code>文件，然后编辑如下内容：</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[repositories]&#10;local&#10;aliyun: http://maven.aliyun.com/nexus/content/groups/public&#10;typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly</span><br></pre></td></tr></table></figure>
</li>
<li><p>将<code>kafka-manager-1.3.3.22.zip</code>上传至ECS，解压后进入<code>kafka-manager</code>目录，执行如下命令：</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./sbt clean dist</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>需要等待一会，执行成功后，在<code>target/universal</code>目录下会产生一个<code>kafka-manager-1.3.3.7.zip</code>压缩文件，将其拷贝到要部署Kafka Manager的目录下，执行如下命令启动：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin/kafka-manager &#38;</span><br></pre></td></tr></table></figure></p>
<p>成功后，访问<code>http://ECS外网IP:9000</code>，即可看到Kafka Manager的界面了。如果有需要可以自行在<code>conf</code>目录下的<code>application.conf</code>文件中进行配置，比如端口号、Zookeeper的地址等。</p>
<blockquote>
<p>注意：Kafka Manager需要JDK8以上的环境。</p>
</blockquote>
<p>访问后，我们看到的是Kafka集群的列表列表，首先通过顶部的Add Cluster在Kafka Manager中创建Kafka集群：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576541891.png" alt=""><br>这里需要注意的有六项：</p>
<ul>
<li><code>My_Kafka_Cluster</code>：Kafka集群名称，这里随意输入。</li>
<li><code>Cluster Zookeeper Hosts</code>：Zookeeper Server的地址，如果是集群，则地址以逗号分割。</li>
<li><code>Kafka Version</code>：Kafka版本选择2.0.0。</li>
<li><code>brokerViewThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
<li><code>offsetCacheThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
<li><code>kafkaAdminClientThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
</ul>
<p>然后点击<strong>Save</strong>，Kafka Manager中的Kafka集群就创建好了。然后在Kafka Cluster列表页就能看到我们创建的集群了：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576561520.png" alt=""></p>
<p>点击进入后可以看到集群的基本信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576584316.png" alt=""><br>从上图可以看到，我们的Kafka集群中一共有6个Topic，3个Broker。点击进入Broker列表，可以看到Broker的基本信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576602212.png" alt=""></p>
<p>点击Broker ID可以进入Broker详细信息页面：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576624326.png" alt=""><br>可以看到这个Broker中都有哪些Topic，他们的Partition、ISR、Leader等信息。</p>
<p>我们再来看看Topic列表：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576651485.png" alt=""></p>
<p>从上图可以看到在列表中有一列是<strong>Brokers Spread %</strong>，只有2个Topic达到了100%，其他的都是33%，这是因为<code>my_topic_in_cluster</code>和<code>another_topic_in_cluster</code>这两个Topic是在Kafka集群中创建的，所以它们的Partitions和Replicas被均匀的分配到了三个Broker中。而其他的Topic都是在单机Kafka时创建的，所以他们的Partitions和Replicas都在一个Broker里。可见Kafka并不能自动改变之前已存在的Topic Partitions的分布情况。</p>
<p>我们点击进入之前创建的<code>my_topic_in_cluster</code>Topic看一下它的详情：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576670922.png" alt=""><br>从上图可以看到，从Kafka Manager中可以很清晰的看到Topic Partitions、ISR、Leader在Kafka集群中的分布情况。同时，也提供了对Topic的各种快捷操作，非常方便。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践搭建Zookeeper和Kafka的UI管理工具，通过可视化的视图以及方便的快捷操作能有效的监控Zookeeper和Kafka的状态以及大大提高生产效率。下一章节会对Kafka的重要配置和性能做一些探讨。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节主要介绍Zookeeper和Kafka的UI管理工具。</p>
<h3 id="ZKUI"><a href="#ZKUI" class="headerlink" title="ZKUI"></a>ZKUI</h3><p>ZKUI是一款简洁易用的Zookeeper信息管理工具。首先从<a href="https://github.com/DeemOpen/zkui">Github</a>上克隆工程到本地，这是一个Maven工程，然后<code>mvn clean install</code>，在<code>target</code>目录下打出两个jar包<code>zkui-2.0-SNAPSHOT.jar</code>和<code>zkui-2.0-SNAPSHOT-jar-with-dependencies.jar</code>，将其上传至你的阿里云ECS。因为我们Zookeeper是集群模式，所以首先需要修改<code>config.cfg</code>中的Zookeeper地址：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Comma seperated list of all the zookeeper servers&#10;zkServer=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181</span><br></pre></td></tr></table></figure></p>
<p>然后运行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &#38;</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：启动Kafka集群]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-17/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-17/</id>
    <published>2019-03-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节来真正启动Kafka集群，先给出一份Broker的配置项列表，将以下信息复制三份，分别配置三台阿里云ECS上的Broker配置文件：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;listener.security.protocol.map=EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT&#10;inter.broker.listener.name=INTERNAL&#10;advertised.listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;num.network.threads=3&#10;num.io.threads=8&#10;socket.send.buffer.bytes=102400&#10;socket.receive.buffer.bytes=102400&#10;socket.request.max.bytes=104857600&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;offsets.topic.replication.factor=2&#10;transaction.state.log.replication.factor=1&#10;transaction.state.log.min.isr=1&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>以上列表有两点需要修改的地方：</p>
<ul>
<li><code>broker.id</code>需要修改，不同Broker的ID不能相同。</li>
<li>阿里云ECS的内/外网IP需要配置正确。</li>
</ul>
<p>然后使用如下命令分别启动Kafka Broker：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka_2.12-2.0.0/bin/kafka-server-start.sh kafka_2.12-2.0.0/config/server.properties &#38;</span><br></pre></td></tr></table></figure></p>
<p>三个Broker没有异常信息，大概率说明我们的Kafka集群部署成功了，下面来验证一下。首先我们创建一个Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka_2.12-2.0.0/bin sh kafka-topics.sh --zookeeper zookeeper.server.1:2181 --topic my_topic_in_cluster --create --partitions 3 --replication-factor 2</span><br></pre></td></tr></table></figure></p>
<p>上面的命令有这样几个信息：</p>
<ul>
<li>连接Zookeeper时，连Zookeeper集群中的任意一个Zookeeper即可。</li>
<li>创建的Topic<code>my_topic_in_cluster</code>有三个Partition，每个Partition有两个Replica，也就是每条发送到这个Topic的Message会保存六份。</li>
</ul>
<p>如果Kafka集群是成功的，那么理论上这六个Partition会被两两均匀分配到三个Broker中。</p>
<p>连接到部署Broker-0的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;__consumer_offsets-0   __consumer_offsets-3   __consumer_offsets-6&#10;__consumer_offsets-1   __consumer_offsets-30  __consumer_offsets-7&#10;__consumer_offsets-10  __consumer_offsets-31  __consumer_offsets-8&#10;__consumer_offsets-11  __consumer_offsets-32  __consumer_offsets-9&#10;__consumer_offsets-12  __consumer_offsets-33  &#10;__consumer_offsets-13  __consumer_offsets-34  &#10;__consumer_offsets-14  __consumer_offsets-35  &#10;__consumer_offsets-15  __consumer_offsets-36  cleaner-offset-checkpoint&#10;__consumer_offsets-16  __consumer_offsets-37  configured-topic-0&#10;__consumer_offsets-17  __consumer_offsets-38  configured-topic-1&#10;__consumer_offsets-18  __consumer_offsets-39  configured-topic-2&#10;__consumer_offsets-19  __consumer_offsets-4   first_topic-0&#10;__consumer_offsets-2   __consumer_offsets-40  first_topic-1&#10;__consumer_offsets-20  __consumer_offsets-41  first_topic-2&#10;__consumer_offsets-21  __consumer_offsets-42  log-start-offset-checkpoint&#10;__consumer_offsets-22  __consumer_offsets-43  meta.properties&#10;__consumer_offsets-23  __consumer_offsets-44  my_topic_in_cluster-0&#10;__consumer_offsets-24  __consumer_offsets-45  my_topic_in_cluster-2&#10;__consumer_offsets-25  __consumer_offsets-46  recovery-point-offset-checkpoint&#10;__consumer_offsets-26  __consumer_offsets-47  replication-offset-checkpoint&#10;__consumer_offsets-27  __consumer_offsets-48  with_keys_topic-0&#10;__consumer_offsets-28  __consumer_offsets-49  with_keys_topic-1&#10;__consumer_offsets-29  __consumer_offsets-5   with_keys_topic-2</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-0中分配了<code>my_topic_in_cluster</code>的Partition-0和Partition-2。</p>
<p>同理，连接到部署Broker-1的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;meta.properties   my_topic_in_cluster-0&#10;my_topic_in_cluster-1   cleaner-offset-checkpoint    &#10;recovery-point-offset-checkpoint  log-start-offset-checkpoint &#10;replication-offset-checkpoint</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-1中分配了<code>my_topic_in_cluster</code>的Partition-0和Partition-1。</p>
<p>同理，连接到部署Broker-2的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;meta.properties   my_topic_in_cluster-1&#10;my_topic_in_cluster-2   cleaner-offset-checkpoint    &#10;recovery-point-offset-checkpoint  log-start-offset-checkpoint &#10;replication-offset-checkpoint</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-2中分配了<code>my_topic_in_cluster</code>的Partition-1和Partition-2。</p>
<p>从上面的结果可以说明我们的Kafka集群是部署成功的。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践运行Kafka集群，通过查看每个Broker的Data目录印证之前章节对Partition介绍的内容。下一章节会带大家搭建管理Zookeeper和Kafka的UI工具。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节来真正启动Kafka集群，先给出一份Broker的配置项列表，将以下信息复制三份，分别配置三台阿里云ECS上的Broker配置文件：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;listener.security.protocol.map=EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT&#10;inter.broker.listener.name=INTERNAL&#10;advertised.listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;num.network.threads=3&#10;num.io.threads=8&#10;socket.send.buffer.bytes=102400&#10;socket.receive.buffer.bytes=102400&#10;socket.request.max.bytes=104857600&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;offsets.topic.replication.factor=2&#10;transaction.state.log.replication.factor=1&#10;transaction.state.log.min.isr=1&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：Kafka Listeners]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-16/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-16/</id>
    <published>2019-02-28T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节主要对和Listener相关的四个配置项做以详细解释。<code>listeners</code>、<code>advertised.listeners</code>、<code>listener.security.protocol.map</code>、<code>inter.broker.listener.name</code>这四个配置项可能是大家最容易混淆和最不容易理解的。</p>
<p>在解释这些配置项之前，我们先来明确几个概念。</p>
<ul>
<li>部署Broker的阿里云ECS称为Host Machine。</li>
<li>在阿里云ECS里启动的Producer或者Consumer，比如使用Kafka CLI启动的称为Internal Client。</li>
<li>在大家的IDEA中使用Java编写的，或者第三方的Producer/Consumer，称为External Client。</li>
<li>Host Machine具有外网IP和内网IP。</li>
<li>Internal Client可以同时和Host Machine的外网IP及内网IP通信。</li>
<li>External Client只能和Host Machine的外网IP通信。</li>
<li>多个阿里云ECS之间可以同时通过外网IP及内网IP通信。<ul>
<li>既在这个特定的场景下，Host Machine之间可以同时通过外网IP及内网IP通信。</li>
<li>再换句话说就是不同Host Machine上的Broker之间可以同时通过外网IP及内网IP通信。</li>
</ul>
</li>
</ul>
<a id="more"></a>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576212167.png" alt=""></p>
<p>如上图所示，是一个很常见的Kafka集群场景，涵盖了上述的概念。图中那些通信虚线箭头就是靠Kafka的Listener建立的，并且是通过Kafka中不同的Listener建立的，这些Listener分为Internal Listener和External Listener。如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576272952.png" alt=""></p>
<p>那么这些Listener的创建以及内外部如何通信都是由上面那四个配置项决定的。</p>
<h3 id="listener-security-protocol-map"><a href="#listener-security-protocol-map" class="headerlink" title="listener.security.protocol.map"></a>listener.security.protocol.map</h3><p>先来看<code>listener.security.protocol.map</code>配置项，在上一章节中介绍过，它是配置监听者的安全协议的，比如<code>PLAINTEXT</code>、<code>SSL</code>、<code>SASL_PLAINTEXT</code>、<code>SASL_SSL</code>。因为它是以Key/Value的形式配置的，所以往往我们也使用该参数给Listener命名：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">listener.security.protocol.map=EXTERNAL_LISTENER_CLIENTS:SSL,INTERNAL_LISTENER_CLIENTS:PLAINTEXT,INTERNAL_LISTENER_BROKER:PLAINTEXT</span><br></pre></td></tr></table></figure></p>
<p>使用Key作为Listener的名称。就如上图所示，Internal Producer、External Producer、Internal Consumer、External Consumer和Broker通信以及Broker之间互相通信时都很有可能使用不同的Listener。这些不同的Listener有监听内网IP的，有监听外网IP的，还有不同安全协议的，所以使用Key来表示更加直观。当然这只是一种非官方的用法，Key本质上还是代表了安全协议，如果只有一个安全协议，多个Listener的话，那么这些Listener所谓的名称肯定都是相同的。</p>
<h3 id="listeners"><a href="#listeners" class="headerlink" title="listeners"></a>listeners</h3><p><code>listeners</code>就是主要用来定义Kafka Broker的Listener的配置项。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">listeners=EXTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093,INTERNAL_LISTENER_BROKER://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9094</span><br></pre></td></tr></table></figure></p>
<p>上面的配置表示，这个Broker定义了三个Listener，一个External Listener，用于External Producer和External Consumer连接使用。也许因为业务场景的关系，Internal Producer和Broker之间使用不同的安全协议进行连接，所以定义了两个不同协议的Internal Listener，分别用于Internal Producer和Broker之间连接使用。</p>
<p>通过之前的章节，我们知道Kafka是由Zookeeper进行管理的，由Zookeeper负责Leader选举，Broker Rebalance等工作。所以External Producer和External Consumer其实是通过Zookeeper中提供的信息和Broker通信交互的。所以<code>listeners</code>中配置的信息都会发布到Zookeeper中，但是这样就会把Broker的所有Listener信息都暴露给了外部Clients，在安全上是存在隐患的，我们希望只把给外部Clients使用的Listener暴露出去，此时就需要用到下面这个配置项了。</p>
<h3 id="advertised-listeners"><a href="#advertised-listeners" class="headerlink" title="advertised.listeners"></a>advertised.listeners</h3><p><code>advertised.listeners</code>参数的作用就是将Broker的Listener信息发布到Zookeeper中，供Clients（Producer/Consumer）使用。如果配置了<code>advertised.listeners</code>，那么就不会将<code>listeners</code>配置的信息发布到Zookeeper中去了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">advertised.listeners=EXTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092</span><br></pre></td></tr></table></figure></p>
<p>这里在Zookeeper中发布了供External Clients（Producer/Consumer）使用的Listener<code>EXTERNAL_LISTENER_CLIENTS</code>。所以<code>advertised.listeners</code>配置项实现了只把给外部Clients使用的Listener暴露出去的需求。</p>
<h3 id="inter-broker-listener-name"><a href="#inter-broker-listener-name" class="headerlink" title="inter.broker.listener.name"></a>inter.broker.listener.name</h3><p>这个配置项从名称就可以看出它的作用了，就是指定一个<code>listener.security.protocol.map</code>配置项中配置的Key，或者说指定一个或一类Listener的名称，将它作为Internal Listener。这个Listener<strong>专门用于Kafka集群中Broker之间的通信</strong>：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">inter.broker.listener.name=INTERNAL_LISTENER_BROKER</span><br></pre></td></tr></table></figure></p>
<h3 id="listener__u548C_advertised-listeners__u7684_u5173_u7CFB"><a href="#listener__u548C_advertised-listeners__u7684_u5173_u7CFB" class="headerlink" title="listener 和 advertised.listeners 的关系"></a>listener 和 advertised.listeners 的关系</h3><p>先来看看<code>KafkaConfig.scala</code>和<code>SocketServer.scala</code>源码中的这几行代码片段：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// KafkaConfig.scala</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> <span class="type">ListenersProp</span> = <span class="string">"listeners"</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dataPlaneListeners</span>:</span> <span class="type">Seq</span>[<span class="type">EndPoint</span>] = &#123;</span><br><span class="line">    <span class="type">Option</span>(getString(<span class="type">KafkaConfig</span>.<span class="type">ControlPlaneListenerNameProp</span>)) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(controlPlaneListenerName) =&gt; listeners.filterNot(_.listenerName.value() == controlPlaneListenerName)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; listeners</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">listeners</span>:</span> <span class="type">Seq</span>[<span class="type">EndPoint</span>] = &#123;</span><br><span class="line">    <span class="type">Option</span>(getString(<span class="type">KafkaConfig</span>.<span class="type">ListenersProp</span>)).map &#123; listenerProp =&gt;</span><br><span class="line">      <span class="type">CoreUtils</span>.listenerListToEndPoints(listenerProp, listenerSecurityProtocolMap)</span><br><span class="line">    &#125;.getOrElse(<span class="type">CoreUtils</span>.listenerListToEndPoints(<span class="string">"PLAINTEXT://"</span> + hostName + <span class="string">":"</span> + port, listenerSecurityProtocolMap))</span><br><span class="line">  &#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment">// SocketServer.scala</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">startup</span>(</span>startupProcessors: <span class="type">Boolean</span> = <span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">      connectionQuotas = <span class="keyword">new</span> <span class="type">ConnectionQuotas</span>(config.maxConnectionsPerIp, config.maxConnectionsPerIpOverrides)</span><br><span class="line">      createControlPlaneAcceptorAndProcessor(config.controlPlaneListener)</span><br><span class="line">      createDataPlaneAcceptorsAndProcessors(config.numNetworkThreads, config.dataPlaneListeners)</span><br><span class="line">      <span class="keyword">if</span> (startupProcessors) &#123;</span><br><span class="line">        startControlPlaneProcessor()</span><br><span class="line">        startDataPlaneProcessors()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createDataPlaneAcceptorsAndProcessors</span>(</span>dataProcessorsPerListener: <span class="type">Int</span>,</span><br><span class="line">                                                    endpoints: <span class="type">Seq</span>[<span class="type">EndPoint</span>]): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">    endpoints.foreach &#123; endpoint =&gt;</span><br><span class="line">      <span class="keyword">val</span> dataPlaneAcceptor = createAcceptor(endpoint)</span><br><span class="line">      addDataPlaneProcessors(dataPlaneAcceptor, endpoint, dataProcessorsPerListener)</span><br><span class="line">      <span class="type">KafkaThread</span>.nonDaemon(s<span class="string">"data-plane-kafka-socket-acceptor-$&#123;endpoint.listenerName&#125;-$&#123;endpoint.securityProtocol&#125;-$&#123;endpoint.port&#125;"</span>, dataPlaneAcceptor).start()</span><br><span class="line">      dataPlaneAcceptor.awaitStartup()</span><br><span class="line">      dataPlaneAcceptors.put(endpoint, dataPlaneAcceptor)</span><br><span class="line">      info(s<span class="string">"Created data-plane acceptor and processors for endpoint : $endpoint"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p><code>startup()</code>方法是Kafka Broker创建启动Socket连接的入口，既用来创建Acceptor线程的入口，该线程负责处理Socket连接。 <code>createDataPlaneAcceptorsAndProcessors()</code>方法的第二个参数<code>config.dataPlaneListeners</code>可以看到取的就是<code>listeners</code>配置项的内容。 </p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line">* Create a server socket to listen for connections on.</span><br><span class="line">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">openServerSocket</span>(</span>host: <span class="type">String</span>, port: <span class="type">Int</span>): <span class="type">ServerSocketChannel</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> socketAddress =</span><br><span class="line">    <span class="keyword">if</span> (host == <span class="literal">null</span> || host.trim.isEmpty)</span><br><span class="line">      <span class="keyword">new</span> <span class="type">InetSocketAddress</span>(port)</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">new</span> <span class="type">InetSocketAddress</span>(host, port)</span><br><span class="line">  <span class="keyword">val</span> serverChannel = <span class="type">ServerSocketChannel</span>.open()</span><br><span class="line">  serverChannel.configureBlocking(<span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">if</span> (recvBufferSize != <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>)</span><br><span class="line">    serverChannel.socket().setReceiveBufferSize(recvBufferSize)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    serverChannel.socket.bind(socketAddress)</span><br><span class="line">    info(<span class="string">"Awaiting socket connections on %s:%d."</span>.format(socketAddress.getHostString, serverChannel.socket.getLocalPort))</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">SocketException</span> =&gt;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Socket server failed to bind to %s:%d: %s."</span>.format(socketAddress.getHostString, port, e.getMessage), e)</span><br><span class="line">  &#125;</span><br><span class="line">  serverChannel</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>跟到里面，可以看到如果没有配置<code>listeners</code>，那么会使用网卡地址创建Socket连接，对于阿里云ECS，就是内网IP。</p>
<p>再来看看<code>KafkaServer.scala</code>源码中的这几行代码片段：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> brokerInfo = createBrokerInfo</span><br><span class="line"><span class="keyword">val</span> brokerEpoch = zkClient.registerBroker(brokerInfo)</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[server] <span class="function"><span class="keyword">def</span> <span class="title">createBrokerInfo</span>:</span> <span class="type">BrokerInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> endPoints = config.advertisedListeners.map(e =&gt; s<span class="string">"$&#123;e.host&#125;:$&#123;e.port&#125;"</span>)</span><br><span class="line">    zkClient.getAllBrokersInCluster.filter(_.id != config.brokerId).foreach &#123; broker =&gt;</span><br><span class="line">      <span class="keyword">val</span> commonEndPoints = broker.endPoints.map(e =&gt; s<span class="string">"$&#123;e.host&#125;:$&#123;e.port&#125;"</span>).intersect(endPoints)</span><br><span class="line">      require(commonEndPoints.isEmpty, s<span class="string">"Configured end points $&#123;commonEndPoints.mkString("</span>,<span class="string">")&#125; in"</span> +</span><br><span class="line">        s<span class="string">" advertised listeners are already registered by broker $&#123;broker.id&#125;"</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> listeners = config.advertisedListeners.map &#123; endpoint =&gt;</span><br><span class="line">      <span class="keyword">if</span> (endpoint.port == <span class="number">0</span>)</span><br><span class="line">        endpoint.copy(port = socketServer.boundPort(endpoint.listenerName))</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        endpoint</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> updatedEndpoints = listeners.map(endpoint =&gt;</span><br><span class="line">      <span class="keyword">if</span> (endpoint.host == <span class="literal">null</span> || endpoint.host.trim.isEmpty)</span><br><span class="line">        endpoint.copy(host = <span class="type">InetAddress</span>.getLocalHost.getCanonicalHostName)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        endpoint</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> jmxPort = <span class="type">System</span>.getProperty(<span class="string">"com.sun.management.jmxremote.port"</span>, <span class="string">"-1"</span>).toInt</span><br><span class="line">    <span class="type">BrokerInfo</span>(<span class="type">Broker</span>(config.brokerId, updatedEndpoints, config.rack), config.interBrokerProtocolVersion, jmxPort)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>从上面的代码可以看到，<code>advertised.listeners</code>主要用于向Zookeeper注册Broker的连接信息，但是不参与创建Socket连接。</p>
<p>所以从这几处源码内容可以得出结论，Kafka Broker真正建立通信连接使用的是<code>listeners</code>配置项里的内容，而<code>advertised.listeners</code>只用于向Zookeeper注册Broker的连接信息，既向Client暴露Broker对外的连接信息（Endpoint）。</p>
<p>另外在<code>KafkaConfig.scala</code>源码中还有有这么几行代码：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> advertisedListenerNames = advertisedListeners.map(_.listenerName).toSet</span><br><span class="line"><span class="keyword">val</span> listenerNames = listeners.map(_.listenerName).toSet</span><br><span class="line"></span><br><span class="line">require(advertisedListenerNames.contains(interBrokerListenerName),</span><br><span class="line">      s<span class="string">"$&#123;KafkaConfig.InterBrokerListenerNameProp&#125; must be a listener name defined in $&#123;KafkaConfig.AdvertisedListenersProp&#125;. "</span> +</span><br><span class="line">      s<span class="string">"The valid options based on currently configured listeners are $&#123;advertisedListenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line">require(advertisedListenerNames.subsetOf(listenerNames),</span><br><span class="line">      s<span class="string">"$&#123;KafkaConfig.AdvertisedListenersProp&#125; listener names must be equal to or a subset of the ones defined in $&#123;KafkaConfig.ListenersProp&#125;. "</span> +</span><br><span class="line">      s<span class="string">"Found $&#123;advertisedListenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;. The valid options based on the current configuration "</span> +</span><br><span class="line">      s<span class="string">"are $&#123;listenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;"</span></span><br></pre></td></tr></table></figure></p>
<p>从上面的代码片段可以得出两个结论：</p>
<ul>
<li><code>advertised.listeners</code>配置项中配置的Listener名称或者说安全协议必须在<code>listeners</code>中存在。因为真正创建连接的是<code>listeners</code>中的信息。</li>
<li><code>inter.broker.listener.name</code>配置项中配置的Listener名称或者说安全协议必须在<code>advertised.listeners</code>中存在。因为Broker之间也是要通过<code>advertised.listeners</code>配置项获取Internal Listener信息的。</li>
</ul>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节主要大家详细解释了Broker几个比较容易混淆和不好理解的配置项，解释了什么是内外部Listener，如何暴露Listener等。这些配置在我们搭建Kafka集群时至关重要。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节主要对和Listener相关的四个配置项做以详细解释。<code>listeners</code>、<code>advertised.listeners</code>、<code>listener.security.protocol.map</code>、<code>inter.broker.listener.name</code>这四个配置项可能是大家最容易混淆和最不容易理解的。</p>
<p>在解释这些配置项之前，我们先来明确几个概念。</p>
<ul>
<li>部署Broker的阿里云ECS称为Host Machine。</li>
<li>在阿里云ECS里启动的Producer或者Consumer，比如使用Kafka CLI启动的称为Internal Client。</li>
<li>在大家的IDEA中使用Java编写的，或者第三方的Producer/Consumer，称为External Client。</li>
<li>Host Machine具有外网IP和内网IP。</li>
<li>Internal Client可以同时和Host Machine的外网IP及内网IP通信。</li>
<li>External Client只能和Host Machine的外网IP通信。</li>
<li>多个阿里云ECS之间可以同时通过外网IP及内网IP通信。<ul>
<li>既在这个特定的场景下，Host Machine之间可以同时通过外网IP及内网IP通信。</li>
<li>再换句话说就是不同Host Machine上的Broker之间可以同时通过外网IP及内网IP通信。</li>
</ul>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：配置Broker]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-15/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-15/</id>
    <published>2019-02-19T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.009Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>接下来几个章节我们开始搭建真正的Kafka集群，服务器还是使用上一节章节搭建Zookeeper使用的三台阿里云ECS。</p>
<p>在<strong>搭建单机Kafka</strong>章节中，在Kafka的<code>/root/kafka_2.12-2.0.0/config/server.properties</code>配置文件中，我们只配置了<code>log.dirs</code>和<code>advertised.listeners</code>这两个配置项，其他配置项都是使用默认值。</p>
<p>Kafka的配置项一共多达140余个，虽然有一部分通常情况下我们不需要修改，使用默认值即可，<strong>但这只是一少部分</strong>。搭建Kafka集群时，光通常情况下需要考虑的配置项就有40余个。</p>
<p>另外，这些配置项要根据具体的业务场景做各种调整，不存在一套配置项通吃所有业务场景的情况，而且基本不可能一次性配置出性能最优、最能满足业务场景的配置项组合，都需要经过调整、测试，反复进行配置才能总结出相对最优的配置项组合。</p>
<a id="more"></a>
<h2 id="Broker_u914D_u7F6E"><a href="#Broker_u914D_u7F6E" class="headerlink" title="Broker配置"></a>Broker配置</h2><p>先展示一份Broker的配置内容（<code>/root/kafka_2.12-2.0.0/config/server.properties</code>），这里给出的是一个平铺的配置项列表，有一些配置项已经作废，有一些配置项之间有会有相互影响：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;# DEPRECATED&#10;host.name=&#38463;&#37324;&#20113;ECS IP&#10;# DEPRECATED&#10;port=9092&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=PLAINTEXT://&#38463;&#37324;&#20113;ECS IP:9092&#10;listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL&#10;advertised.listeners=PLAINTEXT://&#38463;&#37324;&#20113;ECS IP:9092&#10;inter.broker.listener.name=PLAINTEXT&#10;num.network.threads=3&#10;num.io.threads=8&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>
<p>我们逐一了解上面这些配置项：</p>
<h3 id="Broker_Server_u57FA_u7840_u914D_u7F6E"><a href="#Broker_Server_u57FA_u7840_u914D_u7F6E" class="headerlink" title="Broker Server基础配置"></a>Broker Server基础配置</h3><p>Broker Server的基础配置涉及到四个配置项：</p>
<ul>
<li><code>broker.id</code>：整个Kafka集群内标识唯一Broker的ID。整数类型。</li>
<li><code>host.name</code>：部署Broker的服务器IP地址或者域名。该参数已作废。</li>
<li><code>port</code>：Broker开放的端口号。该参数已作废。</li>
<li><code>delete.topic.enable</code>：是否允许删除Topic。</li>
<li><code>auto.create.topics.enable</code>：是否允许在Producer在未指定Topic发送Message时自动创建Topic。</li>
</ul>
<h3 id="Socket_Server_u914D_u7F6E"><a href="#Socket_Server_u914D_u7F6E" class="headerlink" title="Socket Server配置"></a>Socket Server配置</h3><p>传输通信方面的配置涉及到六个配置项：</p>
<ul>
<li><code>listeners</code>：Broker之间，Client与Broker之间通信建立连接时使用的信息。既Broker的监听者，可以以逗号分割配置多个。它的格式为<code>[安全协议]://Hostname/IP:Port</code>。</li>
<li><p><code>listener.security.protocol.map</code>：以Key/Value的形式定义监听者的安全协议，在大多数情况下会将Key认为是监听者的别名。所以会这样设置：</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listeners=LISTENER_BOB://阿里云ECS IP1:<span class="number">9092</span>,LISTENER_JOHN://阿里云ECS IP2:<span class="number">9092</span></span><br><span class="line">listener.security.protocol.map=LISTENER_BOB:PLAINTEXT,LISTENER_JOHN:SSL</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>advertised.listeners</code>：将Broker建立通信的地址发布到Zookeeper中，便于Client（Producer和Consumer）连接。它的格式和<code>listener</code>一致。</p>
</li>
<li><code>inter.broker.listener.name</code>：设置内部通信时使用哪个监听者。可以直接设置<code>listener.security.protocol.map</code>中设置的Key。</li>
<li><code>num.network.threads</code>：Broker Server接收请求及发送响应时启用的线程数量。</li>
<li><code>num.io.threads</code>：Broker Server处理请求、对Message进行I/O操作时启用的线程数。</li>
</ul>
<p>和监听者相关的四个配置项，在下一章节会做详细解释。</p>
<h3 id="u65E5_u5FD7_u57FA_u7840_u914D_u7F6E"><a href="#u65E5_u5FD7_u57FA_u7840_u914D_u7F6E" class="headerlink" title="日志基础配置"></a>日志基础配置</h3><p>Broker Server处理日志的基础配置涉及到五个配置项：</p>
<ul>
<li><code>log.dirs</code>：日志、Message保存的路径。</li>
<li><code>num.partitions</code>：创建Topic时，如果没有指定Partition数量，则使用该配置项设置的Partition数量。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。</li>
<li><code>default.replication.factor</code>：创建Topic时，如果没有指定Partition的Replication Factor数，则使用该配置项设置的Replication Factor数。</li>
<li><code>min.insync.replicas</code>：当<code>acks=all</code>时，至少有多少个Replicas需要确认已持久化数据，包括Leader。</li>
</ul>
<h3 id="u65E5_u5FD7_u4FDD_u7559_u7B56_u7565_u914D_u7F6E"><a href="#u65E5_u5FD7_u4FDD_u7559_u7B56_u7565_u914D_u7F6E" class="headerlink" title="日志保留策略配置"></a>日志保留策略配置</h3><p>Broker Server处理日志保留问题的配置涉及到四个配置项：</p>
<ul>
<li><code>log.retention.hours</code>：Kafka保留Message的时间，默认是168小时，既7天。</li>
<li><code>log.segment.bytes</code>：每个Segment文件的大小，默认是1G。</li>
<li><code>log.retention.check.interval.ms</code>：检测Message是否可以被删除的时间间隔。</li>
<li><code>log.segment.ms</code>：Segment文件关闭的时间。</li>
</ul>
<h3 id="Zookeeper_u76F8_u5173_u914D_u7F6E"><a href="#Zookeeper_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Zookeeper相关配置"></a>Zookeeper相关配置</h3><p>Zookeeper的相关配置涉及到两个配置项：</p>
<ul>
<li><code>zookeeper.connect</code>：设置Zookeeper地址。可用逗号分割配置多个地址，既Zookeeper集群的地址。</li>
<li><code>zookeeper.connection.timeout.ms</code>：等待连接Zookeeper的超时时间。</li>
</ul>
<h3 id="Consumer_Group_u76F8_u5173_u914D_u7F6E"><a href="#Consumer_Group_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Consumer Group相关配置"></a>Consumer Group相关配置</h3><p>Consumer Group相关的配置主要涉及到一个配置项：</p>
<ul>
<li><code>group.initial.rebalance.delay.ms</code>：当Consumer Group新增或减少Consumer时，重新分配Topic Partition的延迟时间。</li>
</ul>
<h3 id="Message_u76F8_u5173_u914D_u7F6E"><a href="#Message_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Message相关配置"></a>Message相关配置</h3><p>Message相关配置涉及到两个配置项：</p>
<ul>
<li><code>message.max.bytes</code>：Broker接收每条Message的最大值，默认是1M。</li>
<li><code>fetch.message.max.bytes</code>：Consumer每次获取Message的大小。</li>
</ul>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节给大家介绍了Broker的详细配置，为搭建Kafka集群做好充分准备。下一章节会对大家比较不容易理解的Listener配置做详细介绍。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>接下来几个章节我们开始搭建真正的Kafka集群，服务器还是使用上一节章节搭建Zookeeper使用的三台阿里云ECS。</p>
<p>在<strong>搭建单机Kafka</strong>章节中，在Kafka的<code>/root/kafka_2.12-2.0.0/config/server.properties</code>配置文件中，我们只配置了<code>log.dirs</code>和<code>advertised.listeners</code>这两个配置项，其他配置项都是使用默认值。</p>
<p>Kafka的配置项一共多达140余个，虽然有一部分通常情况下我们不需要修改，使用默认值即可，<strong>但这只是一少部分</strong>。搭建Kafka集群时，光通常情况下需要考虑的配置项就有40余个。</p>
<p>另外，这些配置项要根据具体的业务场景做各种调整，不存在一套配置项通吃所有业务场景的情况，而且基本不可能一次性配置出性能最优、最能满足业务场景的配置项组合，都需要经过调整、测试，反复进行配置才能总结出相对最优的配置项组合。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：搭建Zookeeper集群]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-14/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-14/</id>
    <published>2019-02-09T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.009Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来真正搭建一个Zookeeper集群。</p>
<h2 id="u642D_u5EFAZookeeper_u96C6_u7FA4"><a href="#u642D_u5EFAZookeeper_u96C6_u7FA4" class="headerlink" title="搭建Zookeeper集群"></a>搭建Zookeeper集群</h2><p>首先要做的就是再租赁两个服务器，参照<strong>搭建单机Kafka</strong>章节中的步骤，租赁阿里云服务器、安装JDK、下载配置Kafka、配置安全组规则。</p>
<h3 id="Zookeeper_u914D_u7F6E_u4FE1_u606F"><a href="#Zookeeper_u914D_u7F6E_u4FE1_u606F" class="headerlink" title="Zookeeper配置信息"></a>Zookeeper配置信息</h3><p>在<strong>搭建单机Kafka</strong>章节中，启动的是单机Zookeeper，所以<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件中只配置了<code>dataDir</code>，也就是存储各种数据、日志、快照的路径。</p>
<p>在搭建Zookeeper时，就需要额外再配置一些参数了。同样打开<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件，额外添加如下内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>逐一解释一下这些配置信息：</p>
<ul>
<li><code>maxClientCnxns</code>：该参数表示允许客户端最大连接数。如果设置为0则表示不做限制。</li>
<li><code>tickTime</code>：该参数表示Zookeeper服务之间进行心跳监测的间隔时间，单位是毫秒。设置为2000，表示每隔2秒，Zookeeper服务器之间会进行一次心跳监测。</li>
<li><code>initLimit</code>：该参数表示Zookeeper集群中的Follower在启动时需要在多少个心跳时间内从Leader同步数据。设置为10，表示要在10个心跳时间内，也就是在20秒内，要完成Leader数据的同步。</li>
<li><code>syncLimit</code>：该参数表示超过多少个心跳时间收不到Follower的响应，Leader就认为此Follower已经下线。设置为5，表示在5个心跳时间内，也就是判断Follower是否存活的响应时间是10秒。</li>
</ul>
<h3 id="Zookeeper_u96C6_u7FA4_u8282_u70B9_u5217_u8868"><a href="#Zookeeper_u96C6_u7FA4_u8282_u70B9_u5217_u8868" class="headerlink" title="Zookeeper集群节点列表"></a>Zookeeper集群节点列表</h3><p>首先节点列表的配置规则为<code>server.N=IP:Port1:Port2</code>：</p>
<ul>
<li><code>N</code>表示Zookeeper节点编号。</li>
<li><code>IP</code>表示Zookeeper节点的服务器IP，既阿里云ECS的外网IP。</li>
<li><code>Port1</code>表示该Zookeeper集群中的Follower节点与Leader节点通讯时使用的端口。作为Leader时监听该端口。</li>
<li><code>Port2</code>表示选举新的Leader时，Zookeeper节点之间互相通信的端口，比如当Leader挂掉时，其余服务器会互相通信，选出新的Leader。Leader和Follower都会监听该端口。</li>
</ul>
<p>这里的节点编号是数字类型，需要我们在<code>/root/kafka_2.12-2.0.0/data/zookeeper</code>目录下创建名为<code>myid</code>的文件，然后将编号配置在里面。<code>server.N</code>这里的<code>N</code>要和<code>myid</code>文件中配置的编号保持一致。</p>
<p>另外还需要注意的是，如果要在一台服务器上搭建伪集群，那么每个<code>Port1</code>和每个<code>Port2</code>要不一样才可以，因为<code>IP</code>都是一样的。这里我们是分别用三台不同的阿里云ECS，所以<code>IP</code>肯定是不一样的，而每个<code>Port1</code>是一致的，每个<code>Port2</code>也是一致的。</p>
<p>为了方便起见，我们可以在服务器的<code>/etc/hosts</code>文件中设置一下域名映射，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&#38463;&#37324;&#20113;ECS-1 IP] zookeeper.server.1&#10;[&#38463;&#37324;&#20113;ECS-2 IP] zookeeper.server.2&#10;[&#38463;&#37324;&#20113;ECS-3 IP] zookeeper.server.3</span><br></pre></td></tr></table></figure></p>
<p>这样在配置Zookeeper集群节点列表时就可以写成如下形式了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>
<h3 id="u963F_u91CC_u4E91ECS_u670D_u52A1_u76D1_u542C_u6240_u6709_u7F51_u5361"><a href="#u963F_u91CC_u4E91ECS_u670D_u52A1_u76D1_u542C_u6240_u6709_u7F51_u5361" class="headerlink" title="阿里云ECS服务监听所有网卡"></a>阿里云ECS服务监听所有网卡</h3><p>如果现在通过<code>/root/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh config/zookeeper.properties</code>启动Zookeeper，肯定会报一大堆错误，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[myid:0] - WARN  [WorkerSender[myid=0]:QuorumCnxManager@588] - Cannot open channel to 1 at election address /zookeeper.server.1:3888&#10;java.net.ConnectException: Connection refused&#10;&#160; &#160; &#160; &#160; at java.net.PlainSocketImpl.socketConnect(Native Method)&#10;&#160; &#160; &#160; &#160; at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)&#10;.......</span><br></pre></td></tr></table></figure></p>
<p>这是因为阿里云ECS都是采用虚拟化技术创建的服务器实例，而虚拟机中并没有物理网卡，所以Zookeeper服务启动后，进程并没有监听到<code>3888</code>端口，而是会随机生成一个端口进行监听。所以会报上面的错。解决的办法就是让Zookeeper服务进程监听<code>0.0.0.0</code>的IP地址，也就是监听所有网卡。那么就需要在<code>zookeeper.properties</code>配置文件加入<code>quorumListenOnAllIPs=true</code>配置信息，来保证Zookeeper服务进程能监听到我们设定的<code>3888</code>端口。</p>
<h3 id="Zookeeper_u96C6_u7FA4_u914D_u7F6E_u603B_u7ED3"><a href="#Zookeeper_u96C6_u7FA4_u914D_u7F6E_u603B_u7ED3" class="headerlink" title="Zookeeper集群配置总结"></a>Zookeeper集群配置总结</h3><p>在启动Zookeeper集群前，先来总结一下配置工作：</p>
<ul>
<li>租赁三台阿里云ECS，下载JDK、Kafka、配置安全组规则。</li>
<li>在<code>/root/kafka_2.12-2.0.0/data/zookeeper</code>目录下创建名为<code>myid</code>的文件，配置Zookeeper节点编号。</li>
<li>在服务器的<code>/etc/hosts</code>文件中设置一下域名映射：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&#38463;&#37324;&#20113;ECS-1 IP] zookeeper.server.1&#10;[&#38463;&#37324;&#20113;ECS-2 IP] zookeeper.server.2&#10;[&#38463;&#37324;&#20113;ECS-3 IP] zookeeper.server.3</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>在<code>/root/kafka_2.12-2.0.0/config/zookeeper.properties</code>配置文件中添加如下配置（<code>server.N</code>中的<code>N</code>要和<code>myid</code>中配置的节点编号保持一致）：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>在三台阿里云ECS中都完成上述工作后，就可以逐一启动Zookeeper了，命令如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh config/zookeeper.properties &#38;</span><br></pre></td></tr></table></figure></p>
<h2 id="u68C0_u9A8CZookeeper_u96C6_u7FA4"><a href="#u68C0_u9A8CZookeeper_u96C6_u7FA4" class="headerlink" title="检验Zookeeper集群"></a>检验Zookeeper集群</h2><p>三个Zookeeper节点都启动后，我们可以通过下面两个方法对Zookeeper集群进行基础的验证。</p>
<h3 id="u67E5_u770B_u7AEF_u53E3_u76D1_u542C_u72B6_u6001"><a href="#u67E5_u770B_u7AEF_u53E3_u76D1_u542C_u72B6_u6001" class="headerlink" title="查看端口监听状态"></a>查看端口监听状态</h3><p>我们可以使用<code>nc</code>命令看看端口都有没有被成功监听，选择任意一台服务器，通过下面的命令查看：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nc -vz zookeeper.server.1 2181&#10;Connection to zookeeper.server.1 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.1 3888&#10;Connection to zookeeper.server.1 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.1 2888&#10;nc: connect to zookeeper.server.1 port 2888 (tcp) failed: Connection refused&#10;&#10;nc -vz zookeeper.server.2 2181&#10;Connection to zookeeper.server.2 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.2 3888&#10;Connection to zookeeper.server.2 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.2 2888&#10;nc: connect to zookeeper.server.2 port 2888 (tcp) failed: Connection refused&#10;&#10;nc -vz zookeeper.server.3 2181&#10;Connection to zookeeper.server.3 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.3 3888&#10;Connection to zookeeper.server.3 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.3 2888&#10;Connection to zookeeper.server.3 2888 port [tcp/*] succeeded!</span><br></pre></td></tr></table></figure></p>
<p>从上面的信息中可以看出，三个Zookeeper都成功启动了，并且可以知道<code>zookeeper.server.1</code>和<code>zookeeper.server.2</code>是Follower，<code>zookeeper.server.3</code>是Leader，因为前两个节点并没有监听<code>2888</code>端口。</p>
<h3 id="u901A_u8FC7Zookeeper_CLI_u9A8C_u8BC1"><a href="#u901A_u8FC7Zookeeper_CLI_u9A8C_u8BC1" class="headerlink" title="通过Zookeeper CLI验证"></a>通过Zookeeper CLI验证</h3><p>我们还可以通过Zookeeper Client连接到集群来检验。我们选择任意一台服务器，首先连接<code>zookeeper.server.1</code>节点：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.1:2181</span><br></pre></td></tr></table></figure></p>
<p>连接成功后，我们创建一个zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_zNode &#34;some data&#34;&#10;Created /my_zNode</span><br></pre></td></tr></table></figure></p>
<p>查看<code>zookeeper.server.1</code>节点中所有的zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;[cluster, brokers, my_zNode, zookeeper, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>我们看到了刚才创建的<code>my_zNode</code>。然后退出连接，再连接<code>zookeeper.server.2</code>节点：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.2:2181</span><br></pre></td></tr></table></figure></p>
<p>然后查看<code>zookeeper.server.2</code>节点中的所有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;[cluster, controller_epoch, brokers, my_zNode, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>我们同样发现了<code>my_zNode</code>。查看<code>my_zNode</code>中的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /my_zNode&#10;some data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x500000009&#10;mtime = Wed Jan 09 15:38:39 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>看到是在<code>zookeeper.server.1</code>节点中创建时添加的<code>some data</code>数据。</p>
<p>同样我们再连接<code>zookeeper.server.3</code>节点查看zNode情况：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.3:2181&#10;&#10;ls /&#10;[cluster, controller_epoch, brokers, my_zNode, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]&#10;&#10;get /my_zNode&#10;some data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x500000009&#10;mtime = Wed Jan 09 15:38:39 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>我们在<code>zookeeper.server.3</code>节点中修改<code>my_zNode</code>中的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_zNode &#34;new data&#34;&#10;&#10;get /my_zNode&#10;new data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x50000000e&#10;mtime = Wed Jan 09 15:46:29 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>然后再连接<code>zookeeper.server.1</code>节点查看<code>my_zNode</code>的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.1:2181&#10;&#10;get /my_zNode&#10;new data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x50000000e&#10;mtime = Wed Jan 09 15:46:29 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>看到<code>zookeeper.server.1</code>节点中<code>my_zNode</code>的数据也变成了<code>new data</code>。</p>
<p>上面的过程虽然比较繁琐，但是充分说明了我们的Zookeeper集群是搭建成功的。无论从哪个Zookeeper节点创建的zNode，都可以同步到集群中的其他节点。无论从哪个Zookeeper节点修改的zNode中的数据，也可以同步到起群中的其他节点。</p>
<h2 id="Zookeeper_The_Four_Letter_Words_Commands"><a href="#Zookeeper_The_Four_Letter_Words_Commands" class="headerlink" title="Zookeeper The Four Letter Words Commands"></a>Zookeeper The Four Letter Words Commands</h2><p>Zookeeper提供了一些能够查看节点Server状态、Client连接Server的状态、节点健康状态的命令。因为命令大多都是四个字母的简写，所以称为<a href="https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_zkCommands" target="_blank" rel="external">The Four Letter Words Commands</a>，我称为四字真言。</p>
<p>首先来看看整体的命令格式：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;xxxx&#34; | nc IP Port</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>xxxx</code>就是四字真言命令。</li>
<li><code>IP</code>是Zookeeper节点的IP。</li>
<li><code>Port</code>自然是Zookeeper监听的2181端口。</li>
</ul>
<p>下面来具体看看这些命令。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u914D_u7F6E"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u914D_u7F6E" class="headerlink" title="查看Zookeeper节点配置"></a>查看Zookeeper节点配置</h3><p>该命令可以查看指定节点的配置信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;conf&#34; | nc zookeeper.server.1 2181&#10;&#10;clientPort=2181&#10;dataDir=/root/kafka_2.12-2.0.0/data/zookeeper/version-2&#10;dataLogDir=/root/kafka_2.12-2.0.0/data/zookeeper/version-2&#10;tickTime=2000&#10;maxClientCnxns=0&#10;minSessionTimeout=4000&#10;maxSessionTimeout=40000&#10;serverId=1&#10;initLimit=10&#10;syncLimit=5&#10;electionAlg=3&#10;electionPort=3888&#10;quorumPort=2888&#10;peerType=0</span><br></pre></td></tr></table></figure></p>
<p>这个命令可以很方便的查看Zookeeper节点<code>zookeeper.properties</code>中的配置信息，以及默认的配置信息。</p>
<h3 id="u67E5_u770B_u8FDE_u63A5_u5230Zookeeper_u8282_u70B9_u7684Client_u4FE1_u606F"><a href="#u67E5_u770B_u8FDE_u63A5_u5230Zookeeper_u8282_u70B9_u7684Client_u4FE1_u606F" class="headerlink" title="查看连接到Zookeeper节点的Client信息"></a>查看连接到Zookeeper节点的Client信息</h3><p>该命令可以查看连接到指定Zookeeper节点的Client信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;cons&#34; | nc zookeeper.server.1 2181&#10;&#10;/[Client IP]:35764[1](queued=0,recved=1,sent=1,sid=0x10000b81b7d0003,lop=SESS,est=1547024407028,to=30000,lcxid=0x0,lzxid=0x500000012,lresp=22061060,llat=11,minlat=0,avglat=11,maxlat=11)&#10; /[Zookeeper Server IP]:42946[0](queued=0,recved=1,sent=0)</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BSession_u53CA_u4E34_u65F6_u8282_u70B9_u4FE1_u606F"><a href="#u67E5_u770BSession_u53CA_u4E34_u65F6_u8282_u70B9_u4FE1_u606F" class="headerlink" title="查看Session及临时节点信息"></a>查看Session及临时节点信息</h3><p>该命令可以查看指定Zookeeper节点建立Session的信息以及临时节点的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;dump&#34; | nc zookeeper.server.3 2181&#10;&#10;SessionTracker dump:&#10;Session Sets (3):&#10;0 expire at Fri Jan 02 07:13:54 CST 1970:&#10;0 expire at Fri Jan 02 07:14:04 CST 1970:&#10;1 expire at Fri Jan 02 07:14:14 CST 1970:&#10;&#9;0x10000b81b7d0003&#10;ephemeral nodes dump:&#10;Sessions with Ephemerals (0):</span><br></pre></td></tr></table></figure></p>
<p>该命令只有指定了Leader节点才有效。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u73AF_u5883_u53D8_u91CF"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u73AF_u5883_u53D8_u91CF" class="headerlink" title="查看Zookeeper节点的环境变量"></a>查看Zookeeper节点的环境变量</h3><p>该命令可以查看指定Zookeeper节点的环境变量信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;envi&#34; | nc zookeeper.server.3 2181</span><br></pre></td></tr></table></figure></p>
<h3 id="u76D1_u6D4BZookeeper_u8282_u70B9_u53EF_u7528_u72B6_u6001"><a href="#u76D1_u6D4BZookeeper_u8282_u70B9_u53EF_u7528_u72B6_u6001" class="headerlink" title="监测Zookeeper节点可用状态"></a>监测Zookeeper节点可用状态</h3><p>该命令可以查看指定Zookeeper节点是否正常：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;ruok&#34; | nc zookeeper.server.3 2181&#10;&#10;imok</span><br></pre></td></tr></table></figure></p>
<p>如果节点正常则返回<code>imok</code>，如果不正常则没有任何响应。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的信息"></a>查看Zookeeper节点的信息</h3><p>该命令可以查看指定Zookeeper节点的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;srvr&#34; | nc zookeeper.server.3 2181&#10;&#10;Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;Latency min/avg/max: 0/1/8&#10;Received: 34&#10;Sent: 33&#10;Connections: 1&#10;Outstanding: 0&#10;Zxid: 0x500000012&#10;Mode: leader&#10;Node count: 164&#10;Proposal sizes last/min/max: 36/32/90</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F_u4EE5_u53CA_u8FDE_u63A5Client_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F_u4EE5_u53CA_u8FDE_u63A5Client_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的信息以及连接Client信息"></a>查看Zookeeper节点的信息以及连接Client信息</h3><p>该命令可以查看指定Zookeeper节点的信息，以及连接该节点的Client信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;stat&#34; | nc zookeeper.server.1 2181&#10;&#10;Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;Clients:&#10; /[Client IP]:35764[1](queued=0,recved=54,sent=54)&#10; /[Zookeeper Server IP]:42956[0](queued=0,recved=1,sent=0)&#10;&#10;Latency min/avg/max: 0/0/17&#10;Received: 223&#10;Sent: 222&#10;Connections: 2&#10;Outstanding: 0&#10;Zxid: 0x500000012&#10;Mode: follower&#10;Node count: 164</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u76D1_u63A7_u72B6_u6001_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u76D1_u63A7_u72B6_u6001_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的监控状态信息"></a>查看Zookeeper节点的监控状态信息</h3><p>该命令可以查看指定Zookeeper节点的监控状态信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;mntr&#34; | nc zookeeper.server.1 2181&#10;&#10;zk_version&#9;3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;zk_avg_latency&#9;0&#10;zk_max_latency&#9;17&#10;zk_min_latency&#9;0&#10;zk_packets_received&#9;236&#10;zk_packets_sent&#9;235&#10;zk_num_alive_connections&#9;2&#10;zk_outstanding_requests&#9;0&#10;zk_server_state&#9;follower&#10;zk_znode_count&#9;164&#10;zk_watch_count&#9;0&#10;zk_ephemerals_count&#9;0&#10;zk_approximate_data_size&#9;13322&#10;zk_open_file_descriptor_count&#9;116&#10;zk_max_file_descriptor_count&#9;65535&#10;zk_fsync_threshold_exceed_count&#9;0</span><br></pre></td></tr></table></figure></p>
<p>我们可以使用以上这些命令方便的查看Zookeeper节点以及Client的各种信息，提高效率。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践搭建了真正的Zookeeper集群，为之后搭建Kafka集群打基础，同时还复习了Zookeeper CLI的使用方式以及很重要的Zookeeper四字真言。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来真正搭建一个Zookeeper集群。</p>
<h2 id="u642D_u5EFAZookeeper_u96C6_u7FA4"><a href="#u642D_u5EFAZookeeper_u96C6_u7FA4" class="headerlink" title="搭建Zookeeper集群"></a>搭建Zookeeper集群</h2><p>首先要做的就是再租赁两个服务器，参照<strong>搭建单机Kafka</strong>章节中的步骤，租赁阿里云服务器、安装JDK、下载配置Kafka、配置安全组规则。</p>
<h3 id="Zookeeper_u914D_u7F6E_u4FE1_u606F"><a href="#Zookeeper_u914D_u7F6E_u4FE1_u606F" class="headerlink" title="Zookeeper配置信息"></a>Zookeeper配置信息</h3><p>在<strong>搭建单机Kafka</strong>章节中，启动的是单机Zookeeper，所以<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件中只配置了<code>dataDir</code>，也就是存储各种数据、日志、快照的路径。</p>
<p>在搭建Zookeeper时，就需要额外再配置一些参数了。同样打开<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件，额外添加如下内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Zookeeper CLI：CRUD zNode]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-13/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-13/</id>
    <published>2019-01-27T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.009Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看Zookeeper的命令行工具。</p>
<h2 id="Zookeeper_CLI"><a href="#Zookeeper_CLI" class="headerlink" title="Zookeeper CLI"></a>Zookeeper CLI</h2><p>在第七章节搭建单机Kafka中，我们已经发现了，Kafka是自带Zookeeper的，而且在启动Kafka之前，要先启动Zookeeper，相当于启动了单机Zookeeper，所以我们先说Zookeeper CLI，后面说Zookeeper集群时再具体说配置参数。</p>
<h3 id="u5C55_u793AzNode"><a href="#u5C55_u793AzNode" class="headerlink" title="展示zNode"></a>展示zNode</h3><p>首先打开终端，连接至我们的服务器，进入<code>/root/kafka_2.12-2.0.0/bin</code>目录，执行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh zookeeper-shell.sh 127.0.0.1:2181</span><br></pre></td></tr></table></figure></p>
<p>这是Zookeeper CLI Client连接Zookeeper的命令，当看到如下信息时，说明连接成功：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Connecting to 127.0.0.1:2181&#10;Welcome to ZooKeeper!&#10;JLine support is disabled</span><br></pre></td></tr></table></figure></p>
<p>先来来看看目前Zookeeper里都有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;&#10;[cluster, controller_epoch, controller, brokers, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p><code>ls</code>命令和Linux中的作用一样，在Zookeeper中是展示某个zNode下的所有zNode。这里的<code>/</code>表示根zNode。可以看到已经有很多zNode注册在了Zookeeper。再来看看<code>brokers</code>下还有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers&#10;&#10;[ids, topics, seqid]</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>再来看看有哪些Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers/topics&#10;&#10;[with_keys_topic, first_topic, __consumer_offsets, configured-topic]</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BzNode_u5B58_u50A8_u7684_u6570_u636E"><a href="#u67E5_u770BzNode_u5B58_u50A8_u7684_u6570_u636E" class="headerlink" title="查看zNode存储的数据"></a>查看zNode存储的数据</h3><p>在上一章节中说过，Zookeeper中的zNode是可以存储数据的，那么我们来看看如何查看zNode中存储的数据，比如我们来看看<code>/brokers/ids</code>里保存了什么数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /brokers/ids&#10;&#10;null&#10;cZxid = 0x5&#10;ctime = Wed Dec 19 23:46:53 CST 2018&#10;mZxid = 0x5&#10;mtime = Wed Dec 19 23:46:53 CST 2018&#10;pZxid = 0x43d&#10;cversion = 51&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 0&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p><code>get</code>命令用于查看zNode中存储的数据，从上面的结果看到，<code>/brokers/ids</code>这个zNode里的数据是<code>null</code>，那么看看是否<code>/brokers/ids</code>下还有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers/ids&#10;&#10;[0]</span><br></pre></td></tr></table></figure></p>
<p>果然，<code>/brokers/ids</code>下还有zNode，这个zNode很明显是以Broker ID命名的。那再来看看<code>/brokers/ids/0</code>里存储了什么样的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /brokers/ids/0&#10;&#10;&#123;&#34;listener_security_protocol_map&#34;:&#123;&#34;PLAINTEXT&#34;:&#34;PLAINTEXT&#34;&#125;,&#34;endpoints&#34;:[&#34;PLAINTEXT://ECS&#22806;&#32593;IP:9092&#34;],&#34;jmx_port&#34;:-1,&#34;host&#34;:&#34;ECS&#22806;&#32593;IP&#34;,&#34;timestamp&#34;:&#34;1546570570448&#34;,&#34;port&#34;:9092,&#34;version&#34;:4&#125;&#10;cZxid = 0x43d&#10;ctime = Fri Jan 04 10:56:10 CST 2019&#10;mZxid = 0x43d&#10;mtime = Fri Jan 04 10:56:10 CST 2019&#10;pZxid = 0x43d&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x100363316d3004a&#10;dataLength = 192&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>从上面的结果可以看到，第一行显示的就是zNode存储的数据，<code>/brokers/ids/0</code>这个zNode存储了Broker的IP、端口、注册时间戳、JMX端口等信息。这一行之后的信息都是zNode的标准属性了，有各种时间戳、版本号、数据长度、子节点数等。</p>
<h3 id="u521B_u5EFAzNode"><a href="#u521B_u5EFAzNode" class="headerlink" title="创建zNode"></a>创建zNode</h3><p>我们可以使用Zookeeper CLI自行创建zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;some data&#34;&#10;&#10;Created /my_node&#10;&#10;ls /&#10;&#10;[cluster, controller, brokers, zookeeper, my_node, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>使用<code>create</code>命令创建zNode。这里要注意的是，在创建zNode时必须要带着存储数据，哪怕是空也可以：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;&#34;</span><br></pre></td></tr></table></figure></p>
<p>否则是无法创建zNode的。</p>
<p>在创建zNode时不可以一次性创建多级zNode，如果还没有创建<code>my_node</code>，直接创建<code>deeper_node</code>是不可以的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node/deeper_node &#34;some data&#34;&#10;Node does not exist: /my_node/deeper_node</span><br></pre></td></tr></table></figure></p>
<p>所以Zookeeper要一层一层创建zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;some data&#34;&#10;Created /my_node&#10;create /my_node/deeper_node &#34;some data&#34;&#10;Created /my_node/deeper_node&#10;&#10;get /my_node/deeper_node&#10;some data&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x454&#10;mtime = Mon Jan 07 19:12:20 CST 2019&#10;pZxid = 0x454&#10;cversion = 0</span><br></pre></td></tr></table></figure></p>
<h2 id="u66F4_u65B0zNode_u7684_u6570_u636E"><a href="#u66F4_u65B0zNode_u7684_u6570_u636E" class="headerlink" title="更新zNode的数据"></a>更新zNode的数据</h2><p>我们可以通过<code>set</code>命令更新zNode中存储的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node &#34;new data&#34;&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x455&#10;mtime = Mon Jan 07 19:14:04 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 1&#10;&#10;get /my_node&#10;new data&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x455&#10;mtime = Mon Jan 07 19:14:04 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p>可以看到<code>dataVersion</code>和<code>cversion</code>从0变成了1。这里注意一下，每当更新zNode存储的数据时，<code>dataVersion</code>会递增，之所以<code>cversion</code>也递增了是因为更新数据本身也是对zNode的修改，如果我们再更新一次数据，就只有<code>dataVersion</code>会递增了，因为第一次和第二次都是对zNode存储的数据的修改，只算作一次zNode的改变，所以<code>cversion</code>不会再更新：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node &#34;again new data&#34;&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x456&#10;mtime = Mon Jan 07 19:16:24 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 2&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 14&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p>如果想让<code>cversion</code>变化，那么给<code>my_node</code>再增加一个zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node/another_node &#34;some data&#34;&#10;Created /my_node/another_node&#10;get /my_node&#10;again new data&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x456&#10;mtime = Mon Jan 07 19:16:24 CST 2019&#10;pZxid = 0x457&#10;cversion = 2&#10;dataVersion = 2&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 14&#10;numChildren = 2</span><br></pre></td></tr></table></figure></p>
<p>可以看到<code>cversion</code>和<code>numChildren</code>都变了。</p>
<h3 id="u6DFB_u52A0zNode_Watcher"><a href="#u6DFB_u52A0zNode_Watcher" class="headerlink" title="添加zNode Watcher"></a>添加zNode Watcher</h3><p>上一章节同样说过，Zookeeper中的zNode的所有变更都可以被监控到。来看看如何通过CLI给zNode添加Watcher。我们给<code>/my_node/deeper_node</code>添加Watcher：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /my_node/deeper_node true&#10;some data&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x454&#10;mtime = Mon Jan 07 19:12:20 CST 2019&#10;pZxid = 0x454&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>通过<code>get /zNode true</code>给zNode添加Watcher。当<code>/my_node/deeper_node</code>修改数据时，就会收到监听事件了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node/deeper_node &#34;new data&#34;&#10;&#10;WATCHER::&#10;&#10;WatchedEvent state:SyncConnected type:NodeDataChanged path:/my_node/deeper_node&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x458&#10;mtime = Mon Jan 07 19:24:05 CST 2019&#10;pZxid = 0x454&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<h3 id="u5220_u9664zNode"><a href="#u5220_u9664zNode" class="headerlink" title="删除zNode"></a>删除zNode</h3><p>可以通过<code>rmr</code>命令删除zNode，该命令是递归删除，既可以删除指定zNode以及该zNode下的所有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rmr /my_node&#10;ls /&#10;[cluster, controller, brokers, zookeeper, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践了如何使用Zookeeper CLI操作Zookeeper，通过增删改查zNode进一步认知Zookeeper的结构，对之后认知Kafka集群做以铺垫。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看Zookeeper的命令行工具。</p>
<h2 id="Zookeeper_CLI"><a href="#Zookeeper_CLI" class="headerlink" title="Zookeeper CLI"></a>Zookeeper CLI</h2><p>在第七章节搭建单机Kafka中，我们已经发现了，Kafka是自带Zookeeper的，而且在启动Kafka之前，要先启动Zookeeper，相当于启动了单机Zookeeper，所以我们先说Zookeeper CLI，后面说Zookeeper集群时再具体说配置参数。</p>
<h3 id="u5C55_u793AzNode"><a href="#u5C55_u793AzNode" class="headerlink" title="展示zNode"></a>展示zNode</h3><p>首先打开终端，连接至我们的服务器，进入<code>/root/kafka_2.12-2.0.0/bin</code>目录，执行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh zookeeper-shell.sh 127.0.0.1:2181</span><br></pre></td></tr></table></figure></p>
<p>这是Zookeeper CLI Client连接Zookeeper的命令，当看到如下信息时，说明连接成功：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Connecting to 127.0.0.1:2181&#10;Welcome to ZooKeeper!&#10;JLine support is disabled</span><br></pre></td></tr></table></figure></p>
<p>先来来看看目前Zookeeper里都有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;&#10;[cluster, controller_epoch, controller, brokers, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p><code>ls</code>命令和Linux中的作用一样，在Zookeeper中是展示某个zNode下的所有zNode。这里的<code>/</code>表示根zNode。可以看到已经有很多zNode注册在了Zookeeper。再来看看<code>brokers</code>下还有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers&#10;&#10;[ids, topics, seqid]</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-初步认知：Zookeeper]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-12/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-12/</id>
    <published>2019-01-06T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.008Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来认识一下在Kafka中有着超然地位的Zookeeper。</p>
<h2 id="Zookeeper_u521D_u8BC6"><a href="#Zookeeper_u521D_u8BC6" class="headerlink" title="Zookeeper初识"></a>Zookeeper初识</h2><p>ZooKeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。简化分布式应用协调及其管理的难度，提供高性能的分布式服务。ZooKeeper的目标就是封装好复杂、易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
<p>Zookeeper有以下一些特点：</p>
<ul>
<li>Zookeeper的内部数据结构是树状结构的。</li>
<li>每个节点称为zNode。</li>
<li>每个zNode都有一个唯一路径（path）。</li>
<li>zNode分长久存在的和临时存在的。</li>
<li>每个zNode都可以存储数据。</li>
<li>zNode不能重命名。</li>
<li>每个zNode的任何变化都可以被监控。</li>
</ul>
<a id="more"></a>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/1/7/1546826442789.png" alt=""></p>
<p>所以Zookeeper作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，Zookeeper作用主要是用来维护和监控存储的数据的状态变化，通过监控这些数据状态的变化，从而达到基于数据的集群管理，可以说，Zookeeper相当于带有通知机制的文件系统。</p>
<h2 id="Role_of_Zookeeper_in_Kafka"><a href="#Role_of_Zookeeper_in_Kafka" class="headerlink" title="Role of Zookeeper in Kafka"></a>Role of Zookeeper in Kafka</h2><p>Zookeeper在Kafka中的地位是超然的。它的主要作用有以下几点：</p>
<ul>
<li>Zookeeper管理着Kafka集群中的若干个Broker，保存着一份完整的Broker列表。</li>
<li>维护Topic信息，比如Partitions、Replication Factor、ISR等。</li>
<li>Zookeeper帮助选举Partition的Leader.</li>
<li>当有任何变动时，由Zookeeper给Kafka发送通知，比如添加一个新的Topic、Broker挂掉了、删除Topic等等。</li>
<li>Zookeeper集群中也有Leader和Follower的概念。Leader负责写数据，Follower负责读数据.</li>
<li>存储Kafka集群ID。</li>
<li>存储访问控制列表（ACL，Access Control List）。控制Topic、Consumer Group、User等访问权限。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575649583.png" alt=""></p>
<h2 id="Size_of_Zookeeper"><a href="#Size_of_Zookeeper" class="headerlink" title="Size of Zookeeper"></a>Size of Zookeeper</h2><p>Zookeeper对于Kafka有一个很重要的投票选举功能。所以通常情况下Zookeeper集群最少使用三个Server。如果增加更多Server，那最好是奇数个Server（3，5，7，9，2N+1）。因为Zookeeper有一个特性，就是集群中只要有过半的机器是正常工作的，那么整个集群对外就是可用的。也就是说如果有2个Zookeeper Server，那么只要有1个Zookeeper Server宕机，整个集群就不能用了，因为1没有过半，所以我们要搭建奇数个Server，这样就可以保证最大允许1，2，3，4，N个Server宕机，而保证整个系统不受影响。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家初步认知了Zookeeper是什么，以及他在Kafka中为何具有超然的地位。和Kafka CLI一样，Zookeeper也有命令行工具，下一章节将会进行Zookeeper CLI的介绍，希望可以给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来认识一下在Kafka中有着超然地位的Zookeeper。</p>
<h2 id="Zookeeper_u521D_u8BC6"><a href="#Zookeeper_u521D_u8BC6" class="headerlink" title="Zookeeper初识"></a>Zookeeper初识</h2><p>ZooKeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。简化分布式应用协调及其管理的难度，提供高性能的分布式服务。ZooKeeper的目标就是封装好复杂、易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
<p>Zookeeper有以下一些特点：</p>
<ul>
<li>Zookeeper的内部数据结构是树状结构的。</li>
<li>每个节点称为zNode。</li>
<li>每个zNode都有一个唯一路径（path）。</li>
<li>zNode分长久存在的和临时存在的。</li>
<li>每个zNode都可以存储数据。</li>
<li>zNode不能重命名。</li>
<li>每个zNode的任何变化都可以被监控。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：Kafka Java Consumer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-11/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-11/</id>
    <published>2018-12-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.008Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Consumer。</p>
<h2 id="Java_Consumer"><a href="#Java_Consumer" class="headerlink" title="Java Consumer"></a>Java Consumer</h2><p>首先创建Consumer需要的配置信息，最基本的有五个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。</li>
<li>指定Consumer Group。</li>
<li>指定拉取Message范围的策略。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"consumer_group_1"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"latest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<p>然后传入上面实例化好的配置信息，实例化Consumer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br></pre></td></tr></table></figure></p>
<p>然后通过Consumer的<code>subscribe(Collection&lt;String&gt; topics)</code>方法订阅Topic：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">consumer.subscribe(Arrays.asList(<span class="string">"first_topic"</span>));</span><br></pre></td></tr></table></figure></p>
<p>最后获取Topic里的Message，将Message信息输出到日志中：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">	ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">	<span class="keyword">for</span>(ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">		logger.info(<span class="string">"Key: "</span> + record.key() + <span class="string">", Value: "</span> + record.value());</span><br><span class="line">		logger.info(<span class="string">"Partition: "</span> + record.partition() + <span class="string">", Offset: "</span> + record.offset());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Consumer的<code>poll(Duration timeout)</code>方法可以设置获取数据的时间间隔，同时回忆一下在之前Consumer章节的<strong>Consumer Poll Options</strong>小节中，说过关于Consumer获取Message的四个配置项，都可以在Properties里进行设置。</p>
<p>启动Java Consumer后，在控制台可以看到如下信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[main] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Discovered group coordinator IP:9092 (id: 2147483647 rack: null)&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions []&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 1&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-0, first_topic-1, first_topic-2]&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-0 to offset 23.&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-1 to offset 24.&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-2 to offset 21.</span><br></pre></td></tr></table></figure></p>
<p>在上面的信息中，可以看到<code>Setting newly assigned partitions [first_topic-0, first_topic-1, first_topic-2]</code>这句话，说明当前这个Consumer会获取<code>first_topic</code>这个Topic中全部Partition中的Message。</p>
<p>如果我们再启动一个Consumer，这个Consumer和第一个在同一个组里，看看会有什么输出信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[main] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Discovered group coordinator IP:9092 (id: 2147483647 rack: null)&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions []&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 2&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-2]</span><br></pre></td></tr></table></figure></p>
<p>可以看到新启动的Consumer会输出<code>Setting newly assigned partitions [first_topic-2]</code>这句话，说明新的这个Consumer只会获取<code>first_topic</code>这个Topic的一个Partition中的Message。</p>
<p>再回去看看第一个Consumer的控制台：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Attempt to heartbeat failed since group is rebalancing&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions [first_topic-0, first_topic-1, first_topic-2]&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 2&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-0, first_topic-1]</span><br></pre></td></tr></table></figure></p>
<p>第一个Consumer新输出在控制台中的信息很关键，首先看到<code>Attempt to heartbeat failed since group is rebalancing</code>这句话，说明Kafka会自动重新给Consumer Group里的Consumer分配Topic的Partition。</p>
<p>再看<code>Setting newly assigned partitions [first_topic-0, first_topic-1]</code>这句，说明第一个Consumer不会再获取<code>first_topic-2</code>这个Partition里的Message了。这也印证了在Consumer章节的<strong>Consumer Group</strong>小节里讲过的概念。</p>
<h3 id="Java_Consumer_with_Assign_and_Seek"><a href="#Java_Consumer_with_Assign_and_Seek" class="headerlink" title="Java Consumer with Assign and Seek"></a>Java Consumer with Assign and Seek</h3><p>如果我们有一个临时的Consumer，不想加入任何一个Consumer Group，而且需要指定Topic的Partition，以及指定从哪个Message Offset开始获取数据，怎么办？所幸，Kafka提供了这样的API。</p>
<p>首先我们在实例化配置信息时，就不需要指定Consumer Group了：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KafkaConstant.BOOTSTRAP_SERVER);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure></p>
<p>然后实例化<code>TopicPartition</code>，指定Topic和Partition序号。使用Consumer的<code>assign(Collection&lt;TopicPartition&gt; partitions)</code>方法，分配给该Consumer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">TopicPartition topicPartition = <span class="keyword">new</span> TopicPartition(<span class="string">"first_topic"</span>, <span class="number">0</span>);</span><br><span class="line">consumer.assign(Arrays.asList(topicPartition));</span><br></pre></td></tr></table></figure></p>
<p>再然后指定Message Offset：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> offset = <span class="number">21L</span>;</span><br><span class="line">consumer.seek(topicPartition, offset);</span><br></pre></td></tr></table></figure></p>
<p>运行该Consumer，可以看到如下输出信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=] Fetch offset 21 is out of range for partition first_topic-0, resetting offset&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=] Resetting offset for partition first_topic-0 to offset 22.&#10;[main] INFO com.devtalking.jacefu.kafka.tutorial.ConsumerDemoAssignSeek - Key: null, Value: hello world!&#10;[main] INFO com.devtalking.jacefu.kafka.tutorial.ConsumerDemoAssignSeek - Partition: 0, Offset: 22</span><br></pre></td></tr></table></figure></p>
<p>如果我们使用Consumer Group CLI查看，会发现这种操作其实也是临时创建了一个Consumer Group：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@iZ2ze2booskait1cxxyrljZ:~# kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;consumer_group_1&#10;KMOffsetCache-iZ2ze2booskait1cxxyrljZ</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践如何使用Kafka提供的API编写Java Consumer。上一节和这一节主要介绍了Kafka Java Client（Producer和Consumer）的使用方式，相比Kafka CLI，Java Client在实际的开发中可能使用的更加频繁，希望能给使用Java语言的小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Consumer。</p>
<h2 id="Java_Consumer"><a href="#Java_Consumer" class="headerlink" title="Java Consumer"></a>Java Consumer</h2><p>首先创建Consumer需要的配置信息，最基本的有五个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。</li>
<li>指定Consumer Group。</li>
<li>指定拉取Message范围的策略。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"consumer_group_1"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"latest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：Kafka Java Producer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-10/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-10/</id>
    <published>2018-12-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.008Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Producer。</p>
<h2 id="Create_Kafka_Project"><a href="#Create_Kafka_Project" class="headerlink" title="Create Kafka Project"></a>Create Kafka Project</h2><p>创建Maven工程，在POM文件中加入如下两个依赖：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>slf4j-simple<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>第一个是Kafka的依赖包，用于创建Producer、ProducerRecord、Consumer等。第二个是Log4J的依赖包，用于输出日志。</p>
<a id="more"></a>
<h2 id="Java_Producer"><a href="#Java_Producer" class="headerlink" title="Java Producer"></a>Java Producer</h2><p>首先创建Producer需要的配置信息，最基本的有三个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>然后传入上面实例化好的配置信息，实例化Producer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br></pre></td></tr></table></figure></p>
<p>然后实例化Record对象，该对象承载了要往哪个Topic发送以及Message内容的信息：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first_topic"</span>, <span class="string">"hello world!"</span>);</span><br></pre></td></tr></table></figure></p>
<p>再然后发送Record：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.send(producerRecord);</span><br></pre></td></tr></table></figure></p>
<p>最后刷新和关闭Producer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.flush();</span><br><span class="line">kafkaProducer.close();</span><br></pre></td></tr></table></figure></p>
<p>以上就是最简单的Kafka Java Producer的编写方法。运行一下，可以看到类似如下的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.&#10;&#10;Process finished with exit code 0</span><br></pre></td></tr></table></figure></p>
<h3 id="Java_Producer_with_Callback"><a href="#Java_Producer_with_Callback" class="headerlink" title="Java Producer with Callback"></a>Java Producer with Callback</h3><p>如果我们希望在发送Message后，能监控发送状态，或者在发送异常时对异常进行处理。那么我们就可以使用带有Callback的发送方法：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.send(producerRecord, <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">			logger.info(<span class="string">"Received new metadata. \n"</span> +</span><br><span class="line">                            <span class="string">"Topic: "</span> + recordMetadata.topic()  + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Partition: "</span> + recordMetadata.partition() + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Offset: "</span> + recordMetadata.offset() + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Timestamp: "</span> + recordMetadata.timestamp());</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			logger.error(<span class="string">"Error while producing: "</span>, e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p>这样每次发送Message后，都会进入<code>onCompletion</code>这个方法中，然后可以使用<code>RecordMetadata</code>中记录的各种元数据做一些跟踪和监控的事情，同时如果发送异常了，也可以对异常进行处理。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[kafka-producer-network-thread | producer-1] INFO com.devtalking.jacefu.kafka.tutorial1.ProducerDemoWithCallback - Received new metadata. &#10;Topic: first_topic&#10;Partition: 0&#10;Offset: 22&#10;Timestamp: 1546421392063&#10;[main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.&#10;&#10;Process finished with exit code 0</span><br></pre></td></tr></table></figure></p>
<h3 id="Java_Producer_with_Keys"><a href="#Java_Producer_with_Keys" class="headerlink" title="Java Producer with Keys"></a>Java Producer with Keys</h3><p>在前文中，Partition的Compaction Cleanup Policy一节中介绍到，在压缩策略时，就涉及到了Message的Key和Value。我们来看看如何在发送Message时带着Key。</p>
<p>首先来看看<code>ProducerRecord</code>的另一个构造函数：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(topic, (Integer)<span class="keyword">null</span>, (Long)<span class="keyword">null</span>, key, value, (Iterable)<span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到，刚才我们只使用了<code>topic</code>和<code>value</code>两个参数，其中还有一个<code>key</code>，所以我们在实例化<code>ProducerRecord</code>时传入Key就可以了：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first_topic"</span>, <span class="string">"This is the key"</span>, <span class="string">"hello world!"</span>);</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>之前三个章节介绍了如何使用Kafka CLI操作Kafka，其中包括Producer CLI和Consumer CLI。这一章节主要带大家实践如何使用Kafka提供的API编写Java Producer，希望可以给使用Java语言的小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Producer。</p>
<h2 id="Create_Kafka_Project"><a href="#Create_Kafka_Project" class="headerlink" title="Create Kafka Project"></a>Create Kafka Project</h2><p>创建Maven工程，在POM文件中加入如下两个依赖：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>slf4j-simple<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>第一个是Kafka的依赖包，用于创建Producer、ProducerRecord、Consumer等。第二个是Log4J的依赖包，用于输出日志。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Reseting Offset & Config CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-9/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-9/</id>
    <published>2018-11-30T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.012Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Reseting_Offset"><a href="#Reseting_Offset" class="headerlink" title="Reseting Offset"></a>Reseting Offset</h2><p>在实际的业务场景中，经常需要重复消费Topic中的Message，所以来看看如何重置Offset。</p>
<p>首先重置Offset可以通过如下的命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --reset-offsets [options] --execute --topic xxxx</span><br></pre></td></tr></table></figure></p>
<p>Kafka为我们提供了6种重置Offset的方式，也就是命令中的<code>options</code>：</p>
<ul>
<li><code>--to-earliest</code>：重置到最早的Offset。</li>
<li><code>--to-latest</code>：重置到最后的Offset。</li>
<li><code>--to-offset &lt;Long: offset&gt;</code>：重置到指定的Offset。</li>
<li><code>--to-current</code>：重置到当前的Offset。</li>
<li><code>--to-datetime &lt;String: datetime&gt;</code>：重置到指定时间的Offset，时间格式为<code>YYYY-MM-DDTHH:mm:SS.sss</code>。</li>
<li><code>--shift-by &lt;Long: number-of-offsets&gt;</code>：左移或右移Offset。</li>
</ul>
<a id="more"></a>
<p>举个例子来看看：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --topic first_topic --reset-offsets --shift-by -2 --execute&#10;&#10;TOPIC                          PARTITION  NEW-OFFSET&#10;first_topic                    2          15&#10;first_topic                    1          17&#10;first_topic                    0          15</span><br></pre></td></tr></table></figure></p>
<p>上面的命令将<code>consumer_group_1</code>消费<code>first_topic</code>的三个Partitions的Offset向左移了2位。如此之后，相当于<code>consumer_group_1</code>还有6条Message没有消费。我们启动Consumer看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --topic first_topic&#10;&#10;C&#10;F&#10;E&#10;this is another message.&#10;A&#10;D</span><br></pre></td></tr></table></figure></p>
<p>可以看到启动Consumer后，消费了6条Message。其他的Reset Options用法是一样的。这使得我们可以非常灵活的控制Consumer消费Message。</p>
<h2 id="Config_CLI"><a href="#Config_CLI" class="headerlink" title="Config CLI"></a>Config CLI</h2><p>我们再来看看如何通过命令进行Kafka的配置。用到的命令是<code>kafka-config.sh</code>，该命令可以对Topic、Broker、Client进行配置。关键的属性有以下三个：</p>
<ul>
<li><code>--entity-type</code>：这个属性设置要对什么进行配置，可选值为<code>topics</code>、<code>brokers</code>、<code>clients</code>、<code>users</code>。</li>
<li><code>--entity-name</code>：这个属性设置对应Type的名称，比如Topic名称、Broker Id、Client Id、User name。</li>
<li><code>--alter</code>：确认修改。</li>
</ul>
<p>首先我们创建一个Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181 --create --topic configured-topic --partitions 3 --replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>看看新创建的Topic的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic configured-topic --describe&#10;&#10;Topic:configured-topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:&#10;Topic: configured-topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>可以看到打印信息中的Configs是空的，说明这个Topic没有做额外的配置。或者也可以使用如下命令查看Topic的配置：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --describe&#10;&#10;Configs for topic &#39;configured-topic&#39; are</span><br></pre></td></tr></table></figure></p>
<p>看到打印信息只有<code>Configs for topic &#39;configured-topic&#39; are</code>，同样说明该Topic还没有额外配置信息。</p>
<p>接下来该这个Topic设置<code>min.insync.replicas</code>属性：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --add-config min.insync.replicas=2 --alter&#10;&#10;Completed Updating config for entity: topic &#39;configured-topic&#39;.</span><br></pre></td></tr></table></figure></p>
<p>再来查看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --describe&#10;&#10;Configs for topic &#39;configured-topic&#39; are min.insync.replicas=2&#10;&#10;kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic configured-topic --describe&#10;&#10;Topic:configured-topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:min.insync.replicas=2&#10;Topic: configured-topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>两种方式都可以看到刚才更新的配置信息。</p>
<p>将<code>--add-config</code>换成<code>--delete-config</code>就可以删除配置项：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --add-config min.insync.replicas=2 --alter&#10;&#10;Completed Updating config for entity: topic &#39;configured-topic&#39;.</span><br></pre></td></tr></table></figure></p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节进一步介绍了如何通过Kafka CLI操作Consumer Offset，以及如何使用Config CLI对Kafka进行配置。下一章节会介绍如何使用Kafka API编写Kafka Java Client。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Reseting_Offset"><a href="#Reseting_Offset" class="headerlink" title="Reseting Offset"></a>Reseting Offset</h2><p>在实际的业务场景中，经常需要重复消费Topic中的Message，所以来看看如何重置Offset。</p>
<p>首先重置Offset可以通过如下的命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --reset-offsets [options] --execute --topic xxxx</span><br></pre></td></tr></table></figure></p>
<p>Kafka为我们提供了6种重置Offset的方式，也就是命令中的<code>options</code>：</p>
<ul>
<li><code>--to-earliest</code>：重置到最早的Offset。</li>
<li><code>--to-latest</code>：重置到最后的Offset。</li>
<li><code>--to-offset &lt;Long: offset&gt;</code>：重置到指定的Offset。</li>
<li><code>--to-current</code>：重置到当前的Offset。</li>
<li><code>--to-datetime &lt;String: datetime&gt;</code>：重置到指定时间的Offset，时间格式为<code>YYYY-MM-DDTHH:mm:SS.sss</code>。</li>
<li><code>--shift-by &lt;Long: number-of-offsets&gt;</code>：左移或右移Offset。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Consumer CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-8/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-8/</id>
    <published>2018-11-30T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Consumer_CLI"><a href="#Consumer_CLI" class="headerlink" title="Consumer CLI"></a>Consumer CLI</h2><p>这一节来看看使用命令行启动Consumer接收消息，通过如下的命令启动Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-consumer.sh</code>是启动Consumer的命令。</li>
<li><code>--bootstrap-server</code>指定要连接的Broker地址。</li>
<li><code>--topic</code>指定Topic名称，既要从哪个Topic里读数据。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575057414.png" alt=""></p>
<a id="more"></a>
<p>如上图所示，左边启动的是Consumer，右边启动的是Producer。Producer发送的消息可以实时的被Consumer接收到。但是有一个问题，那就是在上一节中，我们已经给<code>first_topic</code>这个Topic发送了一些数据。但是现在Consumer启动后并没有收到。这是因为通过上面的命令启动的Consumer接收的是最新的消息，如果想接收所有的消息，还需要带一个参数：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning</span><br></pre></td></tr></table></figure></p>
<p><code>--from-beginning</code>表示启动的Consumer要接收所有的消息。</p>
<p>前文中说过，Consumer一般都是以组的形式存在，所以可以再加一个参数来创建一个Consumer Group：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --group consumer_group_1</span><br></pre></td></tr></table></figure></p>
<p><code>--group</code>可以指定Consumer Group的名称。</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575079452.png" alt=""></p>
<p>如上图所示，左边启动了三个Consumer，这三个Consumer都在同一个名为<code>consumer_group_1</code>的组里。因为<code>first_topic</code>这个Topic有三个Partitions，所以当一个Consumer Group中有三个Consumer时，他们的收到的信息不会重复。</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575103168.png" alt=""></p>
<p>又如上图所示，左边启动了三个Consumer，但是前两个在<code>consumer_group_1</code>的组里，最后一个在<code>consumer_group_2</code>的组里，所以前两个Consumer是以轮询的方式收到消息的，而最后一个Consumer可以收到全部的消息。</p>
<p>上面两个示例也充分证明了前文中所说的，<strong>不同的Consumer Group可以消费同一个Topic中相同的Partition的消息，但是Consumer Group内的Consumer不能消费同一个Topic中相同的Partition的消息</strong>。</p>
<p>上面的命令是显示的创建Consumer Group。上文中说到过，Kafka中，Consumer都是以组的形式连接Broker消费数据的。那么如果只有一个Consumer的情况下，是否有Consumer Group呢？其实，当只有一个Consumer时，也会自动创建一个Consumer Group。我们可以通过另外一组Consumer Group CLI来看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;console-consumer-40439&#10;console-consumer-81216&#10;consumer_group_1c&#10;console-consumer-14387&#10;consumer_group_2&#10;consumer_group_1&#10;console-consumer-40563</span><br></pre></td></tr></table></figure></p>
<p>可以看到，已经存在的Consumer Group中，除了我们之前创建的，还有以<code>console-consumer-xxxxx</code>这种命名格式存在的Consumer Group。这就是当我们只启动一个Consumer时Kafka自动为这个Consumer创建的Consumer Group。这里可以做个实验，先启动一个Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<p>然后再来看看Consumer Group是否有增加：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;console-consumer-96752&#10;console-consumer-40439&#10;console-consumer-81216&#10;consumer_group_1c&#10;console-consumer-14387&#10;consumer_group_2&#10;consumer_group_1&#10;console-consumer-40563</span><br></pre></td></tr></table></figure></p>
<p>我们看到增加了一个Consumer Group<code>console-consumer-96752</code>。</p>
<p>Consumer Group列表看完了，再来看看某一个Consumer Group的详细信息，比如查看<code>consumer_group_1</code>的详细信息。可以使用如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;Consumer group &#39;consumer_group_1&#39; has no active members.&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               -               -               -&#10;first_topic     2          17              17              0               -               -               -&#10;first_topic     1          18              18              0               -               -</span><br></pre></td></tr></table></figure></p>
<p>首先会告诉我们该Consumer Group中是否有正在活跃的Consumer，目前没有启动任何Consumer，所以提示我们<code>Consumer group &#39;consumer_group_1&#39; has no active members.</code></p>
<p>然后会列出该Consumer Group消费的Topic、Partition情况、Offset情况、延迟（LAG）情况、处于活跃状态的Consumer信息。</p>
<p>可以看到<code>consumer_group_1</code>这个Consumer Group正在消费<code>first_topic</code>这个Topic中的Message，一共从三个Partition中消费了52条Messages，并且目前已经消费了全部的数据，因为每个Partition的延迟都是0，说明没有还未接收的Message。</p>
<p>现在我们再往<code>first_topic</code>中发送一条Message，再来看看情况如何：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1&#10;&#62;this is another message.&#10;&#10;kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;Consumer group &#39;consumer_group_1&#39; has no active members.&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               -               -               -&#10;first_topic     2          17              17              0               -               -               -&#10;first_topic     1          18              19              1               -               -               -</span><br></pre></td></tr></table></figure></p>
<p>可以看到Partition 1 的<code>LOG-END-OFFSET</code>是19，而<code>CURRENT-OFFSET</code>是18，并且Partition 1 的<code>LAG</code>是1，说明现在<code>first-topic</code>一共接收到了19条Message，而<code>consumer-group-1</code>只消费了18条，有1条延迟。</p>
<p>我们再启动<code>consumer_group_1</code>中的Consumer，然后再看看数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning --group consumer_group_1&#10;&#10;this is another message.&#10;&#10;kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1&#10;first_topic     1          19              19              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1&#10;first_topic     2          17              17              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1</span><br></pre></td></tr></table></figure></p>
<p>可以看到，目前有一个处于活跃的Consumer，并且Messages全部被消费。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节主要介绍了如何使用Kafka的Consumer CLI接收Producer生产的Message。同时能更直观的印证之前介绍概念时提到的内容，比如Consumer Group的机制、Offset机制等。下一章节进一步介绍Offset的操作以及Config CLI。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Consumer_CLI"><a href="#Consumer_CLI" class="headerlink" title="Consumer CLI"></a>Consumer CLI</h2><p>这一节来看看使用命令行启动Consumer接收消息，通过如下的命令启动Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-consumer.sh</code>是启动Consumer的命令。</li>
<li><code>--bootstrap-server</code>指定要连接的Broker地址。</li>
<li><code>--topic</code>指定Topic名称，既要从哪个Topic里读数据。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575057414.png" alt=""></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Topic CLI & Producer CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-7/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-7/</id>
    <published>2018-11-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Kafka CLI是Kafka Command Line Interface。其实就是Kafka的命令行工具，可以让我们在终端里方面的进行Kafka的操作，比如创建Topic、Partition、Replication、Produce data、Consume data等等。后续的几个章节主要来介绍如何使用Kafka CLI。</p>
<h2 id="Topic_CLI"><a href="#Topic_CLI" class="headerlink" title="Topic CLI"></a>Topic CLI</h2><p>首先我们可以通过下面的命令创建Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh &#8212;zookeeper 127.0.0.1:2181 &#8212;topic xxxx_topic &#8212;create &#8212;partitions 3 &#8212;replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，<code>replication-factor</code>不能大于Broker的数量，这个很好理解，前文中有过阐述。成功后可以看<code>Created topic &quot;first_topic&quot;.</code>这样的提示。</p>
<a id="more"></a>
<p>可以通过如下命令查看当前有哪些Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --list</span><br></pre></td></tr></table></figure></p>
<p>可以通过如下命令查看某个Topic的具体信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --topic first_topic --describe</span><br></pre></td></tr></table></figure></p>
<p>显示该Topic的Partition信息、Leader信息、ISR信息、Replication信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Topic:first_topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:&#10;Topic: first_topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: first_topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: first_topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>这里注意，Partition后面的数字是序号，因为我们设置了三个Partition。Leader、Replicas、Isr后面的数字是Broker的ID，在<code>server.properties</code>配置文件中可以配置Broker的ID，默认从0开始。</p>
<p>可以通过如下命令删除Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --topic second_topic --delete</span><br></pre></td></tr></table></figure></p>
<p>这里要注意，Broker有一个配置项<code>delete.topic.enable</code>，如果设为<code>false</code>，那么删除Topic时并非立即删除，只是会被打上删除的标记，以减少Topic突然删除给业务带来的冲击。如果设为<code>true</code>，那么就是立即删除，默认是<code>true</code>。</p>
<p>现在大家可以到<code>/kafka_2.12-2.0.0/data/kafka</code>目录中看一下，可以看到Partition的目录，和一些Checkpoint的文件。</p>
<h2 id="Producer_CLI"><a href="#Producer_CLI" class="headerlink" title="Producer CLI"></a>Producer CLI</h2><p>再来看看如何通过CLI启动Producer发送消息，命令如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-producer.sh</code>是启动Producer的命令。</li>
<li><code>--broker-list</code>设置连接的Broker地址，指定要连接哪个Broker。端口号9092是默认的，在<code>server.properties</code>文件中可以通过<code>port</code>属性更改，IP地址可以通过<code>host.name</code>属性更改。</li>
<li><code>--topic</code>设置Topic名称，指定要往哪个Topic里发送消息。</li>
<li><code>--producer-property</code>配置Producer的参数，这里要指定ACK的策略。</li>
</ul>
<p>然后就可以发送消息了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1&#10;&#62;hello this is a producer&#10;&#62;I am JaceFu&#10;&#62;Kafka is a awesome MQ system</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，如果在命令中指定的Topic不存在，则Kafka会自动创建这个Topic，Partition数量会根据<code>server.properties</code>中配置的<code>num.partitions</code>数创建。但建议应该提前创建好Topic再发送消息。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节介绍了如何使用Kafka的Topic CLI创建Topic、查看Topic信息。然后使用Producer CLI生产Message。结合之前对它们概念的介绍，能让我们有更直观的认知。下一章节会介绍如何使用Consumer CLI。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Kafka CLI是Kafka Command Line Interface。其实就是Kafka的命令行工具，可以让我们在终端里方面的进行Kafka的操作，比如创建Topic、Partition、Replication、Produce data、Consume data等等。后续的几个章节主要来介绍如何使用Kafka CLI。</p>
<h2 id="Topic_CLI"><a href="#Topic_CLI" class="headerlink" title="Topic CLI"></a>Topic CLI</h2><p>首先我们可以通过下面的命令创建Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh &#8212;zookeeper 127.0.0.1:2181 &#8212;topic xxxx_topic &#8212;create &#8212;partitions 3 &#8212;replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，<code>replication-factor</code>不能大于Broker的数量，这个很好理解，前文中有过阐述。成功后可以看<code>Created topic &quot;first_topic&quot;.</code>这样的提示。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：搭建单机Kafka]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-6/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-6/</id>
    <published>2018-10-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节介绍如何在Linux服务器上搭建单机Kafka。</p>
<h2 id="u79DF_u8D41_u670D_u52A1_u5668"><a href="#u79DF_u8D41_u670D_u52A1_u5668" class="headerlink" title="租赁服务器"></a>租赁服务器</h2><p>为了更加真实，本小册的实践内容都搭建在云服务器上。可以在阿里云或者腾讯云租赁服务器，如果想租赁国外的服务器，可以在<a href="https://www.vultr.com/?ref=7702774" target="_blank" rel="external">Vultr</a>租赁。我选择在阿里云租赁了一台Linux服务器。配置不需要太高，入门级的就可以，系统可以选择CentOS或者Ubuntu。</p>
<blockquote>
<p>注意：在配置ECS时，宽带计费方式要选择按量计费，这样可以自动分配公网IP，并且价格实惠。</p>
</blockquote>
<h2 id="u5B89_u88C5JDK"><a href="#u5B89_u88C5JDK" class="headerlink" title="安装JDK"></a>安装JDK</h2><p>使用终端登录服务器，首先安装JDK：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt update&#10;apt install openjdk-8-jdk</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="u4E0B_u8F7DKafka"><a href="#u4E0B_u8F7DKafka" class="headerlink" title="下载Kafka"></a>下载Kafka</h2><p>然后去<a href="https://archive.apache.org/dist/kafka/2.0.0/kafka_2.12-2.0.0.tgz" target="_blank" rel="external">Kafka官网</a>下载2.0.0版本的Kafka，Scala版本为2.12（kafka_2.12-2.0.0.tgz）。解压：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -xvf kafka_2.12-2.0.0.tgz</span><br></pre></td></tr></table></figure></p>
<p>解压完之后，将Kafka的bin目录配置到PATH中：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH=/root/kafka_2.12-2.0.0/bin:$PATH</span><br></pre></td></tr></table></figure></p>
<h2 id="u914D_u7F6EKafka"><a href="#u914D_u7F6EKafka" class="headerlink" title="配置Kafka"></a>配置Kafka</h2><p>接下来进行最基本的配置。我们需要创建三个目录，用来存放Zookeeper和Kafka的数据：</p>
<ul>
<li><code>/root/kafka_2.12-2.0.0/data</code></li>
<li><code>/root/kafka_2.12-2.0.0/data/zookeeper</code></li>
<li><code>/root/kafka_2.12-2.0.0/data/kafka</code></li>
</ul>
<p>然后更新Zookeeper配置文件（<code>/root/kafka_2.12-2.0.0/config/zookeeper.properties</code>）中的Data路径（<code>dataDir</code>）为<code>/root/kafka_2.12-2.0.0/data/zookeeper</code>。</p>
<p>接着更新Kakfa Broker配置文件（<code>/root/kafka_2.12-2.0.0/config/server.properties</code>）中的日志路径（<code>log.dirs</code>）为<code>/root/kafka_2.12-2.0.0/data/kafka</code></p>
<h2 id="u8BBE_u7F6E_u963F_u91CC_u4E91ECS_u5B89_u5168_u7EC4_u89C4_u5219"><a href="#u8BBE_u7F6E_u963F_u91CC_u4E91ECS_u5B89_u5168_u7EC4_u89C4_u5219" class="headerlink" title="设置阿里云ECS安全组规则"></a>设置阿里云ECS安全组规则</h2><p>最后我们要对阿里云ECS进行一些配置，才可以让本地的Kafka Client通过外网IP连接到部署在ECS上的Kafka。</p>
<p>打开阿里云控制台/云服务器ECS/实例，在<strong>更多</strong>选项里选择网络和安全组/安全组配置：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555574758784.png" alt=""></p>
<p>然后进入配置规则：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555574799842.png" alt=""></p>
<p>添加安全组规则：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555574830647.png" alt=""></p>
<p>因为是自己用的，所以为了方便起见，将授权对象设置为<code>0.0.0.0/0</code>：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555574846030.png" alt=""></p>
<p>设置完ECS之后，我们还需要配置一下Kafka Broker的信息，打开<code>config/server.properties</code>文件，添加如下信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">advertised.listeners=PLAINTEXT://ECS&#22806;&#32593;IP:9092</span><br></pre></td></tr></table></figure></p>
<p><code>advertised.listeners</code>这个属性的作用是告诉Zookeeper，该Broker将以这里配置的IP作为Host。这样，本地Kafka Client就可以通过ECS的外网IP连接到Broker了。</p>
<h2 id="u542F_u52A8Kafka"><a href="#u542F_u52A8Kafka" class="headerlink" title="启动Kafka"></a>启动Kafka</h2><p>在上文中，我们知道Kafka离开Zookeeper是玩不转的，所以首先要启动Zookeeper：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh config/zookeeper.properties &#38;</span><br></pre></td></tr></table></figure></p>
<p>然后再启动Kafka Broker：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/kafka-server-start.sh config/server.properties &#38;</span><br></pre></td></tr></table></figure></p>
<p>至此，Kafka最基本的搭建和启动就成功了。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节介绍了如何使用Linux服务器搭建单机Kafka，因为后续的Kafka CLI要基于单机Kafka进行实操。所以希望大家都能自己动手先搭建单机Kafka。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节介绍如何在Linux服务器上搭建单机Kafka。</p>
<h2 id="u79DF_u8D41_u670D_u52A1_u5668"><a href="#u79DF_u8D41_u670D_u52A1_u5668" class="headerlink" title="租赁服务器"></a>租赁服务器</h2><p>为了更加真实，本小册的实践内容都搭建在云服务器上。可以在阿里云或者腾讯云租赁服务器，如果想租赁国外的服务器，可以在<a href="https://www.vultr.com/?ref=7702774">Vultr</a>租赁。我选择在阿里云租赁了一台Linux服务器。配置不需要太高，入门级的就可以，系统可以选择CentOS或者Ubuntu。</p>
<blockquote>
<p>注意：在配置ECS时，宽带计费方式要选择按量计费，这样可以自动分配公网IP，并且价格实惠。</p>
</blockquote>
<h2 id="u5B89_u88C5JDK"><a href="#u5B89_u88C5JDK" class="headerlink" title="安装JDK"></a>安装JDK</h2><p>使用终端登录服务器，首先安装JDK：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt update&#10;apt install openjdk-8-jdk</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-庖丁解牛：Consumer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-5/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-5/</id>
    <published>2018-10-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>了解完Producer，接下来介绍Kafka中的Consumer的概念，以及在消费Message时有什么样的策略。</p>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><p>Consumer负责从Topic中读取数据，我们已经知道了Topic是通过名称确定唯一的，所以指定Consumer从哪个Topic中读数据，同样使用Topic名称指定。Kafka中的Consumer有以下几点需要我们注意：</p>
<ul>
<li>我们只需要指定需要从哪个Topic中读取数据即可。不需要关心Consumer是从哪个Broker中的哪个Partition中读数据，这些工作由Kafka帮我们处理好了。</li>
<li>当持有Topic的Broker挂掉，重新恢复后，Consumer可以自动重新从该Broker中读数据。</li>
<li>在一个Partition中，Consumer是按Offset的顺序读取数据的。</li>
<li>一个Consumer可以同时读取多个Broker中的不同Partition，但是Partition之间无法保证读取数据的顺序，因为是并行执行的。</li>
</ul>
<a id="more"></a>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/kafka-consumer.png" alt=""></p>
<h3 id="Consumer_Group"><a href="#Consumer_Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h3><p>Consumer有组的概念，对于Consumer Group有以下几点需要我们注意：</p>
<ul>
<li>不同的Consumer Group之间可以读取相同的Partition中的数据。</li>
<li>Consumer Group里的Consumer之间不能读取相同的Partition中的数据，他们读取数据的Partition是专享的。</li>
<li>所以基于上面的知识点，如果Consumer数量多于Partition数量，那么就会有Consumer处于空闲的状态。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/kafka-consumer.png" alt=""></p>
<p>上图的示例中，如果Consumer Group 2中再增加一个Consumer 4，那么Consumer 4就会处于空闲状态，因为没有多余的Partition分给它了。</p>
<h3 id="Consumer_Offset"><a href="#Consumer_Offset" class="headerlink" title="Consumer Offset"></a>Consumer Offset</h3><p>一个优秀的MQ系统，必定会有一个能力，那就是断点续传的能力。既当Consumer挂掉再恢复后，需要从挂掉的前一时刻读数据的点开始接着往后读。那么如何做到这一点呢，那就是通过Consumer Offset来实现的。</p>
<p>每当一个活跃的Consumer正在从Partition中读取数据时，Kafka都会根据给定的策略记住该Consumer读取数据的Offset。这个策略就是Consumer提交Offset的策略。目前有三个策略：</p>
<h4 id="At_most_once"><a href="#At_most_once" class="headerlink" title="At most once"></a>At most once</h4><p>这种策略下，只要Consumer读到了Message，就立即提交Offset，不考虑Message有没有被正确处理。如果Message刚读过来，还没有处理的时候，Consumer挂掉了，重新恢复后对上一次读取的Message不会重新读取，所以这种模式比较容易丢失数据。整个过程如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/27/1545902569574.png" alt=""></p>
<h4 id="At_least_once"><a href="#At_least_once" class="headerlink" title="At least once"></a>At least once</h4><p>这种策略下，Consumer需要读到Message，并且正确处理了Message后，才会提交Offset。如果Consumer挂掉，再恢复后，可以重新读取上一次的Message继续处理。这里就需要我们处理Message的逻辑必须是幂等的，否则会造成Message重复执行导致错误的业务结果。整个过程如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/27/1545903354244.png" alt=""></p>
<h4 id="Exactly_once"><a href="#Exactly_once" class="headerlink" title="Exactly once"></a>Exactly once</h4><p>这个策略想做到的是不丢数据，又可以不用幂等的处理逻辑。这里通常需要Kafka和外部系统配合使用。后面再做具体介绍。</p>
<h3 id="Consumer_Poll_Options"><a href="#Consumer_Poll_Options" class="headerlink" title="Consumer Poll Options"></a>Consumer Poll Options</h3><p>在Consumer订阅Topic拉取Message的行为中，会涉及到四个参数：</p>
<ul>
<li><code>fetch.min.bytes</code>：该参数表示每次拉取Message的最小量，默认是1Bytes。</li>
<li><code>fetch.max.bytes</code>：该参数表示每次拉取Message的最大量，默认是50MB。</li>
<li><code>max.poll.records</code>：该参数表示每次拉取Message的条数，默认是500条。</li>
<li><code>max.partitions.fetch.bytes</code>：该参数表示每个Partition在一次拉取中，可以被拉取到Message的最大量，默认是1MB。</li>
</ul>
<p>这些参数可以让Consumer控制拉取Message的速率，以及可以监控Consumer每次拉取Message的具体信息。</p>
<h3 id="Consumer_Offset_Reset_Behavior"><a href="#Consumer_Offset_Reset_Behavior" class="headerlink" title="Consumer Offset Reset Behavior"></a>Consumer Offset Reset Behavior</h3><p>在实际应用中，Consumer是很有可能在运行过程中挂掉的，那么当Consumer重新恢复后，拉取什么范围的Message，是有策略可以设置的，可以通过设置<code>auto.offset.reset</code>属性，常用的值有两个：</p>
<ul>
<li><code>earliest</code>：从Message文件的最开始进行拉取，既将Topic中的所有数据重新拉取过来。</li>
<li><code>latest</code>：从Message文件的最后开始拉取，既不考虑Topic之前的所有数据，只拉取最新的数据。</li>
</ul>
<p>在后面讲到CLI的时候，这部分再做详细阐述。</p>
<h3 id="Consumer_internal_thread"><a href="#Consumer_internal_thread" class="headerlink" title="Consumer internal thread"></a>Consumer internal thread</h3><p>为保证Consumer的稳定性和高可用性。Kafka有心跳机制，所以Consumer不光和Broker交互，也要和心跳监控节点交互：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/27/1545925702680.png" alt=""></p>
<p>这里引出了两个参数：</p>
<ul>
<li><code>seesion.timeout.ms</code>：该参数的作用是Broker认为Consumer挂掉的持续时间。默认为10秒。也就是说Broker在10秒内没有收到Consumer的心跳信号，那么认为该Consumer已经挂掉了。</li>
<li><code>heartbeat.interval.ms</code>：该参数决定了Consumer发送心跳信号的间隔时间。默认为3秒。</li>
</ul>
<p>总结一下前文介绍的Kafka核心概念。先上一张图总体概括：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/19/1545190605332.png" alt=""></p>
<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>在Producer层面，我们了解了以下知识点：</p>
<ul>
<li>Producer发送Message到Broker默认采用轮询方式，除非显示的将Message带着Key。</li>
<li>如果希望Message根据某个字段发送至相同的Partition中，可以将Message带着Key发送。</li>
<li>Producer有acks机制，关系到Message的完整性，以及整体MQ系统的整体性能（Message吞吐量）。</li>
<li>Producer发送Message有重试机制。</li>
<li>在实际使用时，我们通常需要考虑幂等Producer，以确保不会有业务上的错误。</li>
<li>Message压缩和批量发送有助于提高Message传输性能。</li>
</ul>
<h2 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h2><p>在Broker层面，我们了解了以下知识点：</p>
<ul>
<li>Partition是以文件夹的形式存储在Broker中的。</li>
<li>Partition有Replication的概念，可以确保Message的完整性。</li>
<li>Partition有Leader和ISR的概念。</li>
<li>Partition中Message存储的方式。</li>
<li>Partition中清理Message的策略。</li>
</ul>
<h2 id="Consumer-1"><a href="#Consumer-1" class="headerlink" title="Consumer"></a>Consumer</h2><p>在Consumer层面，我们了解了以下知识点：</p>
<ul>
<li>Consumer有组的概念，Consumer Group和Consumer获取Topic中数据的方式。</li>
<li>Consumer提交Offset的策略，关系到Consumer断点续传的方式。</li>
<li>Consumer如何控制获取Topic中Message的速率。</li>
<li>Consumer如何重制Offset。</li>
</ul>
<p>最后我们再明确一下有哪些是Kafka提供的保障，或者说是我们不能，也不应该违背的原则：</p>
<ul>
<li>Message写入Topic-Partition的顺序严格按照Producer发送Message的顺序。</li>
<li>Consumer从Topic-Partition读Message的顺序严格按照Partition中Message的Offset顺序。</li>
<li>如果Partition的Replication Factor是N，那么可以允许有N-1个Broker挂掉，而且Kafka可以正常运转。</li>
<li>只要Topic的Partition的数量恒定，那么带有指定Key的Message会始终写入该Key对应的Partition。</li>
<li>如果你想给Kafka集群中的某个Topic发送数据，你只需要连接Kafka集群中的一个Broker以及给定Topic名称既可。不用考虑Partition、Replication等等的问题。</li>
</ul>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>前面五个章节阐述了什么是MQ系统，然后基于这个大的框架介绍了Kafka系统中的核心模块，以及这些核心模块中的核心知识点。之后的章节主要就是实践部分，包括如何使用Kafka CLI、搭建Zookeeper、单机Kakfa、集群Kafka等。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>了解完Producer，接下来介绍Kafka中的Consumer的概念，以及在消费Message时有什么样的策略。</p>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><p>Consumer负责从Topic中读取数据，我们已经知道了Topic是通过名称确定唯一的，所以指定Consumer从哪个Topic中读数据，同样使用Topic名称指定。Kafka中的Consumer有以下几点需要我们注意：</p>
<ul>
<li>我们只需要指定需要从哪个Topic中读取数据即可。不需要关心Consumer是从哪个Broker中的哪个Partition中读数据，这些工作由Kafka帮我们处理好了。</li>
<li>当持有Topic的Broker挂掉，重新恢复后，Consumer可以自动重新从该Broker中读数据。</li>
<li>在一个Partition中，Consumer是按Offset的顺序读取数据的。</li>
<li>一个Consumer可以同时读取多个Broker中的不同Partition，但是Partition之间无法保证读取数据的顺序，因为是并行执行的。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-庖丁解牛：Producer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-4/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-4/</id>
    <published>2018-09-30T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>通过上一章节，我们知道了Kafka的Message是如何持久化的，知道了保证高可用性、稳定性的策略。这一节来看看Kafka中如何生产Message以及相关的策略。</p>
<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>简而言之，Producer就负责往Topic里发送数据，或者说写入数据。换言之，就是往组成这个Topic的一至多个Partition里写入数据。这里有三点需要注意：</p>
<ul>
<li>我们只需要通过Producer产生数据，往Topic里塞既可。Producer会自动去选择正确的、合适的Broker和Partition持久化数据。</li>
<li>Producer默认采用轮询的机制选择Broker往Partition里持久化数据的。</li>
<li>如果其中有一个Broker挂了，当它再恢复时，Producer会自动接纳它。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/18/1545090560721.png" alt=""></p>
<h3 id="Message_keys"><a href="#Message_keys" class="headerlink" title="Message keys"></a>Message keys</h3><p>Producer默认采用轮询的机制选择Broker往Partition里持久化数据。但当我们需要根据数据中的某个字段按Partition进行分组或者排序时，就需要在每条Message里添加Key，这个Key可以是数字，也可以是字符串等等。然后相同Key的Message永远会持久化到同一个Partition。</p>
<a id="more"></a>
<h3 id="Acks"><a href="#Acks" class="headerlink" title="Acks"></a>Acks</h3><p>Producer在发送生产出的数据给Broker时，可以选择三种模式，称为acks，它是Acknowledgment的缩写。意思是Broker对Producer即将发送来的数据采用何种确认方式。</p>
<h4 id="acks_3D0"><a href="#acks_3D0" class="headerlink" title="acks=0"></a>acks=0</h4><p>在该模式下，Producer不会等待Broker的确认反馈，即不关心Broker是否正确的将发送来的数据持久化，所以在这种模式下，很有可能会丢失数据。因为如果Broker挂了，Producer不会被通知到，所以还会不停的发送数据导致数据丢失。在对数据完整性需求不强烈的场景下，这种模式可以提高性能。</p>
<h4 id="acks_3D1"><a href="#acks_3D1" class="headerlink" title="acks=1"></a>acks=1</h4><p>默认采用的模式，该模式下Producer会等待Leader Broker的确认反馈，当Broker确实将数据持久化到至少一个Partition中后，给予Producer确认反馈，Producer才会继续发送数据。该模式下有几点需要注意：</p>
<ul>
<li>不保证Replicas也持久化了数据。</li>
<li>当Producer没有收到Broker的确认反馈时，Producer会尝试重新发送数据。</li>
<li>当Leader Broker挂了，但是Replicas又没有持久化数据时，还是会丢失数据。</li>
<li>该模式只能说是可以有效防止数据丢失。</li>
</ul>
<h4 id="acks_3Dall"><a href="#acks_3Dall" class="headerlink" title="acks=all"></a>acks=all</h4><p>该模式下，Producer同样需要等待Broker的确认，但是确认更为严格，需要所有的Partition（Leader + Replicas）都持久化数据后才返回确认信息。这种模式下，只要Replicas足够多，数据基本不会丢失。</p>
<p>在该模式下，还有一个重要的参数<code>min.insync.replicas</code>需要配置。该参数的意思是当<code>acks=all</code>时，至少有多少个Replicas需要确认已成功持久化数据，这个Replicas数量也包括Leader。</p>
<p>举个例子，假设有三个Broker，参数为<code>min.insync.replicas=2</code>、<code>replication.factor=3</code>、<code>acks=all</code>，那么Producer每次发送Message时，都需要至少2个Broker给予确认反馈，换句话说，在这个Kafka集群中，只能允许一个Broker挂掉。如果<code>min.insync.replicas=3</code>，那么一个Broker都不能挂，否则Producer在发送Message时会收到<code>NOT_ENOUGH_REPLICAS</code>的异常。</p>
<h3 id="Retry"><a href="#Retry" class="headerlink" title="Retry"></a>Retry</h3><p>有时候Producer发送Message失败可能并不是因为Broker挂了，可能是因为网络问题，没有连接到Broker等等。这种问题可能在很短暂的时间内就会自动修复，那么在这种情况下，我们希望Producer在发送失败后能重新尝试发送。这里就需要设置<code>retries</code>这个参数，意思就是重试的次数，默认是0次，可以根据实际业务情况设置。</p>
<p>但是当设置了<code>retries</code>参数大于0后，有可能会带来新的问题。假如我们需要相同Key的Message进入特定的Partition，并且是要严格按照Producer生产Message的顺序排序。那么此时如果第一条Message发送失败，第二条Message发送成功了，第一条通过重试发送成功了，那Message的顺序就发生了变化。</p>
<p>这里又会引出一个参数<code>max.in.flight.requests.per.connection</code>，这个参数默认是5，意思是在被Broker阻止前，未通过acks确认的发送请求最大数，也就是在Broker处排队等待acks确认的Message数量。所以刚才那个场景，第一条和第二条Message都在Broker那排队等待确认放行，这时第一条失败了，等重试的第一条Message再来排队时，第二条早都通过进去了，所以排序就乱了。</p>
<p>如果想在设置了<code>retries</code>还要严格控制Message顺序，可以把<code>max.in.flight.requests.per.connection</code>设置为1。让Broker处永远只有一条Message在排队，就可以严格控制顺序了。但是这样做会严重影响性能（接收Message的吞吐量）。</p>
<h3 id="Idempotent_Producer"><a href="#Idempotent_Producer" class="headerlink" title="Idempotent Producer"></a>Idempotent Producer</h3><p>在实际情况中，经常会遇到一个现象，那就是当Broker给Producer返回acks确认时，网络出异常了，导致Producer没有收到ack确认，于是，Producer进行重试。如果Consumer的Offset策略（在后续章节会介绍）是<code>at least once</code>或者是<code>exactly once</code>，那么第一次对Message就已经进行了处理，比如入库。那么第二次会对相同的Message再做一次处理，对相同数据进行重复处理，势必会引起业务上的错误。整个过程如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/26/1545807972109.png" alt=""></p>
<p>所以这就需要幂等Producer来保证我们处理数据的唯一性。Kafka在0.11版本之后，就为我们提供了定义幂等Producer的能力，可以通过将<code>enable.idempotence.config</code>参数设置为<code>true</code>来定义幂等Producer。将Producer定义为幂等后，还要设置其他对应的参数：</p>
<ul>
<li><code>retries=Integer.MAX_VALUE</code></li>
<li><code>max.in.flight.requests.per.connection=1 (Kafka &gt;= v0.11 &amp; &lt; v1.1)</code></li>
<li><code>max.in.flight.requests.per.connection=5 (Kafka &gt;= v1.1)</code></li>
<li><code>acks=all</code></li>
</ul>
<p>如此设置后，可以有效防止重复消费Message，整个过程就会如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/26/1545808307901.png" alt=""></p>
<h3 id="Message_Compression"><a href="#Message_Compression" class="headerlink" title="Message Compression"></a>Message Compression</h3><p>消息压缩的作用不言而喻：</p>
<ul>
<li>加快网络传输速度，减少消息延迟。</li>
<li>更有效的利用磁盘空间。</li>
<li>加快消息吞吐率。</li>
</ul>
<p>只需要设置<code>compression.type</code>参数，该参数默认是<code>none</code>，可选项有<code>gzip</code>、<code>lz4</code>、<code>snappy</code>。建议使用<code>lz4</code>或者<code>snappy</code>。</p>
<h3 id="Message_Batch"><a href="#Message_Batch" class="headerlink" title="Message Batch"></a>Message Batch</h3><p>上面介绍了<code>max.in.flight.requests.per.connection</code>参数，默认会在Broker那排队5条Message，那么如果第六条来了怎么办呢？这时候Kafka会自动开启批量处理Message的模式，将这6条Message作为一个批次进行处理。这一个批次可以看作是一次Message处理请求。</p>
<p>开启批量模式后，会引出两个参数：</p>
<ul>
<li><code>linger.ms</code>：每次批量处理的间隔时间。如果设为5，那么就是每5毫秒对Message进行一次批量处理。</li>
<li><code>batch.size</code>：每个批次的最大字节数，默认是16KB，可以设置为32KB或者64KB，可以提高性能。</li>
</ul>
<p>过程如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/26/1545814677871.png" alt=""></p>
<h3 id="Producer_Buffer"><a href="#Producer_Buffer" class="headerlink" title="Producer Buffer"></a>Producer Buffer</h3><p>在大多数情况下，Consumer消费Message的速率是远不如Producer生产Message的速率的。所以Producer有一个缓存机制，将Broker还没来得及接收的Message缓存在内存中。缓存的大小可以通过<code>buffer.memory</code>配置，默认大小是32MB。默认存储时间为7天，这个时间可以通过设置Broker的<code>offset.retention.minutes</code>属性改变。</p>
<p>如果Producer的缓存被打满后，Producer会被阻塞，阻塞的最大时间可以通过<code>max.block.ms</code>配置，默认大小是60秒。</p>
<p>概括一下，就是当Producer生产Message的速率大于Broker接收Message（Consumer消费数据）的速率时，Producer会把Broker还没来得及接收的Message存在缓存里（内存），当存满设置的缓存大小后，Producer将不再发送Message给Broker，也就是进入阻塞状态，如果在设置的阻塞时间内，缓存还没有被释放出有用空间，那么Producer将抛出异常。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节我们了解了Kafka的Producer，介绍很重要的Acks机制、Retry机制、幂等机制以及消息批次机制等。这些和我们满足性能方面的需求息息相关，同时我们也进一步了解了Kafka是如何保证业务层面的高可用性的。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>通过上一章节，我们知道了Kafka的Message是如何持久化的，知道了保证高可用性、稳定性的策略。这一节来看看Kafka中如何生产Message以及相关的策略。</p>
<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>简而言之，Producer就负责往Topic里发送数据，或者说写入数据。换言之，就是往组成这个Topic的一至多个Partition里写入数据。这里有三点需要注意：</p>
<ul>
<li>我们只需要通过Producer产生数据，往Topic里塞既可。Producer会自动去选择正确的、合适的Broker和Partition持久化数据。</li>
<li>Producer默认采用轮询的机制选择Broker往Partition里持久化数据的。</li>
<li>如果其中有一个Broker挂了，当它再恢复时，Producer会自动接纳它。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/18/1545090560721.png" alt=""></p>
<h3 id="Message_keys"><a href="#Message_keys" class="headerlink" title="Message keys"></a>Message keys</h3><p>Producer默认采用轮询的机制选择Broker往Partition里持久化数据。但当我们需要根据数据中的某个字段按Partition进行分组或者排序时，就需要在每条Message里添加Key，这个Key可以是数字，也可以是字符串等等。然后相同Key的Message永远会持久化到同一个Partition。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-庖丁解牛：Partition]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-3/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-3/</id>
    <published>2018-09-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>了解了Kafka的窗户和内核之后，我们深入Broker中，看看Topic和Broker之间的关系，它们之间到底是用什么联系起来的。Broker对Message的持久化是如何处理的。</p>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>Kafka的Partition是分区的概念，在Kafka中，一个Topic可以有多个Partition，换句话说，就是一个Topic中的内容是被多个Partition分割的。对于Partition，我们需要注意以下几个要点：</p>
<ul>
<li>一个Topic下的所有Partition是有顺序的，或者说在创建Topic和Partition时，Partition的顺序就已经是确定了的。</li>
<li>每条进入Partition中的Message都会获得一个自增的ID，这个ID称为Offset（消息的偏移量）。</li>
<li>通常在说Message的Offset时，只是针对该条Message所在的Partition而言。举个例子，Partition-0中Offset为3的Message和Partition-1中Offset为3的Message没有任何关系。</li>
<li>当说到Message的顺序时，通常有两种解读：<ul>
<li>业务语义上的Message顺序，如下图所示，1至4条Message之间是有语义顺序的，可以理解为是消息生产者生产消息时的顺序。</li>
<li>Partition中的Message顺序，如下图所示，Partition-1中的Message如果按照Offset的顺序，那么第一条和第二条Message其实是语义上的第一条和第三条Message。</li>
</ul>
</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/kafka-message-order.png" alt=""></p>
<ul>
<li>当Message进入Partition后，它的Offset和内容就无法再修改了。</li>
<li>Message默认是随机存储在一个Topic下的不同的Partition中的，如上图。除非显示的指定Partition。</li>
<li>存储在Partition中的Message是有时效性的，默认是保存一周，可以通过配置更改（后续章节会介绍）。</li>
</ul>
<a id="more"></a>
<p>在Kafka中，一个Partition对应物理机器上的一个文件夹，文件夹命名会以Topic名称加序号表示。换句话说，Partition在Broker中以文件夹的形式存在。每个Partition文件夹中会有多个大小相等的日志段文件（Segment File），消息生产者生产的消息发送到Broker后就会以追加到日志文件末尾的方式持久化到Partition中。</p>
<h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>我们再来看一个和Partition相关的概念，Replication。从字面意思就可以看出，这是Partition副本的意思。Replication Factor决定了将Partition复制几份，也就是将数据复制几份。Partition的副本也是会随机被分配到任意Broker中。下图展示了它们之间的关系：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/17/1545061968721.png" alt=""></p>
<p>从上图中可以看出，如果Broker 102挂掉了，是不会影响我们的Kafka集群的运转的，因为我们的数据并没有丢失，Broker 101和Broker 103中任何持久化着Topic-A的数据。这就是Replication的作用，它可以有效保证数据在Kafka系统中的完整性和有效性。</p>
<h3 id="Leader_for_Partition"><a href="#Leader_for_Partition" class="headerlink" title="Leader for Partition"></a>Leader for Partition</h3><p>当Partition有多个副本时，又会引出一个概念，那就是Partition的Leader Broker。关于Partition的Leader有以下几个要点：</p>
<ul>
<li>在任何时候，只有一个Broker会成为某个Partition的Leader。</li>
<li>只有作为Leader的Broker才会为Partition接收和处理数据。其他持有Partition副本的Broker只是从Leader Broker同步数据。</li>
<li>每个Partition只有一个Leader Broker，但可以有多个随从Broker，或者说是ISR（in-sync replica）。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/18/1545064328376.png" alt=""></p>
<p>上图所示，Broker 101是Topic-A Partition 0的Leader Broker。Broker 102是Topic-A Partition 1的Leader Broker。如果Broker 101挂掉了，那么Broker 102会自动被选举为新的Topic-A Partition 0的Leader Broker。当Broker 101恢复后，会重新将Leader交还给Broker 101。选举Leader Broker的工作由Zookeeper帮Kafka完成，这里暂做了解。</p>
<h3 id="Partition_Count_and_Replication_Factor_Convention"><a href="#Partition_Count_and_Replication_Factor_Convention" class="headerlink" title="Partition Count  and Replication Factor Convention"></a>Partition Count  and Replication Factor Convention</h3><p>在通常情况下，设置Topic的Partition数量和Replication数量有一些惯例可以参照。</p>
<p><strong>首先这两个参数是非常非常重要的，直接关系到Kafka集群的性能、高可用问题。在创建Topic之前，一定要先思考如何设置Partition数量和Replication数量。并且尽量不要在之后调整Partition数量和Replication数量。</strong></p>
<p>前文中讲过，如果在Kafka运行时调整Topic的Partition数量，会直接影响Message根据Key的顺序问题。如果调整Replication数量，会给集群带来较大的性能压力，因为涉及到Zookeeper要重新选举Leader一系列操作。</p>
<p>所以在较小的Kafka集群中（小于6个Broker），一般每个Topic的Partition数量为Broker数量的两倍。在较大的Kafka集群中（大于12个Broker），一般每个Topic的Partition数量等于Broker的数量。介于这两者之间的可以根据具体业务和IaaS的情况，设置两倍于Broker或等于Broker数量。</p>
<p><strong>Replication数量最少为2，通常为3，最大也就设置到4</strong>。前文中说过，Replication的数量关系到我们可以容忍有几个Broker挂掉（N -1个）。而且如果<code>acks=all</code>，Replication太多会影响效率，并且会增加磁盘空间。所以综上，一般将Replication Factor设置为3，比较合理。</p>
<h3 id="Segment_File"><a href="#Segment_File" class="headerlink" title="Segment File"></a>Segment File</h3><p>我们已经知道了Topic是由Partition构成的。再来说说构成Partition的Segment文件。</p>
<p>进入<code>kafka_2.12-2.0.0/data/kafka</code>这个目录后（这里的目录暂做了解，后续在Kafka搭建小节里会讲到），可以看到一些以<code>Topic name-index</code>这种格式命名的文件夹，这些就是Partition：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/29/1546053528484.png" alt=""></p>
<p>进入<code>first_topic-0</code>这个Partition后，可以看到有一些文件，<code>*.log</code>就是Partition的Segment文件：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/29/1546053710199.png" alt=""></p>
<p>Partition的Segment文件涉及到两个参数：</p>
<ul>
<li><code>log.segment.bytes</code>：设置每个Segment文件的大小，默认是1GB。</li>
<li><code>log.segment.ms</code>：设置每个Segment文件允许写入的时间，默认是一周。</li>
</ul>
<p>上面两个参数说明了，Partition的Segment文件可以有多个，当一个Segment的大小达到<code>log.segment.bytes</code>参数设置的大小后，关闭（不允许写入）这个Segment文件，并自动开启下一个Segment文件。如果一个Segment文件在<code>log.segment.ms</code>参数设置的时间内没有写满，那么也将自动关闭，并开启新的Segment文件。所以始终只会有一个处于活跃状态的Segment文件可以被写入。</p>
<p><code>log.segment.bytes</code>设置的越小，Partition的Segment文件数就越多，对关闭的<code>*.log</code>文件压缩操作就越频繁。<code>log.segment.ms</code>的值也同样影响文件压缩的频率。所以这两个参数要根据业务实际情况，对吞吐量的需求去合理设置。</p>
<p>在上图中，还看到<code>*.index</code>和<code>*.timeindex</code>两个文件，这两个都是帮助Kafka查找Message的索引文件：</p>
<ul>
<li><code>*.index</code>：这个文件记录了Message Offset，可以让Kafka通过Message Offset快速定位到Message。</li>
<li><code>*.timeindex</code>：这个文件记录了Message的时间戳，可以让Kafka通过绝对时间定位到Message。</li>
</ul>
<p>这三个文件的名称是一样的，整个名称的长度为20位数字，第一个Segment文件从0开始，后续每个Segment文件的名称为上一个<code>*.log</code>文件中最后一条Message Offset，其他位数用0填充，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0000000000000000000.index&#10;0000000000000000000.log&#10;0000000000000037489.index&#10;0000000000000037489.log&#10;0000000000005467283.index&#10;0000000000005467283.log</span><br></pre></td></tr></table></figure>
<p>用一张图来概括Partition和Segment文件的关系：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/29/1546055197464.png" alt=""></p>
<h3 id="Delete_Cleanup_Policy"><a href="#Delete_Cleanup_Policy" class="headerlink" title="Delete Cleanup Policy"></a>Delete Cleanup Policy</h3><p>Kafka的Message既然是存在磁盘上的，那么必然会有数据回收或者数据清理的机制，这里涉及到一个参数<code>log.cleanup.policy</code>如果将值设置为<code>delete</code>，那么Partition中的Message会基于规则在一段时间后被删除。这里的规则有两个，一个是基于时间的，一个是基于Partition大小的。</p>
<h4 id="log-retention-hours"><a href="#log-retention-hours" class="headerlink" title="log.retention.hours"></a>log.retention.hours</h4><p><code>log.retention.hours</code>参数的值默认是168小时，既1周时间，也就是Partition中的未处于活跃状态的Segment文件只保留一周，一周后会被自动删除。</p>
<p>这个参数如果设置的比较大，那么意味着Topic的历史数据会保留较长时间，Consumer丢失数据的容错率会高一些。同时会占用更多磁盘空间。如果设置的比较小，意味着Topic的历史数据保留的时间较短，Consumer丢失数据的潜在风险较大，但是占用的磁盘空间较小。所以该值需要根据实际情况设置。</p>
<h4 id="log-retention-bytes"><a href="#log-retention-bytes" class="headerlink" title="log.retention.bytes"></a>log.retention.bytes</h4><p><code>log.retention.bytes</code>参数的值默认是-1，也就是指Partition的大小是无穷大的，既不考虑Partition的大小。如果将其设置为524288000，那么就表示当Partition大小超过500MB时，会删除未处于活跃状态的Segment文件。</p>
<p>通常情况下，使用默认配置就好，既不考虑Partition大小，历史数据保留一周。但也可以根据业务自行设置，灵活组合。但有一点需要注意的是，这两个规则只要达到一个，就会启动清理数据的任务。</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/31/1546267108235.png" alt=""></p>
<h3 id="Compaction_Cleanup_Policy"><a href="#Compaction_Cleanup_Policy" class="headerlink" title="Compaction Cleanup Policy"></a>Compaction Cleanup Policy</h3><p>另外一个策略是压缩策略，<code>__consumer_offset</code>这个Topic默认采用的就是这种策略，我们先看一张图：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/1/1/1546353684917.png" alt=""></p>
<p>上图表示的应该比较清楚了，压缩模式就是把相同Key的旧数据删了，每个Key只留下最近的数据。这种模式相对DELETE策略，至少每个Key都会有数据，但是历史数据会丢失。</p>
<p>当<code>log.cleanup.policy=compact</code>时，有以下相关的一些参数需要我们注意：</p>
<ul>
<li><code>segment.ms</code>：该参数会使用默认的值，默认为7天。该参数表示等待关闭活跃状态Segment文件的时间。</li>
<li><code>segment.bytes</code>：每个Segment文件的大小，默认为1G。</li>
<li><code>min.compaction.lag.ms</code>：当Message可以被压缩的时候，要等待的时长，也就是延迟压缩的时间，默认是0。</li>
<li><code>delete.retention.ms</code>：当Message被标记为需要压缩到删除它之间的时间，默认为24小时。</li>
<li><code>min.cleanable.dirty.ratio</code>：压缩率，默认为0.5。</li>
</ul>
<h4 id="Cleanup_Frequency"><a href="#Cleanup_Frequency" class="headerlink" title="Cleanup Frequency"></a>Cleanup Frequency</h4><p>不论是删除策略还是压缩策略，都是针对Partition的Segment文件进行的，根本还是磁盘IO操作，所以这种清理工作不应该过于频繁，否则会对整个Broker造成性能方面的影响。对Segment文件的大小也要把控在合理的范围内。太小，太多的Segment文件肯定会使清理工作更加频繁。</p>
<p>另外还可以对<code>log.cleaner.backoff.ms</code>参数进行设置来控制清理频率，这个参数控制检测是否需要清理的时间，默认是15秒检查一次。将其设大一点，也可以降低清理频率。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节通过对Partition、Replication、Segment File的介绍可以了解Broker中对Message持久化的方式。通过对Partition Leader、Relipcation Factor、Message的处理策略的介绍了解了Kafka保证可用性和稳定性的基本策略。这些概念是之后我们进行实践时的基础。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>了解了Kafka的窗户和内核之后，我们深入Broker中，看看Topic和Broker之间的关系，它们之间到底是用什么联系起来的。Broker对Message的持久化是如何处理的。</p>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>Kafka的Partition是分区的概念，在Kafka中，一个Topic可以有多个Partition，换句话说，就是一个Topic中的内容是被多个Partition分割的。对于Partition，我们需要注意以下几个要点：</p>
<ul>
<li>一个Topic下的所有Partition是有顺序的，或者说在创建Topic和Partition时，Partition的顺序就已经是确定了的。</li>
<li>每条进入Partition中的Message都会获得一个自增的ID，这个ID称为Offset（消息的偏移量）。</li>
<li>通常在说Message的Offset时，只是针对该条Message所在的Partition而言。举个例子，Partition-0中Offset为3的Message和Partition-1中Offset为3的Message没有任何关系。</li>
<li>当说到Message的顺序时，通常有两种解读：<ul>
<li>业务语义上的Message顺序，如下图所示，1至4条Message之间是有语义顺序的，可以理解为是消息生产者生产消息时的顺序。</li>
<li>Partition中的Message顺序，如下图所示，Partition-1中的Message如果按照Offset的顺序，那么第一条和第二条Message其实是语义上的第一条和第三条Message。</li>
</ul>
</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/kafka-message-order.png" alt=""></p>
<ul>
<li>当Message进入Partition后，它的Offset和内容就无法再修改了。</li>
<li>Message默认是随机存储在一个Topic下的不同的Partition中的，如上图。除非显示的指定Partition。</li>
<li>存储在Partition中的Message是有时效性的，默认是保存一周，可以通过配置更改（后续章节会介绍）。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-庖丁解牛：Topic&Broker]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-2/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-2/</id>
    <published>2018-08-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Apache Kafka正是上节描述的MQ系统，但不仅是MQ系统，它往往也被描述为<strong>分布式提交日志系统</strong>或者<strong>分布式流式处理系统</strong>。从这节开始，我们将逐步了解Kafka的核心概念。</p>
<h2 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h2><p>在Kafka中，Topic可以理解为表示一组特殊的数据流。可以将它想象为关系性数据库中的表。</p>
<ul>
<li>数据库中的表存储着同一类的数据。那么Topic同样表示同一类的数据流。</li>
<li>数据库中的表可以根据需求创建多张。那么Topic同样可以根据需求创建多个，但有一点区别是，Topic没有像数据库表中约束（Constraints）的概念。</li>
<li>数据库中表的名称是不能重复的，表名能唯一确定一张表。那么Topic同样是以名称确定唯一的，Topic名称不能重复。</li>
</ul>
<a id="more"></a>
<h2 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h2><p>一个Kafka的Server就称之为Broker，可以每台物理服务器上只部署一个Broker，可以将多个Broker部署在一台物理服务器上。本身Broker这个单词的意思是中间代理的意思。Broker负责接收Producer发送的消息、对消息进行持久化、让Consumer获取消息。</p>
<p>关于Broker，我们需要注意以下几点概念：</p>
<ul>
<li>Kafka集群就是由多个Broker组成的。</li>
<li>每个Broker都有一个整数类型的唯一标识ID。</li>
<li>当我们连接到任意一个Broker后，我们就已经连接到了整个Kafka集群。我们连接的第一个Broker称之为Bootstrap Broker。</li>
<li>通常，最小的Kafka集群最好有三个Broker。</li>
</ul>
<p>我们来看看Broker、Topic、Partition（后续章节会介绍）之间的关系。假设有Broker 101、Broker 102、Broker 103三个Broker。Topic-A、Topic-B两个Topic，这两个Topic分别有三个Partition和两个Partition。他们的关系如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/17/1545060563441.png" alt=""></p>
<p>可以看到，Topic的Partition在Kafka集群中是随机分配给Broker的。也就是说Topic-A的数据会分别被持久化在这三个Broker中，而Topic-B的数据只会持久化在Broker 101和Broker 102中。如果Topic-A再加一个Partition 4，则它会随机被分配给任意一个Broker。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节介绍了Topic和Broker的概念，Topic承载了Message的输入输出，相当于Kafka对外的窗户。Broker则负责Kafka内部核心的功能，比如Message持久化、如何保证Kafka高可用性等等。。在后续的章节里，会详细介绍它们的各种配置和用法。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Apache Kafka正是上节描述的MQ系统，但不仅是MQ系统，它往往也被描述为<strong>分布式提交日志系统</strong>或者<strong>分布式流式处理系统</strong>。从这节开始，我们将逐步了解Kafka的核心概念。</p>
<h2 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h2><p>在Kafka中，Topic可以理解为表示一组特殊的数据流。可以将它想象为关系性数据库中的表。</p>
<ul>
<li>数据库中的表存储着同一类的数据。那么Topic同样表示同一类的数据流。</li>
<li>数据库中的表可以根据需求创建多张。那么Topic同样可以根据需求创建多个，但有一点区别是，Topic没有像数据库表中约束（Constraints）的概念。</li>
<li>数据库中表的名称是不能重复的，表名能唯一确定一张表。那么Topic同样是以名称确定唯一的，Topic名称不能重复。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
</feed>
