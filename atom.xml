<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[程序员说]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://www.devtalking.com/"/>
  <updated>2020-06-21T08:12:29.010Z</updated>
  <id>http://www.devtalking.com/</id>
  
  <author>
    <name><![CDATA[DevTalking]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：重要配置和性能探讨]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-19/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-19/</id>
    <published>2019-04-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>最后这一章节总结Kafka中需要特别关注的重要配置以及影响Kafka性能的因素。</p>
<h3 id="u91CD_u8981_u914D_u7F6E"><a href="#u91CD_u8981_u914D_u7F6E" class="headerlink" title="重要配置"></a>重要配置</h3><ul>
<li><code>auto.create.topics.enable</code>：该配置项默认值是<code>true</code>，但在生产环境最好设置为<code>false</code>。这样可以控制创建Topic的人以及创建时间。</li>
<li><code>background.threads</code>：该配置项默认值是10，既整个Kafka在执行各种任务时会启动的线程数。如果你的CPU很强劲，那么可以将线程数设大一点。</li>
<li><code>delete.topic.enable</code>：该配置项默认值是<code>false</code>，可以根据实际需求改变，在生产环境还是建议保持默认值，这样至少不会出现Topic被误删的情况。</li>
<li><code>log.flush.interval.messages</code>：该配置项最好保持默认值，把这个任务交给操作系统的文件系统去处理。</li>
<li><code>log.retention.hours</code>：日志文件保留的时间默认是168小时，既7天。这个配置可以根据具体业务需求而定。</li>
<li><code>message.max.bytes</code>：每条Message或一批次Message的大小默认是1MB。这个配置也要根据具体需求而定，比如带宽的情况。</li>
<li><code>min.insync.replicas</code>：该配置项的默认值是1，既在acks=all时，最少得有一个Replica进行确认回执。建议在生产环境配置为2，保证数据的完整性。</li>
<li><code>num.io.threads</code>：处理I/O操作的线程数，默认是8个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.network.threads</code>：处理网络请求和响应的线程数，默认是3个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。默认值是1，根据实际情况配置数据目录数，从而判断该配置项应该如何设置。</li>
<li><code>num.replica.fetchers</code>：该配置项影响Replicas同步数据的速度，默认值是1，如果发现Replicas同步延迟较大，可以提升该配置项。</li>
<li><code>offsets.retention.minutes</code>：Offset保留的时间，默认值是1440，既24小时。在生产环境建议将该配置项设大一点，比如设置为1个月，保证消费数据的完整性。</li>
<li><code>unclean.leader.election.enable</code>：该配置项的作用是，指定是否可以将非ISR的Replicas选举为Leader，默认值为<code>false</code>。在生产环境建议保持默认值，防止数据丢失。</li>
<li><code>zookeeper.session.timeout.ms</code>：Zookeeper会话超时时间，默认值为6000。按实际情况而定，通常情况下保持60秒即可。</li>
<li><code>default.replication.factor</code>：默认Replication Factor为1，建议设置为2或者3，以保证数据完整性和整个集群的健壮性。</li>
<li><code>num.partitions</code>：Topic默认的Partition数，默认是1，建议设置为3或者6，以保证数据完整性和整个集群的健壮性。</li>
</ul>
<a id="more"></a>
<p>以上是比较重要，需要我们根据实际情况额外关注的配置项。</p>
<h3 id="u5F71_u54CD_u6027_u80FD_u7684_u56E0_u7D20"><a href="#u5F71_u54CD_u6027_u80FD_u7684_u56E0_u7D20" class="headerlink" title="影响性能的因素"></a>影响性能的因素</h3><p>影响Kafka性能大概有五个因素。</p>
<h4 id="u78C1_u76D8I/O"><a href="#u78C1_u76D8I/O" class="headerlink" title="磁盘I/O"></a>磁盘I/O</h4><p>我们知道Kafka是将大多数数据保存在磁盘上的。所以磁盘的读写性能很大程度上会影响Kafka系统的性能。所以我们可以注意以下几点：</p>
<ul>
<li>使用性能比较好的XFS日志文档系统，既Linux中的文件系统。</li>
<li>如果发现在I/O操作方面出现了瓶颈，那么可以通过扩充磁盘来改善。Broker配置文件中的<code>log.dirs</code>配置项可以配置多个数据目录路径。</li>
<li>设置合理的数据清理时间，也就是配置文件中的<code>log.retention.hours</code>配置项。如果已经消费的数据长时间保留在磁盘中，既没有意义又会对Kafka读写性能造成影响。</li>
<li>及时监控部署Kafka服务器的磁盘情况。</li>
</ul>
<h4 id="u7F51_u7EDC"><a href="#u7F51_u7EDC" class="headerlink" title="网络"></a>网络</h4><p>数据传输的延迟性是任何MQ系统都要关注的问题，Kafka也不例外，在这方面我们要注意以下几点：</p>
<ul>
<li>确保部署Kafka的服务器和部署Zookeeper的服务器在一个内网内，服务器之间的物理距离不要太远，比如一个在北京，一个在上海。</li>
<li>确保部署不同Kafka Broker的服务器在一个内网内，服务器之间的物理距离不要太远。</li>
<li>保证服务器有比较好的网络带宽配置。</li>
</ul>
<h4 id="RAM"><a href="#RAM" class="headerlink" title="RAM"></a>RAM</h4><p>Kafka的高性能特性离不开对计算机内存的使用技术，对内存的使用大体分Java堆内存的使用和操作系统（Linux）Page Cache的使用：</p>
<ul>
<li>在启动Kafka Broker时，可以通过环境变量<code>KAFKA_HEAP_OPTS</code>设置对Java堆内存的使用大小。比如<code>export KAFKA_HEAP_OPTS=“-Xmx4g”</code>。</li>
<li>Broker中的Partition数量会影响对Java堆内存的使用大小。Partition越多，堆内存使用的越多。</li>
<li>对于Page Cache/文件Cache，我们不用做任何设置：<blockquote>
<p>Page Cache：当应用程序需要读取文件中的数据时，操作系统先分配一些内存，将数据从存储设备读入到这些内存中，然后再将数据分发给应用程序；当需要往文件中写数据时，操作系统先分配内存接收用户数据，然后再将数据从内存写到磁盘上。文件 Cache 管理指的就是对这些由操作系统分配，并用来存储文件数据的内存的管理。</p>
</blockquote>
</li>
</ul>
<h4 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h4><p>因为Kafka在Message传输的整个过程中，不会对Message进行任何计算，所以CPU通常不会成为Kafka性能的主要瓶颈。但是在一些情况下，也会对Kafka的性能产生影响：</p>
<ul>
<li>Message加密/解密的过程中会增加CPU的负载。</li>
<li>Message压缩/解压的过程中会增加CPU的负载。</li>
<li>在GC堆内存时会增加CPU的负载。</li>
</ul>
<h4 id="u64CD_u4F5C_u7CFB_u7EDF"><a href="#u64CD_u4F5C_u7CFB_u7EDF" class="headerlink" title="操作系统"></a>操作系统</h4><p>通常优先推荐使用Linux系统，尤其在高性能计算领域，Linux已经成为一个占主导地位的操作系统。其次也可以使用Solaris系统。Windows系统是不推荐使用的。另外，尽量保证运行Kafka Broker的操作系统中，不要运行其他的应用程序，避免和Kafka产生资源竞争，从而影响性能。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这是本小册的最后一章节，探讨了Kafka的一些重要配置和影响Kafka性能的关键因素。整个小册从最基本的认知到核心概念的诠释再到实践，帮助小伙伴渡过Kafka和Zookeeper的萌新阶段。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>最后这一章节总结Kafka中需要特别关注的重要配置以及影响Kafka性能的因素。</p>
<h3 id="u91CD_u8981_u914D_u7F6E"><a href="#u91CD_u8981_u914D_u7F6E" class="headerlink" title="重要配置"></a>重要配置</h3><ul>
<li><code>auto.create.topics.enable</code>：该配置项默认值是<code>true</code>，但在生产环境最好设置为<code>false</code>。这样可以控制创建Topic的人以及创建时间。</li>
<li><code>background.threads</code>：该配置项默认值是10，既整个Kafka在执行各种任务时会启动的线程数。如果你的CPU很强劲，那么可以将线程数设大一点。</li>
<li><code>delete.topic.enable</code>：该配置项默认值是<code>false</code>，可以根据实际需求改变，在生产环境还是建议保持默认值，这样至少不会出现Topic被误删的情况。</li>
<li><code>log.flush.interval.messages</code>：该配置项最好保持默认值，把这个任务交给操作系统的文件系统去处理。</li>
<li><code>log.retention.hours</code>：日志文件保留的时间默认是168小时，既7天。这个配置可以根据具体业务需求而定。</li>
<li><code>message.max.bytes</code>：每条Message或一批次Message的大小默认是1MB。这个配置也要根据具体需求而定，比如带宽的情况。</li>
<li><code>min.insync.replicas</code>：该配置项的默认值是1，既在acks=all时，最少得有一个Replica进行确认回执。建议在生产环境配置为2，保证数据的完整性。</li>
<li><code>num.io.threads</code>：处理I/O操作的线程数，默认是8个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.network.threads</code>：处理网络请求和响应的线程数，默认是3个线程。如果觉得在这个环节达到了瓶颈，那么可以适当调整该参数。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。默认值是1，根据实际情况配置数据目录数，从而判断该配置项应该如何设置。</li>
<li><code>num.replica.fetchers</code>：该配置项影响Replicas同步数据的速度，默认值是1，如果发现Replicas同步延迟较大，可以提升该配置项。</li>
<li><code>offsets.retention.minutes</code>：Offset保留的时间，默认值是1440，既24小时。在生产环境建议将该配置项设大一点，比如设置为1个月，保证消费数据的完整性。</li>
<li><code>unclean.leader.election.enable</code>：该配置项的作用是，指定是否可以将非ISR的Replicas选举为Leader，默认值为<code>false</code>。在生产环境建议保持默认值，防止数据丢失。</li>
<li><code>zookeeper.session.timeout.ms</code>：Zookeeper会话超时时间，默认值为6000。按实际情况而定，通常情况下保持60秒即可。</li>
<li><code>default.replication.factor</code>：默认Replication Factor为1，建议设置为2或者3，以保证数据完整性和整个集群的健壮性。</li>
<li><code>num.partitions</code>：Topic默认的Partition数，默认是1，建议设置为3或者6，以保证数据完整性和整个集群的健壮性。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：搭建Kafka相关的UI工具]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-18/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-18/</id>
    <published>2019-03-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节主要介绍Zookeeper和Kafka的UI管理工具。</p>
<h3 id="ZKUI"><a href="#ZKUI" class="headerlink" title="ZKUI"></a>ZKUI</h3><p>ZKUI是一款简洁易用的Zookeeper信息管理工具。首先从<a href="https://github.com/DeemOpen/zkui" target="_blank" rel="external">Github</a>上克隆工程到本地，这是一个Maven工程，然后<code>mvn clean install</code>，在<code>target</code>目录下打出两个jar包<code>zkui-2.0-SNAPSHOT.jar</code>和<code>zkui-2.0-SNAPSHOT-jar-with-dependencies.jar</code>，将其上传至你的阿里云ECS。因为我们Zookeeper是集群模式，所以首先需要修改<code>config.cfg</code>中的Zookeeper地址：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Comma seperated list of all the zookeeper servers&#10;zkServer=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181</span><br></pre></td></tr></table></figure></p>
<p>然后运行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &#38;</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>成功后，访问<code>http://ECS外网IP:9090</code>即可，默认用户名密码是<code>admin/manager</code>。如果有需要可以自行在<code>config.cfg</code>文件中进行配置。</p>
<blockquote>
<p>注意：ZKUI需要JDK7以上的环境。</p>
</blockquote>
<p>然后登录ZKUI，可以看到如下界面：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576430353.png" alt=""></p>
<p>整个界面分为三部分：</p>
<ul>
<li>顶部一行是快捷操作，比如创建zNode、删除zNode、给zNode添加数据、每个Zookeeper Server的监控信息等。</li>
<li>左侧列出的是含有子zNode的zNode，所以文件夹作为icon。点击后会进入该zNode，整个界面以递归的方式展示。</li>
<li>右侧是不包含子zNode的zNode，所以直接展示zNode名称和存储的数据。</li>
</ul>
<p>从上图可以看到，左侧有名为<code>brokers</code>的zNode，点击进去后显示他的两个zNode，<code>ids</code>和<code>topics</code>：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576454552.png" alt=""></p>
<p>再点进<code>ids</code>可以看到，它还有三个子zNode，分别是Kafka集群中的三个Broker的信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576497231.png" alt=""></p>
<p>如果进入<code>topics</code>，可以看到它下面的子zNode都是我们之前创建的Topic，再进入每个Topic会看到Partition的zNode。充分展示了Zookeeper管理Kafka的方式。</p>
<p>ZKUI可以让我们方便直观的管理Zookeeper中的zNode，大大提高我们的工作效率。</p>
<h3 id="Kafka_Manager"><a href="#Kafka_Manager" class="headerlink" title="Kafka Manager"></a>Kafka Manager</h3><p>Kafka Manager是一款强大的Kafka集群监控工具。首先做一些准备工作：</p>
<ul>
<li>从<a href="https://github.com/yahoo/kafka-manager/releases" target="_blank" rel="external">Github</a>上下载<a href="https://github.com/yahoo/kafka-manager/releases" target="_blank" rel="external"> kafka-manager-1.3.3.22 </a>。</li>
<li><p>为了之后编译速度能快一些，先配置一下sbt的Maven仓库，连接到阿里云ECS，进入root用户目录，使用<code>mkdir .sbt</code>创建<code>.sbt</code>目录，进入该目录，使用<code>vim repositories</code>创建<code>repositories</code>文件，然后编辑如下内容：</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[repositories]&#10;local&#10;aliyun: http://maven.aliyun.com/nexus/content/groups/public&#10;typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly</span><br></pre></td></tr></table></figure>
</li>
<li><p>将<code>kafka-manager-1.3.3.22.zip</code>上传至ECS，解压后进入<code>kafka-manager</code>目录，执行如下命令：</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./sbt clean dist</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>需要等待一会，执行成功后，在<code>target/universal</code>目录下会产生一个<code>kafka-manager-1.3.3.7.zip</code>压缩文件，将其拷贝到要部署Kafka Manager的目录下，执行如下命令启动：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin/kafka-manager &#38;</span><br></pre></td></tr></table></figure></p>
<p>成功后，访问<code>http://ECS外网IP:9000</code>，即可看到Kafka Manager的界面了。如果有需要可以自行在<code>conf</code>目录下的<code>application.conf</code>文件中进行配置，比如端口号、Zookeeper的地址等。</p>
<blockquote>
<p>注意：Kafka Manager需要JDK8以上的环境。</p>
</blockquote>
<p>访问后，我们看到的是Kafka集群的列表列表，首先通过顶部的Add Cluster在Kafka Manager中创建Kafka集群：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576541891.png" alt=""><br>这里需要注意的有六项：</p>
<ul>
<li><code>My_Kafka_Cluster</code>：Kafka集群名称，这里随意输入。</li>
<li><code>Cluster Zookeeper Hosts</code>：Zookeeper Server的地址，如果是集群，则地址以逗号分割。</li>
<li><code>Kafka Version</code>：Kafka版本选择2.0.0。</li>
<li><code>brokerViewThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
<li><code>offsetCacheThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
<li><code>kafkaAdminClientThreadPoolSize</code>：这是Kafka Manager需要的配置项，最小为2。</li>
</ul>
<p>然后点击<strong>Save</strong>，Kafka Manager中的Kafka集群就创建好了。然后在Kafka Cluster列表页就能看到我们创建的集群了：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576561520.png" alt=""></p>
<p>点击进入后可以看到集群的基本信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576584316.png" alt=""><br>从上图可以看到，我们的Kafka集群中一共有6个Topic，3个Broker。点击进入Broker列表，可以看到Broker的基本信息：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576602212.png" alt=""></p>
<p>点击Broker ID可以进入Broker详细信息页面：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576624326.png" alt=""><br>可以看到这个Broker中都有哪些Topic，他们的Partition、ISR、Leader等信息。</p>
<p>我们再来看看Topic列表：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576651485.png" alt=""></p>
<p>从上图可以看到在列表中有一列是<strong>Brokers Spread %</strong>，只有2个Topic达到了100%，其他的都是33%，这是因为<code>my_topic_in_cluster</code>和<code>another_topic_in_cluster</code>这两个Topic是在Kafka集群中创建的，所以它们的Partitions和Replicas被均匀的分配到了三个Broker中。而其他的Topic都是在单机Kafka时创建的，所以他们的Partitions和Replicas都在一个Broker里。可见Kafka并不能自动改变之前已存在的Topic Partitions的分布情况。</p>
<p>我们点击进入之前创建的<code>my_topic_in_cluster</code>Topic看一下它的详情：<br><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576670922.png" alt=""><br>从上图可以看到，从Kafka Manager中可以很清晰的看到Topic Partitions、ISR、Leader在Kafka集群中的分布情况。同时，也提供了对Topic的各种快捷操作，非常方便。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践搭建Zookeeper和Kafka的UI管理工具，通过可视化的视图以及方便的快捷操作能有效的监控Zookeeper和Kafka的状态以及大大提高生产效率。下一章节会对Kafka的重要配置和性能做一些探讨。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节主要介绍Zookeeper和Kafka的UI管理工具。</p>
<h3 id="ZKUI"><a href="#ZKUI" class="headerlink" title="ZKUI"></a>ZKUI</h3><p>ZKUI是一款简洁易用的Zookeeper信息管理工具。首先从<a href="https://github.com/DeemOpen/zkui">Github</a>上克隆工程到本地，这是一个Maven工程，然后<code>mvn clean install</code>，在<code>target</code>目录下打出两个jar包<code>zkui-2.0-SNAPSHOT.jar</code>和<code>zkui-2.0-SNAPSHOT-jar-with-dependencies.jar</code>，将其上传至你的阿里云ECS。因为我们Zookeeper是集群模式，所以首先需要修改<code>config.cfg</code>中的Zookeeper地址：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#Comma seperated list of all the zookeeper servers&#10;zkServer=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181</span><br></pre></td></tr></table></figure></p>
<p>然后运行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &#38;</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：启动Kafka集群]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-17/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-17/</id>
    <published>2019-03-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节来真正启动Kafka集群，先给出一份Broker的配置项列表，将以下信息复制三份，分别配置三台阿里云ECS上的Broker配置文件：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;listener.security.protocol.map=EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT&#10;inter.broker.listener.name=INTERNAL&#10;advertised.listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;num.network.threads=3&#10;num.io.threads=8&#10;socket.send.buffer.bytes=102400&#10;socket.receive.buffer.bytes=102400&#10;socket.request.max.bytes=104857600&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;offsets.topic.replication.factor=2&#10;transaction.state.log.replication.factor=1&#10;transaction.state.log.min.isr=1&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>以上列表有两点需要修改的地方：</p>
<ul>
<li><code>broker.id</code>需要修改，不同Broker的ID不能相同。</li>
<li>阿里云ECS的内/外网IP需要配置正确。</li>
</ul>
<p>然后使用如下命令分别启动Kafka Broker：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka_2.12-2.0.0/bin/kafka-server-start.sh kafka_2.12-2.0.0/config/server.properties &#38;</span><br></pre></td></tr></table></figure></p>
<p>三个Broker没有异常信息，大概率说明我们的Kafka集群部署成功了，下面来验证一下。首先我们创建一个Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka_2.12-2.0.0/bin sh kafka-topics.sh --zookeeper zookeeper.server.1:2181 --topic my_topic_in_cluster --create --partitions 3 --replication-factor 2</span><br></pre></td></tr></table></figure></p>
<p>上面的命令有这样几个信息：</p>
<ul>
<li>连接Zookeeper时，连Zookeeper集群中的任意一个Zookeeper即可。</li>
<li>创建的Topic<code>my_topic_in_cluster</code>有三个Partition，每个Partition有两个Replica，也就是每条发送到这个Topic的Message会保存六份。</li>
</ul>
<p>如果Kafka集群是成功的，那么理论上这六个Partition会被两两均匀分配到三个Broker中。</p>
<p>连接到部署Broker-0的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;__consumer_offsets-0   __consumer_offsets-3   __consumer_offsets-6&#10;__consumer_offsets-1   __consumer_offsets-30  __consumer_offsets-7&#10;__consumer_offsets-10  __consumer_offsets-31  __consumer_offsets-8&#10;__consumer_offsets-11  __consumer_offsets-32  __consumer_offsets-9&#10;__consumer_offsets-12  __consumer_offsets-33  &#10;__consumer_offsets-13  __consumer_offsets-34  &#10;__consumer_offsets-14  __consumer_offsets-35  &#10;__consumer_offsets-15  __consumer_offsets-36  cleaner-offset-checkpoint&#10;__consumer_offsets-16  __consumer_offsets-37  configured-topic-0&#10;__consumer_offsets-17  __consumer_offsets-38  configured-topic-1&#10;__consumer_offsets-18  __consumer_offsets-39  configured-topic-2&#10;__consumer_offsets-19  __consumer_offsets-4   first_topic-0&#10;__consumer_offsets-2   __consumer_offsets-40  first_topic-1&#10;__consumer_offsets-20  __consumer_offsets-41  first_topic-2&#10;__consumer_offsets-21  __consumer_offsets-42  log-start-offset-checkpoint&#10;__consumer_offsets-22  __consumer_offsets-43  meta.properties&#10;__consumer_offsets-23  __consumer_offsets-44  my_topic_in_cluster-0&#10;__consumer_offsets-24  __consumer_offsets-45  my_topic_in_cluster-2&#10;__consumer_offsets-25  __consumer_offsets-46  recovery-point-offset-checkpoint&#10;__consumer_offsets-26  __consumer_offsets-47  replication-offset-checkpoint&#10;__consumer_offsets-27  __consumer_offsets-48  with_keys_topic-0&#10;__consumer_offsets-28  __consumer_offsets-49  with_keys_topic-1&#10;__consumer_offsets-29  __consumer_offsets-5   with_keys_topic-2</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-0中分配了<code>my_topic_in_cluster</code>的Partition-0和Partition-2。</p>
<p>同理，连接到部署Broker-1的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;meta.properties   my_topic_in_cluster-0&#10;my_topic_in_cluster-1   cleaner-offset-checkpoint    &#10;recovery-point-offset-checkpoint  log-start-offset-checkpoint &#10;replication-offset-checkpoint</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-1中分配了<code>my_topic_in_cluster</code>的Partition-0和Partition-1。</p>
<p>同理，连接到部署Broker-2的阿里云ECS，进入Kafka的data目录：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /kafka_2.12-2.0.0/data/kafka&#10;/kafka_2.12-2.0.0/data/kafka# ls&#10;&#10;meta.properties   my_topic_in_cluster-1&#10;my_topic_in_cluster-2   cleaner-offset-checkpoint    &#10;recovery-point-offset-checkpoint  log-start-offset-checkpoint &#10;replication-offset-checkpoint</span><br></pre></td></tr></table></figure></p>
<p>可以看到Broker-2中分配了<code>my_topic_in_cluster</code>的Partition-1和Partition-2。</p>
<p>从上面的结果可以说明我们的Kafka集群是部署成功的。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践运行Kafka集群，通过查看每个Broker的Data目录印证之前章节对Partition介绍的内容。下一章节会带大家搭建管理Zookeeper和Kafka的UI工具。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节来真正启动Kafka集群，先给出一份Broker的配置项列表，将以下信息复制三份，分别配置三台阿里云ECS上的Broker配置文件：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;listener.security.protocol.map=EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT&#10;inter.broker.listener.name=INTERNAL&#10;advertised.listeners=EXTERNAL://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093&#10;num.network.threads=3&#10;num.io.threads=8&#10;socket.send.buffer.bytes=102400&#10;socket.receive.buffer.bytes=102400&#10;socket.request.max.bytes=104857600&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;offsets.topic.replication.factor=2&#10;transaction.state.log.replication.factor=1&#10;transaction.state.log.min.isr=1&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：Kafka Listeners]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-16/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-16/</id>
    <published>2019-02-28T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节主要对和Listener相关的四个配置项做以详细解释。<code>listeners</code>、<code>advertised.listeners</code>、<code>listener.security.protocol.map</code>、<code>inter.broker.listener.name</code>这四个配置项可能是大家最容易混淆和最不容易理解的。</p>
<p>在解释这些配置项之前，我们先来明确几个概念。</p>
<ul>
<li>部署Broker的阿里云ECS称为Host Machine。</li>
<li>在阿里云ECS里启动的Producer或者Consumer，比如使用Kafka CLI启动的称为Internal Client。</li>
<li>在大家的IDEA中使用Java编写的，或者第三方的Producer/Consumer，称为External Client。</li>
<li>Host Machine具有外网IP和内网IP。</li>
<li>Internal Client可以同时和Host Machine的外网IP及内网IP通信。</li>
<li>External Client只能和Host Machine的外网IP通信。</li>
<li>多个阿里云ECS之间可以同时通过外网IP及内网IP通信。<ul>
<li>既在这个特定的场景下，Host Machine之间可以同时通过外网IP及内网IP通信。</li>
<li>再换句话说就是不同Host Machine上的Broker之间可以同时通过外网IP及内网IP通信。</li>
</ul>
</li>
</ul>
<a id="more"></a>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576212167.png" alt=""></p>
<p>如上图所示，是一个很常见的Kafka集群场景，涵盖了上述的概念。图中那些通信虚线箭头就是靠Kafka的Listener建立的，并且是通过Kafka中不同的Listener建立的，这些Listener分为Internal Listener和External Listener。如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555576272952.png" alt=""></p>
<p>那么这些Listener的创建以及内外部如何通信都是由上面那四个配置项决定的。</p>
<h3 id="listener-security-protocol-map"><a href="#listener-security-protocol-map" class="headerlink" title="listener.security.protocol.map"></a>listener.security.protocol.map</h3><p>先来看<code>listener.security.protocol.map</code>配置项，在上一章节中介绍过，它是配置监听者的安全协议的，比如<code>PLAINTEXT</code>、<code>SSL</code>、<code>SASL_PLAINTEXT</code>、<code>SASL_SSL</code>。因为它是以Key/Value的形式配置的，所以往往我们也使用该参数给Listener命名：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">listener.security.protocol.map=EXTERNAL_LISTENER_CLIENTS:SSL,INTERNAL_LISTENER_CLIENTS:PLAINTEXT,INTERNAL_LISTENER_BROKER:PLAINTEXT</span><br></pre></td></tr></table></figure></p>
<p>使用Key作为Listener的名称。就如上图所示，Internal Producer、External Producer、Internal Consumer、External Consumer和Broker通信以及Broker之间互相通信时都很有可能使用不同的Listener。这些不同的Listener有监听内网IP的，有监听外网IP的，还有不同安全协议的，所以使用Key来表示更加直观。当然这只是一种非官方的用法，Key本质上还是代表了安全协议，如果只有一个安全协议，多个Listener的话，那么这些Listener所谓的名称肯定都是相同的。</p>
<h3 id="listeners"><a href="#listeners" class="headerlink" title="listeners"></a>listeners</h3><p><code>listeners</code>就是主要用来定义Kafka Broker的Listener的配置项。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">listeners=EXTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092,INTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9093,INTERNAL_LISTENER_BROKER://&#38463;&#37324;&#20113;ECS&#20869;&#32593;IP:9094</span><br></pre></td></tr></table></figure></p>
<p>上面的配置表示，这个Broker定义了三个Listener，一个External Listener，用于External Producer和External Consumer连接使用。也许因为业务场景的关系，Internal Producer和Broker之间使用不同的安全协议进行连接，所以定义了两个不同协议的Internal Listener，分别用于Internal Producer和Broker之间连接使用。</p>
<p>通过之前的章节，我们知道Kafka是由Zookeeper进行管理的，由Zookeeper负责Leader选举，Broker Rebalance等工作。所以External Producer和External Consumer其实是通过Zookeeper中提供的信息和Broker通信交互的。所以<code>listeners</code>中配置的信息都会发布到Zookeeper中，但是这样就会把Broker的所有Listener信息都暴露给了外部Clients，在安全上是存在隐患的，我们希望只把给外部Clients使用的Listener暴露出去，此时就需要用到下面这个配置项了。</p>
<h3 id="advertised-listeners"><a href="#advertised-listeners" class="headerlink" title="advertised.listeners"></a>advertised.listeners</h3><p><code>advertised.listeners</code>参数的作用就是将Broker的Listener信息发布到Zookeeper中，供Clients（Producer/Consumer）使用。如果配置了<code>advertised.listeners</code>，那么就不会将<code>listeners</code>配置的信息发布到Zookeeper中去了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">advertised.listeners=EXTERNAL_LISTENER_CLIENTS://&#38463;&#37324;&#20113;ECS&#22806;&#32593;IP:9092</span><br></pre></td></tr></table></figure></p>
<p>这里在Zookeeper中发布了供External Clients（Producer/Consumer）使用的Listener<code>EXTERNAL_LISTENER_CLIENTS</code>。所以<code>advertised.listeners</code>配置项实现了只把给外部Clients使用的Listener暴露出去的需求。</p>
<h3 id="inter-broker-listener-name"><a href="#inter-broker-listener-name" class="headerlink" title="inter.broker.listener.name"></a>inter.broker.listener.name</h3><p>这个配置项从名称就可以看出它的作用了，就是指定一个<code>listener.security.protocol.map</code>配置项中配置的Key，或者说指定一个或一类Listener的名称，将它作为Internal Listener。这个Listener<strong>专门用于Kafka集群中Broker之间的通信</strong>：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">inter.broker.listener.name=INTERNAL_LISTENER_BROKER</span><br></pre></td></tr></table></figure></p>
<h3 id="listener__u548C_advertised-listeners__u7684_u5173_u7CFB"><a href="#listener__u548C_advertised-listeners__u7684_u5173_u7CFB" class="headerlink" title="listener 和 advertised.listeners 的关系"></a>listener 和 advertised.listeners 的关系</h3><p>先来看看<code>KafkaConfig.scala</code>和<code>SocketServer.scala</code>源码中的这几行代码片段：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// KafkaConfig.scala</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> <span class="type">ListenersProp</span> = <span class="string">"listeners"</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dataPlaneListeners</span>:</span> <span class="type">Seq</span>[<span class="type">EndPoint</span>] = &#123;</span><br><span class="line">    <span class="type">Option</span>(getString(<span class="type">KafkaConfig</span>.<span class="type">ControlPlaneListenerNameProp</span>)) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(controlPlaneListenerName) =&gt; listeners.filterNot(_.listenerName.value() == controlPlaneListenerName)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; listeners</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">listeners</span>:</span> <span class="type">Seq</span>[<span class="type">EndPoint</span>] = &#123;</span><br><span class="line">    <span class="type">Option</span>(getString(<span class="type">KafkaConfig</span>.<span class="type">ListenersProp</span>)).map &#123; listenerProp =&gt;</span><br><span class="line">      <span class="type">CoreUtils</span>.listenerListToEndPoints(listenerProp, listenerSecurityProtocolMap)</span><br><span class="line">    &#125;.getOrElse(<span class="type">CoreUtils</span>.listenerListToEndPoints(<span class="string">"PLAINTEXT://"</span> + hostName + <span class="string">":"</span> + port, listenerSecurityProtocolMap))</span><br><span class="line">  &#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment">// SocketServer.scala</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">startup</span>(</span>startupProcessors: <span class="type">Boolean</span> = <span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">      connectionQuotas = <span class="keyword">new</span> <span class="type">ConnectionQuotas</span>(config.maxConnectionsPerIp, config.maxConnectionsPerIpOverrides)</span><br><span class="line">      createControlPlaneAcceptorAndProcessor(config.controlPlaneListener)</span><br><span class="line">      createDataPlaneAcceptorsAndProcessors(config.numNetworkThreads, config.dataPlaneListeners)</span><br><span class="line">      <span class="keyword">if</span> (startupProcessors) &#123;</span><br><span class="line">        startControlPlaneProcessor()</span><br><span class="line">        startDataPlaneProcessors()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createDataPlaneAcceptorsAndProcessors</span>(</span>dataProcessorsPerListener: <span class="type">Int</span>,</span><br><span class="line">                                                    endpoints: <span class="type">Seq</span>[<span class="type">EndPoint</span>]): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">    endpoints.foreach &#123; endpoint =&gt;</span><br><span class="line">      <span class="keyword">val</span> dataPlaneAcceptor = createAcceptor(endpoint)</span><br><span class="line">      addDataPlaneProcessors(dataPlaneAcceptor, endpoint, dataProcessorsPerListener)</span><br><span class="line">      <span class="type">KafkaThread</span>.nonDaemon(s<span class="string">"data-plane-kafka-socket-acceptor-$&#123;endpoint.listenerName&#125;-$&#123;endpoint.securityProtocol&#125;-$&#123;endpoint.port&#125;"</span>, dataPlaneAcceptor).start()</span><br><span class="line">      dataPlaneAcceptor.awaitStartup()</span><br><span class="line">      dataPlaneAcceptors.put(endpoint, dataPlaneAcceptor)</span><br><span class="line">      info(s<span class="string">"Created data-plane acceptor and processors for endpoint : $endpoint"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p><code>startup()</code>方法是Kafka Broker创建启动Socket连接的入口，既用来创建Acceptor线程的入口，该线程负责处理Socket连接。 <code>createDataPlaneAcceptorsAndProcessors()</code>方法的第二个参数<code>config.dataPlaneListeners</code>可以看到取的就是<code>listeners</code>配置项的内容。 </p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line">* Create a server socket to listen for connections on.</span><br><span class="line">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">openServerSocket</span>(</span>host: <span class="type">String</span>, port: <span class="type">Int</span>): <span class="type">ServerSocketChannel</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> socketAddress =</span><br><span class="line">    <span class="keyword">if</span> (host == <span class="literal">null</span> || host.trim.isEmpty)</span><br><span class="line">      <span class="keyword">new</span> <span class="type">InetSocketAddress</span>(port)</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="keyword">new</span> <span class="type">InetSocketAddress</span>(host, port)</span><br><span class="line">  <span class="keyword">val</span> serverChannel = <span class="type">ServerSocketChannel</span>.open()</span><br><span class="line">  serverChannel.configureBlocking(<span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">if</span> (recvBufferSize != <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>)</span><br><span class="line">    serverChannel.socket().setReceiveBufferSize(recvBufferSize)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    serverChannel.socket.bind(socketAddress)</span><br><span class="line">    info(<span class="string">"Awaiting socket connections on %s:%d."</span>.format(socketAddress.getHostString, serverChannel.socket.getLocalPort))</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">SocketException</span> =&gt;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Socket server failed to bind to %s:%d: %s."</span>.format(socketAddress.getHostString, port, e.getMessage), e)</span><br><span class="line">  &#125;</span><br><span class="line">  serverChannel</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>跟到里面，可以看到如果没有配置<code>listeners</code>，那么会使用网卡地址创建Socket连接，对于阿里云ECS，就是内网IP。</p>
<p>再来看看<code>KafkaServer.scala</code>源码中的这几行代码片段：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> brokerInfo = createBrokerInfo</span><br><span class="line"><span class="keyword">val</span> brokerEpoch = zkClient.registerBroker(brokerInfo)</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[server] <span class="function"><span class="keyword">def</span> <span class="title">createBrokerInfo</span>:</span> <span class="type">BrokerInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> endPoints = config.advertisedListeners.map(e =&gt; s<span class="string">"$&#123;e.host&#125;:$&#123;e.port&#125;"</span>)</span><br><span class="line">    zkClient.getAllBrokersInCluster.filter(_.id != config.brokerId).foreach &#123; broker =&gt;</span><br><span class="line">      <span class="keyword">val</span> commonEndPoints = broker.endPoints.map(e =&gt; s<span class="string">"$&#123;e.host&#125;:$&#123;e.port&#125;"</span>).intersect(endPoints)</span><br><span class="line">      require(commonEndPoints.isEmpty, s<span class="string">"Configured end points $&#123;commonEndPoints.mkString("</span>,<span class="string">")&#125; in"</span> +</span><br><span class="line">        s<span class="string">" advertised listeners are already registered by broker $&#123;broker.id&#125;"</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> listeners = config.advertisedListeners.map &#123; endpoint =&gt;</span><br><span class="line">      <span class="keyword">if</span> (endpoint.port == <span class="number">0</span>)</span><br><span class="line">        endpoint.copy(port = socketServer.boundPort(endpoint.listenerName))</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        endpoint</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> updatedEndpoints = listeners.map(endpoint =&gt;</span><br><span class="line">      <span class="keyword">if</span> (endpoint.host == <span class="literal">null</span> || endpoint.host.trim.isEmpty)</span><br><span class="line">        endpoint.copy(host = <span class="type">InetAddress</span>.getLocalHost.getCanonicalHostName)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        endpoint</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> jmxPort = <span class="type">System</span>.getProperty(<span class="string">"com.sun.management.jmxremote.port"</span>, <span class="string">"-1"</span>).toInt</span><br><span class="line">    <span class="type">BrokerInfo</span>(<span class="type">Broker</span>(config.brokerId, updatedEndpoints, config.rack), config.interBrokerProtocolVersion, jmxPort)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>从上面的代码可以看到，<code>advertised.listeners</code>主要用于向Zookeeper注册Broker的连接信息，但是不参与创建Socket连接。</p>
<p>所以从这几处源码内容可以得出结论，Kafka Broker真正建立通信连接使用的是<code>listeners</code>配置项里的内容，而<code>advertised.listeners</code>只用于向Zookeeper注册Broker的连接信息，既向Client暴露Broker对外的连接信息（Endpoint）。</p>
<p>另外在<code>KafkaConfig.scala</code>源码中还有有这么几行代码：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> advertisedListenerNames = advertisedListeners.map(_.listenerName).toSet</span><br><span class="line"><span class="keyword">val</span> listenerNames = listeners.map(_.listenerName).toSet</span><br><span class="line"></span><br><span class="line">require(advertisedListenerNames.contains(interBrokerListenerName),</span><br><span class="line">      s<span class="string">"$&#123;KafkaConfig.InterBrokerListenerNameProp&#125; must be a listener name defined in $&#123;KafkaConfig.AdvertisedListenersProp&#125;. "</span> +</span><br><span class="line">      s<span class="string">"The valid options based on currently configured listeners are $&#123;advertisedListenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;"</span>)</span><br><span class="line">require(advertisedListenerNames.subsetOf(listenerNames),</span><br><span class="line">      s<span class="string">"$&#123;KafkaConfig.AdvertisedListenersProp&#125; listener names must be equal to or a subset of the ones defined in $&#123;KafkaConfig.ListenersProp&#125;. "</span> +</span><br><span class="line">      s<span class="string">"Found $&#123;advertisedListenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;. The valid options based on the current configuration "</span> +</span><br><span class="line">      s<span class="string">"are $&#123;listenerNames.map(_.value).mkString("</span>,<span class="string">")&#125;"</span></span><br></pre></td></tr></table></figure></p>
<p>从上面的代码片段可以得出两个结论：</p>
<ul>
<li><code>advertised.listeners</code>配置项中配置的Listener名称或者说安全协议必须在<code>listeners</code>中存在。因为真正创建连接的是<code>listeners</code>中的信息。</li>
<li><code>inter.broker.listener.name</code>配置项中配置的Listener名称或者说安全协议必须在<code>advertised.listeners</code>中存在。因为Broker之间也是要通过<code>advertised.listeners</code>配置项获取Internal Listener信息的。</li>
</ul>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节主要大家详细解释了Broker几个比较容易混淆和不好理解的配置项，解释了什么是内外部Listener，如何暴露Listener等。这些配置在我们搭建Kafka集群时至关重要。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一章节主要对和Listener相关的四个配置项做以详细解释。<code>listeners</code>、<code>advertised.listeners</code>、<code>listener.security.protocol.map</code>、<code>inter.broker.listener.name</code>这四个配置项可能是大家最容易混淆和最不容易理解的。</p>
<p>在解释这些配置项之前，我们先来明确几个概念。</p>
<ul>
<li>部署Broker的阿里云ECS称为Host Machine。</li>
<li>在阿里云ECS里启动的Producer或者Consumer，比如使用Kafka CLI启动的称为Internal Client。</li>
<li>在大家的IDEA中使用Java编写的，或者第三方的Producer/Consumer，称为External Client。</li>
<li>Host Machine具有外网IP和内网IP。</li>
<li>Internal Client可以同时和Host Machine的外网IP及内网IP通信。</li>
<li>External Client只能和Host Machine的外网IP通信。</li>
<li>多个阿里云ECS之间可以同时通过外网IP及内网IP通信。<ul>
<li>既在这个特定的场景下，Host Machine之间可以同时通过外网IP及内网IP通信。</li>
<li>再换句话说就是不同Host Machine上的Broker之间可以同时通过外网IP及内网IP通信。</li>
</ul>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka集群：配置Broker]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-15/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-15/</id>
    <published>2019-02-19T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.009Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>接下来几个章节我们开始搭建真正的Kafka集群，服务器还是使用上一节章节搭建Zookeeper使用的三台阿里云ECS。</p>
<p>在<strong>搭建单机Kafka</strong>章节中，在Kafka的<code>/root/kafka_2.12-2.0.0/config/server.properties</code>配置文件中，我们只配置了<code>log.dirs</code>和<code>advertised.listeners</code>这两个配置项，其他配置项都是使用默认值。</p>
<p>Kafka的配置项一共多达140余个，虽然有一部分通常情况下我们不需要修改，使用默认值即可，<strong>但这只是一少部分</strong>。搭建Kafka集群时，光通常情况下需要考虑的配置项就有40余个。</p>
<p>另外，这些配置项要根据具体的业务场景做各种调整，不存在一套配置项通吃所有业务场景的情况，而且基本不可能一次性配置出性能最优、最能满足业务场景的配置项组合，都需要经过调整、测试，反复进行配置才能总结出相对最优的配置项组合。</p>
<a id="more"></a>
<h2 id="Broker_u914D_u7F6E"><a href="#Broker_u914D_u7F6E" class="headerlink" title="Broker配置"></a>Broker配置</h2><p>先展示一份Broker的配置内容（<code>/root/kafka_2.12-2.0.0/config/server.properties</code>），这里给出的是一个平铺的配置项列表，有一些配置项已经作废，有一些配置项之间有会有相互影响：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">############################# Server Basics #############################&#10;broker.id=0&#10;# DEPRECATED&#10;host.name=&#38463;&#37324;&#20113;ECS IP&#10;# DEPRECATED&#10;port=9092&#10;delete.topic.enable=true&#10;auto.create.topics.enable=true&#10;&#10;############################# Socket Server Settings #############################&#10;listeners=PLAINTEXT://&#38463;&#37324;&#20113;ECS IP:9092&#10;listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL&#10;advertised.listeners=PLAINTEXT://&#38463;&#37324;&#20113;ECS IP:9092&#10;inter.broker.listener.name=PLAINTEXT&#10;num.network.threads=3&#10;num.io.threads=8&#10;&#10;############################# Log Basics #############################&#10;log.dirs=/root/kafka_2.12-2.0.0/data/kafka&#10;num.partitions=1&#10;num.recovery.threads.per.data.dir=1&#10;default.replication.factor=3&#10;min.insync.replicas=2&#10;&#10;############################# Log Retention Policy #############################&#10;log.retention.hours=168&#10;log.segment.bytes=1073741824&#10;log.retention.check.interval.ms=300000&#10;log.segment.ms=604800000&#10;&#10;############################# Zookeeper #############################&#10;zookeeper.connect=zookeeper.server.1:2181,zookeeper.server.2:2181,zookeeper.server.3:2181&#10;zookeeper.connection.timeout.ms=6000&#10;&#10;############################# Group Coordinator Settings #############################&#10;group.initial.rebalance.delay.ms=0&#10;&#10;############################# Message #############################&#10;message.max.bytes=1048576&#10;fetch.message.max.bytes=1048576</span><br></pre></td></tr></table></figure></p>
<p>我们逐一了解上面这些配置项：</p>
<h3 id="Broker_Server_u57FA_u7840_u914D_u7F6E"><a href="#Broker_Server_u57FA_u7840_u914D_u7F6E" class="headerlink" title="Broker Server基础配置"></a>Broker Server基础配置</h3><p>Broker Server的基础配置涉及到四个配置项：</p>
<ul>
<li><code>broker.id</code>：整个Kafka集群内标识唯一Broker的ID。整数类型。</li>
<li><code>host.name</code>：部署Broker的服务器IP地址或者域名。该参数已作废。</li>
<li><code>port</code>：Broker开放的端口号。该参数已作废。</li>
<li><code>delete.topic.enable</code>：是否允许删除Topic。</li>
<li><code>auto.create.topics.enable</code>：是否允许在Producer在未指定Topic发送Message时自动创建Topic。</li>
</ul>
<h3 id="Socket_Server_u914D_u7F6E"><a href="#Socket_Server_u914D_u7F6E" class="headerlink" title="Socket Server配置"></a>Socket Server配置</h3><p>传输通信方面的配置涉及到六个配置项：</p>
<ul>
<li><code>listeners</code>：Broker之间，Client与Broker之间通信建立连接时使用的信息。既Broker的监听者，可以以逗号分割配置多个。它的格式为<code>[安全协议]://Hostname/IP:Port</code>。</li>
<li><p><code>listener.security.protocol.map</code>：以Key/Value的形式定义监听者的安全协议，在大多数情况下会将Key认为是监听者的别名。所以会这样设置：</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">listeners=LISTENER_BOB://阿里云ECS IP1:<span class="number">9092</span>,LISTENER_JOHN://阿里云ECS IP2:<span class="number">9092</span></span><br><span class="line">listener.security.protocol.map=LISTENER_BOB:PLAINTEXT,LISTENER_JOHN:SSL</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>advertised.listeners</code>：将Broker建立通信的地址发布到Zookeeper中，便于Client（Producer和Consumer）连接。它的格式和<code>listener</code>一致。</p>
</li>
<li><code>inter.broker.listener.name</code>：设置内部通信时使用哪个监听者。可以直接设置<code>listener.security.protocol.map</code>中设置的Key。</li>
<li><code>num.network.threads</code>：Broker Server接收请求及发送响应时启用的线程数量。</li>
<li><code>num.io.threads</code>：Broker Server处理请求、对Message进行I/O操作时启用的线程数。</li>
</ul>
<p>和监听者相关的四个配置项，在下一章节会做详细解释。</p>
<h3 id="u65E5_u5FD7_u57FA_u7840_u914D_u7F6E"><a href="#u65E5_u5FD7_u57FA_u7840_u914D_u7F6E" class="headerlink" title="日志基础配置"></a>日志基础配置</h3><p>Broker Server处理日志的基础配置涉及到五个配置项：</p>
<ul>
<li><code>log.dirs</code>：日志、Message保存的路径。</li>
<li><code>num.partitions</code>：创建Topic时，如果没有指定Partition数量，则使用该配置项设置的Partition数量。</li>
<li><code>num.recovery.threads.per.data.dir</code>：每个数据目录启用几个线程来处理，这里的线程数和数据目录数是乘积关系，并且只在Broker启动或关闭时使用。</li>
<li><code>default.replication.factor</code>：创建Topic时，如果没有指定Partition的Replication Factor数，则使用该配置项设置的Replication Factor数。</li>
<li><code>min.insync.replicas</code>：当<code>acks=all</code>时，至少有多少个Replicas需要确认已持久化数据，包括Leader。</li>
</ul>
<h3 id="u65E5_u5FD7_u4FDD_u7559_u7B56_u7565_u914D_u7F6E"><a href="#u65E5_u5FD7_u4FDD_u7559_u7B56_u7565_u914D_u7F6E" class="headerlink" title="日志保留策略配置"></a>日志保留策略配置</h3><p>Broker Server处理日志保留问题的配置涉及到四个配置项：</p>
<ul>
<li><code>log.retention.hours</code>：Kafka保留Message的时间，默认是168小时，既7天。</li>
<li><code>log.segment.bytes</code>：每个Segment文件的大小，默认是1G。</li>
<li><code>log.retention.check.interval.ms</code>：检测Message是否可以被删除的时间间隔。</li>
<li><code>log.segment.ms</code>：Segment文件关闭的时间。</li>
</ul>
<h3 id="Zookeeper_u76F8_u5173_u914D_u7F6E"><a href="#Zookeeper_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Zookeeper相关配置"></a>Zookeeper相关配置</h3><p>Zookeeper的相关配置涉及到两个配置项：</p>
<ul>
<li><code>zookeeper.connect</code>：设置Zookeeper地址。可用逗号分割配置多个地址，既Zookeeper集群的地址。</li>
<li><code>zookeeper.connection.timeout.ms</code>：等待连接Zookeeper的超时时间。</li>
</ul>
<h3 id="Consumer_Group_u76F8_u5173_u914D_u7F6E"><a href="#Consumer_Group_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Consumer Group相关配置"></a>Consumer Group相关配置</h3><p>Consumer Group相关的配置主要涉及到一个配置项：</p>
<ul>
<li><code>group.initial.rebalance.delay.ms</code>：当Consumer Group新增或减少Consumer时，重新分配Topic Partition的延迟时间。</li>
</ul>
<h3 id="Message_u76F8_u5173_u914D_u7F6E"><a href="#Message_u76F8_u5173_u914D_u7F6E" class="headerlink" title="Message相关配置"></a>Message相关配置</h3><p>Message相关配置涉及到两个配置项：</p>
<ul>
<li><code>message.max.bytes</code>：Broker接收每条Message的最大值，默认是1M。</li>
<li><code>fetch.message.max.bytes</code>：Consumer每次获取Message的大小。</li>
</ul>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节给大家介绍了Broker的详细配置，为搭建Kafka集群做好充分准备。下一章节会对大家比较不容易理解的Listener配置做详细介绍。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>接下来几个章节我们开始搭建真正的Kafka集群，服务器还是使用上一节章节搭建Zookeeper使用的三台阿里云ECS。</p>
<p>在<strong>搭建单机Kafka</strong>章节中，在Kafka的<code>/root/kafka_2.12-2.0.0/config/server.properties</code>配置文件中，我们只配置了<code>log.dirs</code>和<code>advertised.listeners</code>这两个配置项，其他配置项都是使用默认值。</p>
<p>Kafka的配置项一共多达140余个，虽然有一部分通常情况下我们不需要修改，使用默认值即可，<strong>但这只是一少部分</strong>。搭建Kafka集群时，光通常情况下需要考虑的配置项就有40余个。</p>
<p>另外，这些配置项要根据具体的业务场景做各种调整，不存在一套配置项通吃所有业务场景的情况，而且基本不可能一次性配置出性能最优、最能满足业务场景的配置项组合，都需要经过调整、测试，反复进行配置才能总结出相对最优的配置项组合。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：搭建Zookeeper集群]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-14/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-14/</id>
    <published>2019-02-09T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.009Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来真正搭建一个Zookeeper集群。</p>
<h2 id="u642D_u5EFAZookeeper_u96C6_u7FA4"><a href="#u642D_u5EFAZookeeper_u96C6_u7FA4" class="headerlink" title="搭建Zookeeper集群"></a>搭建Zookeeper集群</h2><p>首先要做的就是再租赁两个服务器，参照<strong>搭建单机Kafka</strong>章节中的步骤，租赁阿里云服务器、安装JDK、下载配置Kafka、配置安全组规则。</p>
<h3 id="Zookeeper_u914D_u7F6E_u4FE1_u606F"><a href="#Zookeeper_u914D_u7F6E_u4FE1_u606F" class="headerlink" title="Zookeeper配置信息"></a>Zookeeper配置信息</h3><p>在<strong>搭建单机Kafka</strong>章节中，启动的是单机Zookeeper，所以<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件中只配置了<code>dataDir</code>，也就是存储各种数据、日志、快照的路径。</p>
<p>在搭建Zookeeper时，就需要额外再配置一些参数了。同样打开<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件，额外添加如下内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>逐一解释一下这些配置信息：</p>
<ul>
<li><code>maxClientCnxns</code>：该参数表示允许客户端最大连接数。如果设置为0则表示不做限制。</li>
<li><code>tickTime</code>：该参数表示Zookeeper服务之间进行心跳监测的间隔时间，单位是毫秒。设置为2000，表示每隔2秒，Zookeeper服务器之间会进行一次心跳监测。</li>
<li><code>initLimit</code>：该参数表示Zookeeper集群中的Follower在启动时需要在多少个心跳时间内从Leader同步数据。设置为10，表示要在10个心跳时间内，也就是在20秒内，要完成Leader数据的同步。</li>
<li><code>syncLimit</code>：该参数表示超过多少个心跳时间收不到Follower的响应，Leader就认为此Follower已经下线。设置为5，表示在5个心跳时间内，也就是判断Follower是否存活的响应时间是10秒。</li>
</ul>
<h3 id="Zookeeper_u96C6_u7FA4_u8282_u70B9_u5217_u8868"><a href="#Zookeeper_u96C6_u7FA4_u8282_u70B9_u5217_u8868" class="headerlink" title="Zookeeper集群节点列表"></a>Zookeeper集群节点列表</h3><p>首先节点列表的配置规则为<code>server.N=IP:Port1:Port2</code>：</p>
<ul>
<li><code>N</code>表示Zookeeper节点编号。</li>
<li><code>IP</code>表示Zookeeper节点的服务器IP，既阿里云ECS的外网IP。</li>
<li><code>Port1</code>表示该Zookeeper集群中的Follower节点与Leader节点通讯时使用的端口。作为Leader时监听该端口。</li>
<li><code>Port2</code>表示选举新的Leader时，Zookeeper节点之间互相通信的端口，比如当Leader挂掉时，其余服务器会互相通信，选出新的Leader。Leader和Follower都会监听该端口。</li>
</ul>
<p>这里的节点编号是数字类型，需要我们在<code>/root/kafka_2.12-2.0.0/data/zookeeper</code>目录下创建名为<code>myid</code>的文件，然后将编号配置在里面。<code>server.N</code>这里的<code>N</code>要和<code>myid</code>文件中配置的编号保持一致。</p>
<p>另外还需要注意的是，如果要在一台服务器上搭建伪集群，那么每个<code>Port1</code>和每个<code>Port2</code>要不一样才可以，因为<code>IP</code>都是一样的。这里我们是分别用三台不同的阿里云ECS，所以<code>IP</code>肯定是不一样的，而每个<code>Port1</code>是一致的，每个<code>Port2</code>也是一致的。</p>
<p>为了方便起见，我们可以在服务器的<code>/etc/hosts</code>文件中设置一下域名映射，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&#38463;&#37324;&#20113;ECS-1 IP] zookeeper.server.1&#10;[&#38463;&#37324;&#20113;ECS-2 IP] zookeeper.server.2&#10;[&#38463;&#37324;&#20113;ECS-3 IP] zookeeper.server.3</span><br></pre></td></tr></table></figure></p>
<p>这样在配置Zookeeper集群节点列表时就可以写成如下形式了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>
<h3 id="u963F_u91CC_u4E91ECS_u670D_u52A1_u76D1_u542C_u6240_u6709_u7F51_u5361"><a href="#u963F_u91CC_u4E91ECS_u670D_u52A1_u76D1_u542C_u6240_u6709_u7F51_u5361" class="headerlink" title="阿里云ECS服务监听所有网卡"></a>阿里云ECS服务监听所有网卡</h3><p>如果现在通过<code>/root/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh config/zookeeper.properties</code>启动Zookeeper，肯定会报一大堆错误，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[myid:0] - WARN  [WorkerSender[myid=0]:QuorumCnxManager@588] - Cannot open channel to 1 at election address /zookeeper.server.1:3888&#10;java.net.ConnectException: Connection refused&#10;&#160; &#160; &#160; &#160; at java.net.PlainSocketImpl.socketConnect(Native Method)&#10;&#160; &#160; &#160; &#160; at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)&#10;.......</span><br></pre></td></tr></table></figure></p>
<p>这是因为阿里云ECS都是采用虚拟化技术创建的服务器实例，而虚拟机中并没有物理网卡，所以Zookeeper服务启动后，进程并没有监听到<code>3888</code>端口，而是会随机生成一个端口进行监听。所以会报上面的错。解决的办法就是让Zookeeper服务进程监听<code>0.0.0.0</code>的IP地址，也就是监听所有网卡。那么就需要在<code>zookeeper.properties</code>配置文件加入<code>quorumListenOnAllIPs=true</code>配置信息，来保证Zookeeper服务进程能监听到我们设定的<code>3888</code>端口。</p>
<h3 id="Zookeeper_u96C6_u7FA4_u914D_u7F6E_u603B_u7ED3"><a href="#Zookeeper_u96C6_u7FA4_u914D_u7F6E_u603B_u7ED3" class="headerlink" title="Zookeeper集群配置总结"></a>Zookeeper集群配置总结</h3><p>在启动Zookeeper集群前，先来总结一下配置工作：</p>
<ul>
<li>租赁三台阿里云ECS，下载JDK、Kafka、配置安全组规则。</li>
<li>在<code>/root/kafka_2.12-2.0.0/data/zookeeper</code>目录下创建名为<code>myid</code>的文件，配置Zookeeper节点编号。</li>
<li>在服务器的<code>/etc/hosts</code>文件中设置一下域名映射：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&#38463;&#37324;&#20113;ECS-1 IP] zookeeper.server.1&#10;[&#38463;&#37324;&#20113;ECS-2 IP] zookeeper.server.2&#10;[&#38463;&#37324;&#20113;ECS-3 IP] zookeeper.server.3</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>在<code>/root/kafka_2.12-2.0.0/config/zookeeper.properties</code>配置文件中添加如下配置（<code>server.N</code>中的<code>N</code>要和<code>myid</code>中配置的节点编号保持一致）：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>在三台阿里云ECS中都完成上述工作后，就可以逐一启动Zookeeper了，命令如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh config/zookeeper.properties &#38;</span><br></pre></td></tr></table></figure></p>
<h2 id="u68C0_u9A8CZookeeper_u96C6_u7FA4"><a href="#u68C0_u9A8CZookeeper_u96C6_u7FA4" class="headerlink" title="检验Zookeeper集群"></a>检验Zookeeper集群</h2><p>三个Zookeeper节点都启动后，我们可以通过下面两个方法对Zookeeper集群进行基础的验证。</p>
<h3 id="u67E5_u770B_u7AEF_u53E3_u76D1_u542C_u72B6_u6001"><a href="#u67E5_u770B_u7AEF_u53E3_u76D1_u542C_u72B6_u6001" class="headerlink" title="查看端口监听状态"></a>查看端口监听状态</h3><p>我们可以使用<code>nc</code>命令看看端口都有没有被成功监听，选择任意一台服务器，通过下面的命令查看：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nc -vz zookeeper.server.1 2181&#10;Connection to zookeeper.server.1 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.1 3888&#10;Connection to zookeeper.server.1 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.1 2888&#10;nc: connect to zookeeper.server.1 port 2888 (tcp) failed: Connection refused&#10;&#10;nc -vz zookeeper.server.2 2181&#10;Connection to zookeeper.server.2 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.2 3888&#10;Connection to zookeeper.server.2 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.2 2888&#10;nc: connect to zookeeper.server.2 port 2888 (tcp) failed: Connection refused&#10;&#10;nc -vz zookeeper.server.3 2181&#10;Connection to zookeeper.server.3 2181 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.3 3888&#10;Connection to zookeeper.server.3 3888 port [tcp/*] succeeded!&#10;&#10;nc -vz zookeeper.server.3 2888&#10;Connection to zookeeper.server.3 2888 port [tcp/*] succeeded!</span><br></pre></td></tr></table></figure></p>
<p>从上面的信息中可以看出，三个Zookeeper都成功启动了，并且可以知道<code>zookeeper.server.1</code>和<code>zookeeper.server.2</code>是Follower，<code>zookeeper.server.3</code>是Leader，因为前两个节点并没有监听<code>2888</code>端口。</p>
<h3 id="u901A_u8FC7Zookeeper_CLI_u9A8C_u8BC1"><a href="#u901A_u8FC7Zookeeper_CLI_u9A8C_u8BC1" class="headerlink" title="通过Zookeeper CLI验证"></a>通过Zookeeper CLI验证</h3><p>我们还可以通过Zookeeper Client连接到集群来检验。我们选择任意一台服务器，首先连接<code>zookeeper.server.1</code>节点：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.1:2181</span><br></pre></td></tr></table></figure></p>
<p>连接成功后，我们创建一个zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_zNode &#34;some data&#34;&#10;Created /my_zNode</span><br></pre></td></tr></table></figure></p>
<p>查看<code>zookeeper.server.1</code>节点中所有的zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;[cluster, brokers, my_zNode, zookeeper, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>我们看到了刚才创建的<code>my_zNode</code>。然后退出连接，再连接<code>zookeeper.server.2</code>节点：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.2:2181</span><br></pre></td></tr></table></figure></p>
<p>然后查看<code>zookeeper.server.2</code>节点中的所有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;[cluster, controller_epoch, brokers, my_zNode, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>我们同样发现了<code>my_zNode</code>。查看<code>my_zNode</code>中的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /my_zNode&#10;some data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x500000009&#10;mtime = Wed Jan 09 15:38:39 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>看到是在<code>zookeeper.server.1</code>节点中创建时添加的<code>some data</code>数据。</p>
<p>同样我们再连接<code>zookeeper.server.3</code>节点查看zNode情况：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.3:2181&#10;&#10;ls /&#10;[cluster, controller_epoch, brokers, my_zNode, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]&#10;&#10;get /my_zNode&#10;some data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x500000009&#10;mtime = Wed Jan 09 15:38:39 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>我们在<code>zookeeper.server.3</code>节点中修改<code>my_zNode</code>中的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_zNode &#34;new data&#34;&#10;&#10;get /my_zNode&#10;new data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x50000000e&#10;mtime = Wed Jan 09 15:46:29 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>然后再连接<code>zookeeper.server.1</code>节点查看<code>my_zNode</code>的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-shell.sh zookeeper.server.1:2181&#10;&#10;get /my_zNode&#10;new data&#10;cZxid = 0x500000009&#10;ctime = Wed Jan 09 15:38:39 CST 2019&#10;mZxid = 0x50000000e&#10;mtime = Wed Jan 09 15:46:29 CST 2019&#10;pZxid = 0x500000009&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>看到<code>zookeeper.server.1</code>节点中<code>my_zNode</code>的数据也变成了<code>new data</code>。</p>
<p>上面的过程虽然比较繁琐，但是充分说明了我们的Zookeeper集群是搭建成功的。无论从哪个Zookeeper节点创建的zNode，都可以同步到集群中的其他节点。无论从哪个Zookeeper节点修改的zNode中的数据，也可以同步到起群中的其他节点。</p>
<h2 id="Zookeeper_The_Four_Letter_Words_Commands"><a href="#Zookeeper_The_Four_Letter_Words_Commands" class="headerlink" title="Zookeeper The Four Letter Words Commands"></a>Zookeeper The Four Letter Words Commands</h2><p>Zookeeper提供了一些能够查看节点Server状态、Client连接Server的状态、节点健康状态的命令。因为命令大多都是四个字母的简写，所以称为<a href="https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_zkCommands" target="_blank" rel="external">The Four Letter Words Commands</a>，我称为四字真言。</p>
<p>首先来看看整体的命令格式：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;xxxx&#34; | nc IP Port</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>xxxx</code>就是四字真言命令。</li>
<li><code>IP</code>是Zookeeper节点的IP。</li>
<li><code>Port</code>自然是Zookeeper监听的2181端口。</li>
</ul>
<p>下面来具体看看这些命令。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u914D_u7F6E"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u914D_u7F6E" class="headerlink" title="查看Zookeeper节点配置"></a>查看Zookeeper节点配置</h3><p>该命令可以查看指定节点的配置信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;conf&#34; | nc zookeeper.server.1 2181&#10;&#10;clientPort=2181&#10;dataDir=/root/kafka_2.12-2.0.0/data/zookeeper/version-2&#10;dataLogDir=/root/kafka_2.12-2.0.0/data/zookeeper/version-2&#10;tickTime=2000&#10;maxClientCnxns=0&#10;minSessionTimeout=4000&#10;maxSessionTimeout=40000&#10;serverId=1&#10;initLimit=10&#10;syncLimit=5&#10;electionAlg=3&#10;electionPort=3888&#10;quorumPort=2888&#10;peerType=0</span><br></pre></td></tr></table></figure></p>
<p>这个命令可以很方便的查看Zookeeper节点<code>zookeeper.properties</code>中的配置信息，以及默认的配置信息。</p>
<h3 id="u67E5_u770B_u8FDE_u63A5_u5230Zookeeper_u8282_u70B9_u7684Client_u4FE1_u606F"><a href="#u67E5_u770B_u8FDE_u63A5_u5230Zookeeper_u8282_u70B9_u7684Client_u4FE1_u606F" class="headerlink" title="查看连接到Zookeeper节点的Client信息"></a>查看连接到Zookeeper节点的Client信息</h3><p>该命令可以查看连接到指定Zookeeper节点的Client信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;cons&#34; | nc zookeeper.server.1 2181&#10;&#10;/[Client IP]:35764[1](queued=0,recved=1,sent=1,sid=0x10000b81b7d0003,lop=SESS,est=1547024407028,to=30000,lcxid=0x0,lzxid=0x500000012,lresp=22061060,llat=11,minlat=0,avglat=11,maxlat=11)&#10; /[Zookeeper Server IP]:42946[0](queued=0,recved=1,sent=0)</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BSession_u53CA_u4E34_u65F6_u8282_u70B9_u4FE1_u606F"><a href="#u67E5_u770BSession_u53CA_u4E34_u65F6_u8282_u70B9_u4FE1_u606F" class="headerlink" title="查看Session及临时节点信息"></a>查看Session及临时节点信息</h3><p>该命令可以查看指定Zookeeper节点建立Session的信息以及临时节点的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;dump&#34; | nc zookeeper.server.3 2181&#10;&#10;SessionTracker dump:&#10;Session Sets (3):&#10;0 expire at Fri Jan 02 07:13:54 CST 1970:&#10;0 expire at Fri Jan 02 07:14:04 CST 1970:&#10;1 expire at Fri Jan 02 07:14:14 CST 1970:&#10;&#9;0x10000b81b7d0003&#10;ephemeral nodes dump:&#10;Sessions with Ephemerals (0):</span><br></pre></td></tr></table></figure></p>
<p>该命令只有指定了Leader节点才有效。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u73AF_u5883_u53D8_u91CF"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u73AF_u5883_u53D8_u91CF" class="headerlink" title="查看Zookeeper节点的环境变量"></a>查看Zookeeper节点的环境变量</h3><p>该命令可以查看指定Zookeeper节点的环境变量信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;envi&#34; | nc zookeeper.server.3 2181</span><br></pre></td></tr></table></figure></p>
<h3 id="u76D1_u6D4BZookeeper_u8282_u70B9_u53EF_u7528_u72B6_u6001"><a href="#u76D1_u6D4BZookeeper_u8282_u70B9_u53EF_u7528_u72B6_u6001" class="headerlink" title="监测Zookeeper节点可用状态"></a>监测Zookeeper节点可用状态</h3><p>该命令可以查看指定Zookeeper节点是否正常：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;ruok&#34; | nc zookeeper.server.3 2181&#10;&#10;imok</span><br></pre></td></tr></table></figure></p>
<p>如果节点正常则返回<code>imok</code>，如果不正常则没有任何响应。</p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的信息"></a>查看Zookeeper节点的信息</h3><p>该命令可以查看指定Zookeeper节点的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;srvr&#34; | nc zookeeper.server.3 2181&#10;&#10;Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;Latency min/avg/max: 0/1/8&#10;Received: 34&#10;Sent: 33&#10;Connections: 1&#10;Outstanding: 0&#10;Zxid: 0x500000012&#10;Mode: leader&#10;Node count: 164&#10;Proposal sizes last/min/max: 36/32/90</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F_u4EE5_u53CA_u8FDE_u63A5Client_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u4FE1_u606F_u4EE5_u53CA_u8FDE_u63A5Client_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的信息以及连接Client信息"></a>查看Zookeeper节点的信息以及连接Client信息</h3><p>该命令可以查看指定Zookeeper节点的信息，以及连接该节点的Client信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;stat&#34; | nc zookeeper.server.1 2181&#10;&#10;Zookeeper version: 3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;Clients:&#10; /[Client IP]:35764[1](queued=0,recved=54,sent=54)&#10; /[Zookeeper Server IP]:42956[0](queued=0,recved=1,sent=0)&#10;&#10;Latency min/avg/max: 0/0/17&#10;Received: 223&#10;Sent: 222&#10;Connections: 2&#10;Outstanding: 0&#10;Zxid: 0x500000012&#10;Mode: follower&#10;Node count: 164</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BZookeeper_u8282_u70B9_u7684_u76D1_u63A7_u72B6_u6001_u4FE1_u606F"><a href="#u67E5_u770BZookeeper_u8282_u70B9_u7684_u76D1_u63A7_u72B6_u6001_u4FE1_u606F" class="headerlink" title="查看Zookeeper节点的监控状态信息"></a>查看Zookeeper节点的监控状态信息</h3><p>该命令可以查看指定Zookeeper节点的监控状态信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &#34;mntr&#34; | nc zookeeper.server.1 2181&#10;&#10;zk_version&#9;3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT&#10;zk_avg_latency&#9;0&#10;zk_max_latency&#9;17&#10;zk_min_latency&#9;0&#10;zk_packets_received&#9;236&#10;zk_packets_sent&#9;235&#10;zk_num_alive_connections&#9;2&#10;zk_outstanding_requests&#9;0&#10;zk_server_state&#9;follower&#10;zk_znode_count&#9;164&#10;zk_watch_count&#9;0&#10;zk_ephemerals_count&#9;0&#10;zk_approximate_data_size&#9;13322&#10;zk_open_file_descriptor_count&#9;116&#10;zk_max_file_descriptor_count&#9;65535&#10;zk_fsync_threshold_exceed_count&#9;0</span><br></pre></td></tr></table></figure></p>
<p>我们可以使用以上这些命令方便的查看Zookeeper节点以及Client的各种信息，提高效率。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践搭建了真正的Zookeeper集群，为之后搭建Kafka集群打基础，同时还复习了Zookeeper CLI的使用方式以及很重要的Zookeeper四字真言。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来真正搭建一个Zookeeper集群。</p>
<h2 id="u642D_u5EFAZookeeper_u96C6_u7FA4"><a href="#u642D_u5EFAZookeeper_u96C6_u7FA4" class="headerlink" title="搭建Zookeeper集群"></a>搭建Zookeeper集群</h2><p>首先要做的就是再租赁两个服务器，参照<strong>搭建单机Kafka</strong>章节中的步骤，租赁阿里云服务器、安装JDK、下载配置Kafka、配置安全组规则。</p>
<h3 id="Zookeeper_u914D_u7F6E_u4FE1_u606F"><a href="#Zookeeper_u914D_u7F6E_u4FE1_u606F" class="headerlink" title="Zookeeper配置信息"></a>Zookeeper配置信息</h3><p>在<strong>搭建单机Kafka</strong>章节中，启动的是单机Zookeeper，所以<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件中只配置了<code>dataDir</code>，也就是存储各种数据、日志、快照的路径。</p>
<p>在搭建Zookeeper时，就需要额外再配置一些参数了。同样打开<code>/root/kafka_2.12-2.0.0/config</code>目录下的<code>zookeeper.properties</code>配置文件，额外添加如下内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxClientCnxns=0&#10;tickTime=2000&#10;initLimit=10&#10;syncLimit=5&#10;quorumListenOnAllIPs=true&#10;server.1=zookeeper.server.1:2888:3888&#10;server.2=zookeeper.server.2:2888:3888&#10;server.3=zookeeper.server.3:2888:3888</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Zookeeper CLI：CRUD zNode]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-13/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-13/</id>
    <published>2019-01-27T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.009Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看Zookeeper的命令行工具。</p>
<h2 id="Zookeeper_CLI"><a href="#Zookeeper_CLI" class="headerlink" title="Zookeeper CLI"></a>Zookeeper CLI</h2><p>在第七章节搭建单机Kafka中，我们已经发现了，Kafka是自带Zookeeper的，而且在启动Kafka之前，要先启动Zookeeper，相当于启动了单机Zookeeper，所以我们先说Zookeeper CLI，后面说Zookeeper集群时再具体说配置参数。</p>
<h3 id="u5C55_u793AzNode"><a href="#u5C55_u793AzNode" class="headerlink" title="展示zNode"></a>展示zNode</h3><p>首先打开终端，连接至我们的服务器，进入<code>/root/kafka_2.12-2.0.0/bin</code>目录，执行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh zookeeper-shell.sh 127.0.0.1:2181</span><br></pre></td></tr></table></figure></p>
<p>这是Zookeeper CLI Client连接Zookeeper的命令，当看到如下信息时，说明连接成功：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Connecting to 127.0.0.1:2181&#10;Welcome to ZooKeeper!&#10;JLine support is disabled</span><br></pre></td></tr></table></figure></p>
<p>先来来看看目前Zookeeper里都有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;&#10;[cluster, controller_epoch, controller, brokers, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p><code>ls</code>命令和Linux中的作用一样，在Zookeeper中是展示某个zNode下的所有zNode。这里的<code>/</code>表示根zNode。可以看到已经有很多zNode注册在了Zookeeper。再来看看<code>brokers</code>下还有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers&#10;&#10;[ids, topics, seqid]</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>再来看看有哪些Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers/topics&#10;&#10;[with_keys_topic, first_topic, __consumer_offsets, configured-topic]</span><br></pre></td></tr></table></figure></p>
<h3 id="u67E5_u770BzNode_u5B58_u50A8_u7684_u6570_u636E"><a href="#u67E5_u770BzNode_u5B58_u50A8_u7684_u6570_u636E" class="headerlink" title="查看zNode存储的数据"></a>查看zNode存储的数据</h3><p>在上一章节中说过，Zookeeper中的zNode是可以存储数据的，那么我们来看看如何查看zNode中存储的数据，比如我们来看看<code>/brokers/ids</code>里保存了什么数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /brokers/ids&#10;&#10;null&#10;cZxid = 0x5&#10;ctime = Wed Dec 19 23:46:53 CST 2018&#10;mZxid = 0x5&#10;mtime = Wed Dec 19 23:46:53 CST 2018&#10;pZxid = 0x43d&#10;cversion = 51&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 0&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p><code>get</code>命令用于查看zNode中存储的数据，从上面的结果看到，<code>/brokers/ids</code>这个zNode里的数据是<code>null</code>，那么看看是否<code>/brokers/ids</code>下还有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers/ids&#10;&#10;[0]</span><br></pre></td></tr></table></figure></p>
<p>果然，<code>/brokers/ids</code>下还有zNode，这个zNode很明显是以Broker ID命名的。那再来看看<code>/brokers/ids/0</code>里存储了什么样的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /brokers/ids/0&#10;&#10;&#123;&#34;listener_security_protocol_map&#34;:&#123;&#34;PLAINTEXT&#34;:&#34;PLAINTEXT&#34;&#125;,&#34;endpoints&#34;:[&#34;PLAINTEXT://ECS&#22806;&#32593;IP:9092&#34;],&#34;jmx_port&#34;:-1,&#34;host&#34;:&#34;ECS&#22806;&#32593;IP&#34;,&#34;timestamp&#34;:&#34;1546570570448&#34;,&#34;port&#34;:9092,&#34;version&#34;:4&#125;&#10;cZxid = 0x43d&#10;ctime = Fri Jan 04 10:56:10 CST 2019&#10;mZxid = 0x43d&#10;mtime = Fri Jan 04 10:56:10 CST 2019&#10;pZxid = 0x43d&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x100363316d3004a&#10;dataLength = 192&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>从上面的结果可以看到，第一行显示的就是zNode存储的数据，<code>/brokers/ids/0</code>这个zNode存储了Broker的IP、端口、注册时间戳、JMX端口等信息。这一行之后的信息都是zNode的标准属性了，有各种时间戳、版本号、数据长度、子节点数等。</p>
<h3 id="u521B_u5EFAzNode"><a href="#u521B_u5EFAzNode" class="headerlink" title="创建zNode"></a>创建zNode</h3><p>我们可以使用Zookeeper CLI自行创建zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;some data&#34;&#10;&#10;Created /my_node&#10;&#10;ls /&#10;&#10;[cluster, controller, brokers, zookeeper, my_node, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p>使用<code>create</code>命令创建zNode。这里要注意的是，在创建zNode时必须要带着存储数据，哪怕是空也可以：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;&#34;</span><br></pre></td></tr></table></figure></p>
<p>否则是无法创建zNode的。</p>
<p>在创建zNode时不可以一次性创建多级zNode，如果还没有创建<code>my_node</code>，直接创建<code>deeper_node</code>是不可以的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node/deeper_node &#34;some data&#34;&#10;Node does not exist: /my_node/deeper_node</span><br></pre></td></tr></table></figure></p>
<p>所以Zookeeper要一层一层创建zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node &#34;some data&#34;&#10;Created /my_node&#10;create /my_node/deeper_node &#34;some data&#34;&#10;Created /my_node/deeper_node&#10;&#10;get /my_node/deeper_node&#10;some data&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x454&#10;mtime = Mon Jan 07 19:12:20 CST 2019&#10;pZxid = 0x454&#10;cversion = 0</span><br></pre></td></tr></table></figure></p>
<h2 id="u66F4_u65B0zNode_u7684_u6570_u636E"><a href="#u66F4_u65B0zNode_u7684_u6570_u636E" class="headerlink" title="更新zNode的数据"></a>更新zNode的数据</h2><p>我们可以通过<code>set</code>命令更新zNode中存储的数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node &#34;new data&#34;&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x455&#10;mtime = Mon Jan 07 19:14:04 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 1&#10;&#10;get /my_node&#10;new data&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x455&#10;mtime = Mon Jan 07 19:14:04 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p>可以看到<code>dataVersion</code>和<code>cversion</code>从0变成了1。这里注意一下，每当更新zNode存储的数据时，<code>dataVersion</code>会递增，之所以<code>cversion</code>也递增了是因为更新数据本身也是对zNode的修改，如果我们再更新一次数据，就只有<code>dataVersion</code>会递增了，因为第一次和第二次都是对zNode存储的数据的修改，只算作一次zNode的改变，所以<code>cversion</code>不会再更新：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node &#34;again new data&#34;&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x456&#10;mtime = Mon Jan 07 19:16:24 CST 2019&#10;pZxid = 0x454&#10;cversion = 1&#10;dataVersion = 2&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 14&#10;numChildren = 1</span><br></pre></td></tr></table></figure></p>
<p>如果想让<code>cversion</code>变化，那么给<code>my_node</code>再增加一个zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create /my_node/another_node &#34;some data&#34;&#10;Created /my_node/another_node&#10;get /my_node&#10;again new data&#10;cZxid = 0x453&#10;ctime = Mon Jan 07 19:12:07 CST 2019&#10;mZxid = 0x456&#10;mtime = Mon Jan 07 19:16:24 CST 2019&#10;pZxid = 0x457&#10;cversion = 2&#10;dataVersion = 2&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 14&#10;numChildren = 2</span><br></pre></td></tr></table></figure></p>
<p>可以看到<code>cversion</code>和<code>numChildren</code>都变了。</p>
<h3 id="u6DFB_u52A0zNode_Watcher"><a href="#u6DFB_u52A0zNode_Watcher" class="headerlink" title="添加zNode Watcher"></a>添加zNode Watcher</h3><p>上一章节同样说过，Zookeeper中的zNode的所有变更都可以被监控到。来看看如何通过CLI给zNode添加Watcher。我们给<code>/my_node/deeper_node</code>添加Watcher：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get /my_node/deeper_node true&#10;some data&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x454&#10;mtime = Mon Jan 07 19:12:20 CST 2019&#10;pZxid = 0x454&#10;cversion = 0&#10;dataVersion = 0&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 9&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<p>通过<code>get /zNode true</code>给zNode添加Watcher。当<code>/my_node/deeper_node</code>修改数据时，就会收到监听事件了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set /my_node/deeper_node &#34;new data&#34;&#10;&#10;WATCHER::&#10;&#10;WatchedEvent state:SyncConnected type:NodeDataChanged path:/my_node/deeper_node&#10;cZxid = 0x454&#10;ctime = Mon Jan 07 19:12:20 CST 2019&#10;mZxid = 0x458&#10;mtime = Mon Jan 07 19:24:05 CST 2019&#10;pZxid = 0x454&#10;cversion = 0&#10;dataVersion = 1&#10;aclVersion = 0&#10;ephemeralOwner = 0x0&#10;dataLength = 8&#10;numChildren = 0</span><br></pre></td></tr></table></figure></p>
<h3 id="u5220_u9664zNode"><a href="#u5220_u9664zNode" class="headerlink" title="删除zNode"></a>删除zNode</h3><p>可以通过<code>rmr</code>命令删除zNode，该命令是递归删除，既可以删除指定zNode以及该zNode下的所有zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rmr /my_node&#10;ls /&#10;[cluster, controller, brokers, zookeeper, admin, isr_change_notification, log_dir_event_notification, controller_epoch, kafka-manager, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践了如何使用Zookeeper CLI操作Zookeeper，通过增删改查zNode进一步认知Zookeeper的结构，对之后认知Kafka集群做以铺垫。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看Zookeeper的命令行工具。</p>
<h2 id="Zookeeper_CLI"><a href="#Zookeeper_CLI" class="headerlink" title="Zookeeper CLI"></a>Zookeeper CLI</h2><p>在第七章节搭建单机Kafka中，我们已经发现了，Kafka是自带Zookeeper的，而且在启动Kafka之前，要先启动Zookeeper，相当于启动了单机Zookeeper，所以我们先说Zookeeper CLI，后面说Zookeeper集群时再具体说配置参数。</p>
<h3 id="u5C55_u793AzNode"><a href="#u5C55_u793AzNode" class="headerlink" title="展示zNode"></a>展示zNode</h3><p>首先打开终端，连接至我们的服务器，进入<code>/root/kafka_2.12-2.0.0/bin</code>目录，执行如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh zookeeper-shell.sh 127.0.0.1:2181</span><br></pre></td></tr></table></figure></p>
<p>这是Zookeeper CLI Client连接Zookeeper的命令，当看到如下信息时，说明连接成功：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Connecting to 127.0.0.1:2181&#10;Welcome to ZooKeeper!&#10;JLine support is disabled</span><br></pre></td></tr></table></figure></p>
<p>先来来看看目前Zookeeper里都有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /&#10;&#10;[cluster, controller_epoch, controller, brokers, zookeeper, kafka-manager, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure></p>
<p><code>ls</code>命令和Linux中的作用一样，在Zookeeper中是展示某个zNode下的所有zNode。这里的<code>/</code>表示根zNode。可以看到已经有很多zNode注册在了Zookeeper。再来看看<code>brokers</code>下还有哪些zNode：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls /brokers&#10;&#10;[ids, topics, seqid]</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-初步认知：Zookeeper]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-12/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-12/</id>
    <published>2019-01-06T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.008Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来认识一下在Kafka中有着超然地位的Zookeeper。</p>
<h2 id="Zookeeper_u521D_u8BC6"><a href="#Zookeeper_u521D_u8BC6" class="headerlink" title="Zookeeper初识"></a>Zookeeper初识</h2><p>ZooKeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。简化分布式应用协调及其管理的难度，提供高性能的分布式服务。ZooKeeper的目标就是封装好复杂、易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
<p>Zookeeper有以下一些特点：</p>
<ul>
<li>Zookeeper的内部数据结构是树状结构的。</li>
<li>每个节点称为zNode。</li>
<li>每个zNode都有一个唯一路径（path）。</li>
<li>zNode分长久存在的和临时存在的。</li>
<li>每个zNode都可以存储数据。</li>
<li>zNode不能重命名。</li>
<li>每个zNode的任何变化都可以被监控。</li>
</ul>
<a id="more"></a>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/1/7/1546826442789.png" alt=""></p>
<p>所以Zookeeper作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，Zookeeper作用主要是用来维护和监控存储的数据的状态变化，通过监控这些数据状态的变化，从而达到基于数据的集群管理，可以说，Zookeeper相当于带有通知机制的文件系统。</p>
<h2 id="Role_of_Zookeeper_in_Kafka"><a href="#Role_of_Zookeeper_in_Kafka" class="headerlink" title="Role of Zookeeper in Kafka"></a>Role of Zookeeper in Kafka</h2><p>Zookeeper在Kafka中的地位是超然的。它的主要作用有以下几点：</p>
<ul>
<li>Zookeeper管理着Kafka集群中的若干个Broker，保存着一份完整的Broker列表。</li>
<li>维护Topic信息，比如Partitions、Replication Factor、ISR等。</li>
<li>Zookeeper帮助选举Partition的Leader.</li>
<li>当有任何变动时，由Zookeeper给Kafka发送通知，比如添加一个新的Topic、Broker挂掉了、删除Topic等等。</li>
<li>Zookeeper集群中也有Leader和Follower的概念。Leader负责写数据，Follower负责读数据.</li>
<li>存储Kafka集群ID。</li>
<li>存储访问控制列表（ACL，Access Control List）。控制Topic、Consumer Group、User等访问权限。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575649583.png" alt=""></p>
<h2 id="Size_of_Zookeeper"><a href="#Size_of_Zookeeper" class="headerlink" title="Size of Zookeeper"></a>Size of Zookeeper</h2><p>Zookeeper对于Kafka有一个很重要的投票选举功能。所以通常情况下Zookeeper集群最少使用三个Server。如果增加更多Server，那最好是奇数个Server（3，5，7，9，2N+1）。因为Zookeeper有一个特性，就是集群中只要有过半的机器是正常工作的，那么整个集群对外就是可用的。也就是说如果有2个Zookeeper Server，那么只要有1个Zookeeper Server宕机，整个集群就不能用了，因为1没有过半，所以我们要搭建奇数个Server，这样就可以保证最大允许1，2，3，4，N个Server宕机，而保证整个系统不受影响。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家初步认知了Zookeeper是什么，以及他在Kafka中为何具有超然的地位。和Kafka CLI一样，Zookeeper也有命令行工具，下一章节将会进行Zookeeper CLI的介绍，希望可以给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节我们来认识一下在Kafka中有着超然地位的Zookeeper。</p>
<h2 id="Zookeeper_u521D_u8BC6"><a href="#Zookeeper_u521D_u8BC6" class="headerlink" title="Zookeeper初识"></a>Zookeeper初识</h2><p>ZooKeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。简化分布式应用协调及其管理的难度，提供高性能的分布式服务。ZooKeeper的目标就是封装好复杂、易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
<p>Zookeeper有以下一些特点：</p>
<ul>
<li>Zookeeper的内部数据结构是树状结构的。</li>
<li>每个节点称为zNode。</li>
<li>每个zNode都有一个唯一路径（path）。</li>
<li>zNode分长久存在的和临时存在的。</li>
<li>每个zNode都可以存储数据。</li>
<li>zNode不能重命名。</li>
<li>每个zNode的任何变化都可以被监控。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：Kafka Java Consumer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-11/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-11/</id>
    <published>2018-12-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.008Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Consumer。</p>
<h2 id="Java_Consumer"><a href="#Java_Consumer" class="headerlink" title="Java Consumer"></a>Java Consumer</h2><p>首先创建Consumer需要的配置信息，最基本的有五个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。</li>
<li>指定Consumer Group。</li>
<li>指定拉取Message范围的策略。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"consumer_group_1"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"latest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<p>然后传入上面实例化好的配置信息，实例化Consumer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br></pre></td></tr></table></figure></p>
<p>然后通过Consumer的<code>subscribe(Collection&lt;String&gt; topics)</code>方法订阅Topic：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">consumer.subscribe(Arrays.asList(<span class="string">"first_topic"</span>));</span><br></pre></td></tr></table></figure></p>
<p>最后获取Topic里的Message，将Message信息输出到日志中：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">	ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">	<span class="keyword">for</span>(ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">		logger.info(<span class="string">"Key: "</span> + record.key() + <span class="string">", Value: "</span> + record.value());</span><br><span class="line">		logger.info(<span class="string">"Partition: "</span> + record.partition() + <span class="string">", Offset: "</span> + record.offset());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Consumer的<code>poll(Duration timeout)</code>方法可以设置获取数据的时间间隔，同时回忆一下在之前Consumer章节的<strong>Consumer Poll Options</strong>小节中，说过关于Consumer获取Message的四个配置项，都可以在Properties里进行设置。</p>
<p>启动Java Consumer后，在控制台可以看到如下信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[main] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Discovered group coordinator IP:9092 (id: 2147483647 rack: null)&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions []&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 1&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-0, first_topic-1, first_topic-2]&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-0 to offset 23.&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-1 to offset 24.&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=consumer_group_1] Resetting offset for partition first_topic-2 to offset 21.</span><br></pre></td></tr></table></figure></p>
<p>在上面的信息中，可以看到<code>Setting newly assigned partitions [first_topic-0, first_topic-1, first_topic-2]</code>这句话，说明当前这个Consumer会获取<code>first_topic</code>这个Topic中全部Partition中的Message。</p>
<p>如果我们再启动一个Consumer，这个Consumer和第一个在同一个组里，看看会有什么输出信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[main] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Discovered group coordinator IP:9092 (id: 2147483647 rack: null)&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions []&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 2&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-2]</span><br></pre></td></tr></table></figure></p>
<p>可以看到新启动的Consumer会输出<code>Setting newly assigned partitions [first_topic-2]</code>这句话，说明新的这个Consumer只会获取<code>first_topic</code>这个Topic的一个Partition中的Message。</p>
<p>再回去看看第一个Consumer的控制台：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Attempt to heartbeat failed since group is rebalancing&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Revoking previously assigned partitions [first_topic-0, first_topic-1, first_topic-2]&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] (Re-)joining group&#10;[main] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Successfully joined group with generation 2&#10;[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=consumer_group_1] Setting newly assigned partitions [first_topic-0, first_topic-1]</span><br></pre></td></tr></table></figure></p>
<p>第一个Consumer新输出在控制台中的信息很关键，首先看到<code>Attempt to heartbeat failed since group is rebalancing</code>这句话，说明Kafka会自动重新给Consumer Group里的Consumer分配Topic的Partition。</p>
<p>再看<code>Setting newly assigned partitions [first_topic-0, first_topic-1]</code>这句，说明第一个Consumer不会再获取<code>first_topic-2</code>这个Partition里的Message了。这也印证了在Consumer章节的<strong>Consumer Group</strong>小节里讲过的概念。</p>
<h3 id="Java_Consumer_with_Assign_and_Seek"><a href="#Java_Consumer_with_Assign_and_Seek" class="headerlink" title="Java Consumer with Assign and Seek"></a>Java Consumer with Assign and Seek</h3><p>如果我们有一个临时的Consumer，不想加入任何一个Consumer Group，而且需要指定Topic的Partition，以及指定从哪个Message Offset开始获取数据，怎么办？所幸，Kafka提供了这样的API。</p>
<p>首先我们在实例化配置信息时，就不需要指定Consumer Group了：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KafkaConstant.BOOTSTRAP_SERVER);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure></p>
<p>然后实例化<code>TopicPartition</code>，指定Topic和Partition序号。使用Consumer的<code>assign(Collection&lt;TopicPartition&gt; partitions)</code>方法，分配给该Consumer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">TopicPartition topicPartition = <span class="keyword">new</span> TopicPartition(<span class="string">"first_topic"</span>, <span class="number">0</span>);</span><br><span class="line">consumer.assign(Arrays.asList(topicPartition));</span><br></pre></td></tr></table></figure></p>
<p>再然后指定Message Offset：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> offset = <span class="number">21L</span>;</span><br><span class="line">consumer.seek(topicPartition, offset);</span><br></pre></td></tr></table></figure></p>
<p>运行该Consumer，可以看到如下输出信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=] Fetch offset 21 is out of range for partition first_topic-0, resetting offset&#10;[main] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-1, groupId=] Resetting offset for partition first_topic-0 to offset 22.&#10;[main] INFO com.devtalking.jacefu.kafka.tutorial.ConsumerDemoAssignSeek - Key: null, Value: hello world!&#10;[main] INFO com.devtalking.jacefu.kafka.tutorial.ConsumerDemoAssignSeek - Partition: 0, Offset: 22</span><br></pre></td></tr></table></figure></p>
<p>如果我们使用Consumer Group CLI查看，会发现这种操作其实也是临时创建了一个Consumer Group：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@iZ2ze2booskait1cxxyrljZ:~# kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;consumer_group_1&#10;KMOffsetCache-iZ2ze2booskait1cxxyrljZ</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节带大家实践如何使用Kafka提供的API编写Java Consumer。上一节和这一节主要介绍了Kafka Java Client（Producer和Consumer）的使用方式，相比Kafka CLI，Java Client在实际的开发中可能使用的更加频繁，希望能给使用Java语言的小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Consumer。</p>
<h2 id="Java_Consumer"><a href="#Java_Consumer" class="headerlink" title="Java Consumer"></a>Java Consumer</h2><p>首先创建Consumer需要的配置信息，最基本的有五个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。</li>
<li>指定Consumer Group。</li>
<li>指定拉取Message范围的策略。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"consumer_group_1"</span>);</span><br><span class="line">properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"latest"</span>); <span class="comment">// earliest, none</span></span><br></pre></td></tr></table></figure>
</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：Kafka Java Producer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-10/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-10/</id>
    <published>2018-12-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.008Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Producer。</p>
<h2 id="Create_Kafka_Project"><a href="#Create_Kafka_Project" class="headerlink" title="Create Kafka Project"></a>Create Kafka Project</h2><p>创建Maven工程，在POM文件中加入如下两个依赖：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>slf4j-simple<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>第一个是Kafka的依赖包，用于创建Producer、ProducerRecord、Consumer等。第二个是Log4J的依赖包，用于输出日志。</p>
<a id="more"></a>
<h2 id="Java_Producer"><a href="#Java_Producer" class="headerlink" title="Java Producer"></a>Java Producer</h2><p>首先创建Producer需要的配置信息，最基本的有三个信息：</p>
<ul>
<li>Kafka集群的地址。</li>
<li>发送的Message中Key的序列化方式。</li>
<li>发送的Message中Value的序列化方式。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"IP:Port"</span>);</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>然后传入上面实例化好的配置信息，实例化Producer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br></pre></td></tr></table></figure></p>
<p>然后实例化Record对象，该对象承载了要往哪个Topic发送以及Message内容的信息：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first_topic"</span>, <span class="string">"hello world!"</span>);</span><br></pre></td></tr></table></figure></p>
<p>再然后发送Record：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.send(producerRecord);</span><br></pre></td></tr></table></figure></p>
<p>最后刷新和关闭Producer：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.flush();</span><br><span class="line">kafkaProducer.close();</span><br></pre></td></tr></table></figure></p>
<p>以上就是最简单的Kafka Java Producer的编写方法。运行一下，可以看到类似如下的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.&#10;&#10;Process finished with exit code 0</span><br></pre></td></tr></table></figure></p>
<h3 id="Java_Producer_with_Callback"><a href="#Java_Producer_with_Callback" class="headerlink" title="Java Producer with Callback"></a>Java Producer with Callback</h3><p>如果我们希望在发送Message后，能监控发送状态，或者在发送异常时对异常进行处理。那么我们就可以使用带有Callback的发送方法：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">kafkaProducer.send(producerRecord, <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">			logger.info(<span class="string">"Received new metadata. \n"</span> +</span><br><span class="line">                            <span class="string">"Topic: "</span> + recordMetadata.topic()  + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Partition: "</span> + recordMetadata.partition() + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Offset: "</span> + recordMetadata.offset() + <span class="string">"\n"</span> +</span><br><span class="line">                            <span class="string">"Timestamp: "</span> + recordMetadata.timestamp());</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			logger.error(<span class="string">"Error while producing: "</span>, e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p>这样每次发送Message后，都会进入<code>onCompletion</code>这个方法中，然后可以使用<code>RecordMetadata</code>中记录的各种元数据做一些跟踪和监控的事情，同时如果发送异常了，也可以对异常进行处理。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.0&#10;[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a8361b734732&#10;[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - Cluster ID: 4nh_0r5iQ_KsR_Fzf1HTGg&#10;[kafka-producer-network-thread | producer-1] INFO com.devtalking.jacefu.kafka.tutorial1.ProducerDemoWithCallback - Received new metadata. &#10;Topic: first_topic&#10;Partition: 0&#10;Offset: 22&#10;Timestamp: 1546421392063&#10;[main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.&#10;&#10;Process finished with exit code 0</span><br></pre></td></tr></table></figure></p>
<h3 id="Java_Producer_with_Keys"><a href="#Java_Producer_with_Keys" class="headerlink" title="Java Producer with Keys"></a>Java Producer with Keys</h3><p>在前文中，Partition的Compaction Cleanup Policy一节中介绍到，在压缩策略时，就涉及到了Message的Key和Value。我们来看看如何在发送Message时带着Key。</p>
<p>首先来看看<code>ProducerRecord</code>的另一个构造函数：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(topic, (Integer)<span class="keyword">null</span>, (Long)<span class="keyword">null</span>, key, value, (Iterable)<span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到，刚才我们只使用了<code>topic</code>和<code>value</code>两个参数，其中还有一个<code>key</code>，所以我们在实例化<code>ProducerRecord</code>时传入Key就可以了：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"first_topic"</span>, <span class="string">"This is the key"</span>, <span class="string">"hello world!"</span>);</span><br></pre></td></tr></table></figure></p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>之前三个章节介绍了如何使用Kafka CLI操作Kafka，其中包括Producer CLI和Consumer CLI。这一章节主要带大家实践如何使用Kafka提供的API编写Java Producer，希望可以给使用Java语言的小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节来看看如何使用Java编写Kafka Producer。</p>
<h2 id="Create_Kafka_Project"><a href="#Create_Kafka_Project" class="headerlink" title="Create Kafka Project"></a>Create Kafka Project</h2><p>创建Maven工程，在POM文件中加入如下两个依赖：<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>slf4j-simple<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>第一个是Kafka的依赖包，用于创建Producer、ProducerRecord、Consumer等。第二个是Log4J的依赖包，用于输出日志。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Reseting Offset & Config CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-9/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-9/</id>
    <published>2018-11-30T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.012Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Reseting_Offset"><a href="#Reseting_Offset" class="headerlink" title="Reseting Offset"></a>Reseting Offset</h2><p>在实际的业务场景中，经常需要重复消费Topic中的Message，所以来看看如何重置Offset。</p>
<p>首先重置Offset可以通过如下的命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --reset-offsets [options] --execute --topic xxxx</span><br></pre></td></tr></table></figure></p>
<p>Kafka为我们提供了6种重置Offset的方式，也就是命令中的<code>options</code>：</p>
<ul>
<li><code>--to-earliest</code>：重置到最早的Offset。</li>
<li><code>--to-latest</code>：重置到最后的Offset。</li>
<li><code>--to-offset &lt;Long: offset&gt;</code>：重置到指定的Offset。</li>
<li><code>--to-current</code>：重置到当前的Offset。</li>
<li><code>--to-datetime &lt;String: datetime&gt;</code>：重置到指定时间的Offset，时间格式为<code>YYYY-MM-DDTHH:mm:SS.sss</code>。</li>
<li><code>--shift-by &lt;Long: number-of-offsets&gt;</code>：左移或右移Offset。</li>
</ul>
<a id="more"></a>
<p>举个例子来看看：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --topic first_topic --reset-offsets --shift-by -2 --execute&#10;&#10;TOPIC                          PARTITION  NEW-OFFSET&#10;first_topic                    2          15&#10;first_topic                    1          17&#10;first_topic                    0          15</span><br></pre></td></tr></table></figure></p>
<p>上面的命令将<code>consumer_group_1</code>消费<code>first_topic</code>的三个Partitions的Offset向左移了2位。如此之后，相当于<code>consumer_group_1</code>还有6条Message没有消费。我们启动Consumer看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --topic first_topic&#10;&#10;C&#10;F&#10;E&#10;this is another message.&#10;A&#10;D</span><br></pre></td></tr></table></figure></p>
<p>可以看到启动Consumer后，消费了6条Message。其他的Reset Options用法是一样的。这使得我们可以非常灵活的控制Consumer消费Message。</p>
<h2 id="Config_CLI"><a href="#Config_CLI" class="headerlink" title="Config CLI"></a>Config CLI</h2><p>我们再来看看如何通过命令进行Kafka的配置。用到的命令是<code>kafka-config.sh</code>，该命令可以对Topic、Broker、Client进行配置。关键的属性有以下三个：</p>
<ul>
<li><code>--entity-type</code>：这个属性设置要对什么进行配置，可选值为<code>topics</code>、<code>brokers</code>、<code>clients</code>、<code>users</code>。</li>
<li><code>--entity-name</code>：这个属性设置对应Type的名称，比如Topic名称、Broker Id、Client Id、User name。</li>
<li><code>--alter</code>：确认修改。</li>
</ul>
<p>首先我们创建一个Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181 --create --topic configured-topic --partitions 3 --replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>看看新创建的Topic的信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic configured-topic --describe&#10;&#10;Topic:configured-topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:&#10;Topic: configured-topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>可以看到打印信息中的Configs是空的，说明这个Topic没有做额外的配置。或者也可以使用如下命令查看Topic的配置：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --describe&#10;&#10;Configs for topic &#39;configured-topic&#39; are</span><br></pre></td></tr></table></figure></p>
<p>看到打印信息只有<code>Configs for topic &#39;configured-topic&#39; are</code>，同样说明该Topic还没有额外配置信息。</p>
<p>接下来该这个Topic设置<code>min.insync.replicas</code>属性：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --add-config min.insync.replicas=2 --alter&#10;&#10;Completed Updating config for entity: topic &#39;configured-topic&#39;.</span><br></pre></td></tr></table></figure></p>
<p>再来查看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --describe&#10;&#10;Configs for topic &#39;configured-topic&#39; are min.insync.replicas=2&#10;&#10;kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic configured-topic --describe&#10;&#10;Topic:configured-topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:min.insync.replicas=2&#10;Topic: configured-topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: configured-topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>两种方式都可以看到刚才更新的配置信息。</p>
<p>将<code>--add-config</code>换成<code>--delete-config</code>就可以删除配置项：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-configs.sh --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name configured-topic --add-config min.insync.replicas=2 --alter&#10;&#10;Completed Updating config for entity: topic &#39;configured-topic&#39;.</span><br></pre></td></tr></table></figure></p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节进一步介绍了如何通过Kafka CLI操作Consumer Offset，以及如何使用Config CLI对Kafka进行配置。下一章节会介绍如何使用Kafka API编写Kafka Java Client。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Reseting_Offset"><a href="#Reseting_Offset" class="headerlink" title="Reseting Offset"></a>Reseting Offset</h2><p>在实际的业务场景中，经常需要重复消费Topic中的Message，所以来看看如何重置Offset。</p>
<p>首先重置Offset可以通过如下的命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group consumer_group_1 --reset-offsets [options] --execute --topic xxxx</span><br></pre></td></tr></table></figure></p>
<p>Kafka为我们提供了6种重置Offset的方式，也就是命令中的<code>options</code>：</p>
<ul>
<li><code>--to-earliest</code>：重置到最早的Offset。</li>
<li><code>--to-latest</code>：重置到最后的Offset。</li>
<li><code>--to-offset &lt;Long: offset&gt;</code>：重置到指定的Offset。</li>
<li><code>--to-current</code>：重置到当前的Offset。</li>
<li><code>--to-datetime &lt;String: datetime&gt;</code>：重置到指定时间的Offset，时间格式为<code>YYYY-MM-DDTHH:mm:SS.sss</code>。</li>
<li><code>--shift-by &lt;Long: number-of-offsets&gt;</code>：左移或右移Offset。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Consumer CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-8/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-8/</id>
    <published>2018-11-30T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Consumer_CLI"><a href="#Consumer_CLI" class="headerlink" title="Consumer CLI"></a>Consumer CLI</h2><p>这一节来看看使用命令行启动Consumer接收消息，通过如下的命令启动Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-consumer.sh</code>是启动Consumer的命令。</li>
<li><code>--bootstrap-server</code>指定要连接的Broker地址。</li>
<li><code>--topic</code>指定Topic名称，既要从哪个Topic里读数据。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575057414.png" alt=""></p>
<a id="more"></a>
<p>如上图所示，左边启动的是Consumer，右边启动的是Producer。Producer发送的消息可以实时的被Consumer接收到。但是有一个问题，那就是在上一节中，我们已经给<code>first_topic</code>这个Topic发送了一些数据。但是现在Consumer启动后并没有收到。这是因为通过上面的命令启动的Consumer接收的是最新的消息，如果想接收所有的消息，还需要带一个参数：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning</span><br></pre></td></tr></table></figure></p>
<p><code>--from-beginning</code>表示启动的Consumer要接收所有的消息。</p>
<p>前文中说过，Consumer一般都是以组的形式存在，所以可以再加一个参数来创建一个Consumer Group：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --group consumer_group_1</span><br></pre></td></tr></table></figure></p>
<p><code>--group</code>可以指定Consumer Group的名称。</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575079452.png" alt=""></p>
<p>如上图所示，左边启动了三个Consumer，这三个Consumer都在同一个名为<code>consumer_group_1</code>的组里。因为<code>first_topic</code>这个Topic有三个Partitions，所以当一个Consumer Group中有三个Consumer时，他们的收到的信息不会重复。</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575103168.png" alt=""></p>
<p>又如上图所示，左边启动了三个Consumer，但是前两个在<code>consumer_group_1</code>的组里，最后一个在<code>consumer_group_2</code>的组里，所以前两个Consumer是以轮询的方式收到消息的，而最后一个Consumer可以收到全部的消息。</p>
<p>上面两个示例也充分证明了前文中所说的，<strong>不同的Consumer Group可以消费同一个Topic中相同的Partition的消息，但是Consumer Group内的Consumer不能消费同一个Topic中相同的Partition的消息</strong>。</p>
<p>上面的命令是显示的创建Consumer Group。上文中说到过，Kafka中，Consumer都是以组的形式连接Broker消费数据的。那么如果只有一个Consumer的情况下，是否有Consumer Group呢？其实，当只有一个Consumer时，也会自动创建一个Consumer Group。我们可以通过另外一组Consumer Group CLI来看一下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;console-consumer-40439&#10;console-consumer-81216&#10;consumer_group_1c&#10;console-consumer-14387&#10;consumer_group_2&#10;consumer_group_1&#10;console-consumer-40563</span><br></pre></td></tr></table></figure></p>
<p>可以看到，已经存在的Consumer Group中，除了我们之前创建的，还有以<code>console-consumer-xxxxx</code>这种命名格式存在的Consumer Group。这就是当我们只启动一个Consumer时Kafka自动为这个Consumer创建的Consumer Group。这里可以做个实验，先启动一个Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<p>然后再来看看Consumer Group是否有增加：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list&#10;&#10;console-consumer-96752&#10;console-consumer-40439&#10;console-consumer-81216&#10;consumer_group_1c&#10;console-consumer-14387&#10;consumer_group_2&#10;consumer_group_1&#10;console-consumer-40563</span><br></pre></td></tr></table></figure></p>
<p>我们看到增加了一个Consumer Group<code>console-consumer-96752</code>。</p>
<p>Consumer Group列表看完了，再来看看某一个Consumer Group的详细信息，比如查看<code>consumer_group_1</code>的详细信息。可以使用如下命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;Consumer group &#39;consumer_group_1&#39; has no active members.&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               -               -               -&#10;first_topic     2          17              17              0               -               -               -&#10;first_topic     1          18              18              0               -               -</span><br></pre></td></tr></table></figure></p>
<p>首先会告诉我们该Consumer Group中是否有正在活跃的Consumer，目前没有启动任何Consumer，所以提示我们<code>Consumer group &#39;consumer_group_1&#39; has no active members.</code></p>
<p>然后会列出该Consumer Group消费的Topic、Partition情况、Offset情况、延迟（LAG）情况、处于活跃状态的Consumer信息。</p>
<p>可以看到<code>consumer_group_1</code>这个Consumer Group正在消费<code>first_topic</code>这个Topic中的Message，一共从三个Partition中消费了52条Messages，并且目前已经消费了全部的数据，因为每个Partition的延迟都是0，说明没有还未接收的Message。</p>
<p>现在我们再往<code>first_topic</code>中发送一条Message，再来看看情况如何：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1&#10;&#62;this is another message.&#10;&#10;kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;Consumer group &#39;consumer_group_1&#39; has no active members.&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               -               -               -&#10;first_topic     2          17              17              0               -               -               -&#10;first_topic     1          18              19              1               -               -               -</span><br></pre></td></tr></table></figure></p>
<p>可以看到Partition 1 的<code>LOG-END-OFFSET</code>是19，而<code>CURRENT-OFFSET</code>是18，并且Partition 1 的<code>LAG</code>是1，说明现在<code>first-topic</code>一共接收到了19条Message，而<code>consumer-group-1</code>只消费了18条，有1条延迟。</p>
<p>我们再启动<code>consumer_group_1</code>中的Consumer，然后再看看数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning --group consumer_group_1&#10;&#10;this is another message.&#10;&#10;kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group consumer_group_1&#10;&#10;TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID&#10;first_topic     0          17              17              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1&#10;first_topic     1          19              19              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1&#10;first_topic     2          17              17              0               consumer-1-4ec288ac-e202-40b1-a2ec-d43abc49b38d /172.17.222.157 consumer-1</span><br></pre></td></tr></table></figure></p>
<p>可以看到，目前有一个处于活跃的Consumer，并且Messages全部被消费。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节主要介绍了如何使用Kafka的Consumer CLI接收Producer生产的Message。同时能更直观的印证之前介绍概念时提到的内容，比如Consumer Group的机制、Offset机制等。下一章节进一步介绍Offset的操作以及Config CLI。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Consumer_CLI"><a href="#Consumer_CLI" class="headerlink" title="Consumer CLI"></a>Consumer CLI</h2><p>这一节来看看使用命令行启动Consumer接收消息，通过如下的命令启动Consumer：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-consumer.sh</code>是启动Consumer的命令。</li>
<li><code>--bootstrap-server</code>指定要连接的Broker地址。</li>
<li><code>--topic</code>指定Topic名称，既要从哪个Topic里读数据。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555575057414.png" alt=""></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-Kafka CLI：Topic CLI & Producer CLI]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-7/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-7/</id>
    <published>2018-11-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Kafka CLI是Kafka Command Line Interface。其实就是Kafka的命令行工具，可以让我们在终端里方面的进行Kafka的操作，比如创建Topic、Partition、Replication、Produce data、Consume data等等。后续的几个章节主要来介绍如何使用Kafka CLI。</p>
<h2 id="Topic_CLI"><a href="#Topic_CLI" class="headerlink" title="Topic CLI"></a>Topic CLI</h2><p>首先我们可以通过下面的命令创建Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh &#8212;zookeeper 127.0.0.1:2181 &#8212;topic xxxx_topic &#8212;create &#8212;partitions 3 &#8212;replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，<code>replication-factor</code>不能大于Broker的数量，这个很好理解，前文中有过阐述。成功后可以看<code>Created topic &quot;first_topic&quot;.</code>这样的提示。</p>
<a id="more"></a>
<p>可以通过如下命令查看当前有哪些Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --list</span><br></pre></td></tr></table></figure></p>
<p>可以通过如下命令查看某个Topic的具体信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --topic first_topic --describe</span><br></pre></td></tr></table></figure></p>
<p>显示该Topic的Partition信息、Leader信息、ISR信息、Replication信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Topic:first_topic&#9;PartitionCount:3&#9;ReplicationFactor:1&#9;Configs:&#10;Topic: first_topic&#9;Partition: 0&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: first_topic&#9;Partition: 1&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0&#10;Topic: first_topic&#9;Partition: 2&#9;Leader: 0&#9;Replicas: 0&#9;Isr: 0</span><br></pre></td></tr></table></figure></p>
<p>这里注意，Partition后面的数字是序号，因为我们设置了三个Partition。Leader、Replicas、Isr后面的数字是Broker的ID，在<code>server.properties</code>配置文件中可以配置Broker的ID，默认从0开始。</p>
<p>可以通过如下命令删除Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper 127.0.0.1:2181  --topic second_topic --delete</span><br></pre></td></tr></table></figure></p>
<p>这里要注意，Broker有一个配置项<code>delete.topic.enable</code>，如果设为<code>false</code>，那么删除Topic时并非立即删除，只是会被打上删除的标记，以减少Topic突然删除给业务带来的冲击。如果设为<code>true</code>，那么就是立即删除，默认是<code>true</code>。</p>
<p>现在大家可以到<code>/kafka_2.12-2.0.0/data/kafka</code>目录中看一下，可以看到Partition的目录，和一些Checkpoint的文件。</p>
<h2 id="Producer_CLI"><a href="#Producer_CLI" class="headerlink" title="Producer CLI"></a>Producer CLI</h2><p>再来看看如何通过CLI启动Producer发送消息，命令如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>kafka-console-producer.sh</code>是启动Producer的命令。</li>
<li><code>--broker-list</code>设置连接的Broker地址，指定要连接哪个Broker。端口号9092是默认的，在<code>server.properties</code>文件中可以通过<code>port</code>属性更改，IP地址可以通过<code>host.name</code>属性更改。</li>
<li><code>--topic</code>设置Topic名称，指定要往哪个Topic里发送消息。</li>
<li><code>--producer-property</code>配置Producer的参数，这里要指定ACK的策略。</li>
</ul>
<p>然后就可以发送消息了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=1&#10;&#62;hello this is a producer&#10;&#62;I am JaceFu&#10;&#62;Kafka is a awesome MQ system</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，如果在命令中指定的Topic不存在，则Kafka会自动创建这个Topic，Partition数量会根据<code>server.properties</code>中配置的<code>num.partitions</code>数创建。但建议应该提前创建好Topic再发送消息。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节介绍了如何使用Kafka的Topic CLI创建Topic、查看Topic信息。然后使用Producer CLI生产Message。结合之前对它们概念的介绍，能让我们有更直观的认知。下一章节会介绍如何使用Consumer CLI。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Kafka CLI是Kafka Command Line Interface。其实就是Kafka的命令行工具，可以让我们在终端里方面的进行Kafka的操作，比如创建Topic、Partition、Replication、Produce data、Consume data等等。后续的几个章节主要来介绍如何使用Kafka CLI。</p>
<h2 id="Topic_CLI"><a href="#Topic_CLI" class="headerlink" title="Topic CLI"></a>Topic CLI</h2><p>首先我们可以通过下面的命令创建Topic：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh &#8212;zookeeper 127.0.0.1:2181 &#8212;topic xxxx_topic &#8212;create &#8212;partitions 3 &#8212;replication-factor 1</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意一点，<code>replication-factor</code>不能大于Broker的数量，这个很好理解，前文中有过阐述。成功后可以看<code>Created topic &quot;first_topic&quot;.</code>这样的提示。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-实践真知：搭建单机Kafka]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-6/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-6/</id>
    <published>2018-10-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节介绍如何在Linux服务器上搭建单机Kafka。</p>
<h2 id="u79DF_u8D41_u670D_u52A1_u5668"><a href="#u79DF_u8D41_u670D_u52A1_u5668" class="headerlink" title="租赁服务器"></a>租赁服务器</h2><p>为了更加真实，本小册的实践内容都搭建在云服务器上。可以在阿里云或者腾讯云租赁服务器，如果想租赁国外的服务器，可以在<a href="https://www.vultr.com/?ref=7702774" target="_blank" rel="external">Vultr</a>租赁。我选择在阿里云租赁了一台Linux服务器。配置不需要太高，入门级的就可以，系统可以选择CentOS或者Ubuntu。</p>
<blockquote>
<p>注意：在配置ECS时，宽带计费方式要选择按量计费，这样可以自动分配公网IP，并且价格实惠。</p>
</blockquote>
<h2 id="u5B89_u88C5JDK"><a href="#u5B89_u88C5JDK" class="headerlink" title="安装JDK"></a>安装JDK</h2><p>使用终端登录服务器，首先安装JDK：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt update&#10;apt install openjdk-8-jdk</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="u4E0B_u8F7DKafka"><a href="#u4E0B_u8F7DKafka" class="headerlink" title="下载Kafka"></a>下载Kafka</h2><p>然后去<a href="https://archive.apache.org/dist/kafka/2.0.0/kafka_2.12-2.0.0.tgz" target="_blank" rel="external">Kafka官网</a>下载2.0.0版本的Kafka，Scala版本为2.12（kafka_2.12-2.0.0.tgz）。解压：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -xvf kafka_2.12-2.0.0.tgz</span><br></pre></td></tr></table></figure></p>
<p>解压完之后，将Kafka的bin目录配置到PATH中：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH=/root/kafka_2.12-2.0.0/bin:$PATH</span><br></pre></td></tr></table></figure></p>
<h2 id="u914D_u7F6EKafka"><a href="#u914D_u7F6EKafka" class="headerlink" title="配置Kafka"></a>配置Kafka</h2><p>接下来进行最基本的配置。我们需要创建三个目录，用来存放Zookeeper和Kafka的数据：</p>
<ul>
<li><code>/root/kafka_2.12-2.0.0/data</code></li>
<li><code>/root/kafka_2.12-2.0.0/data/zookeeper</code></li>
<li><code>/root/kafka_2.12-2.0.0/data/kafka</code></li>
</ul>
<p>然后更新Zookeeper配置文件（<code>/root/kafka_2.12-2.0.0/config/zookeeper.properties</code>）中的Data路径（<code>dataDir</code>）为<code>/root/kafka_2.12-2.0.0/data/zookeeper</code>。</p>
<p>接着更新Kakfa Broker配置文件（<code>/root/kafka_2.12-2.0.0/config/server.properties</code>）中的日志路径（<code>log.dirs</code>）为<code>/root/kafka_2.12-2.0.0/data/kafka</code></p>
<h2 id="u8BBE_u7F6E_u963F_u91CC_u4E91ECS_u5B89_u5168_u7EC4_u89C4_u5219"><a href="#u8BBE_u7F6E_u963F_u91CC_u4E91ECS_u5B89_u5168_u7EC4_u89C4_u5219" class="headerlink" title="设置阿里云ECS安全组规则"></a>设置阿里云ECS安全组规则</h2><p>最后我们要对阿里云ECS进行一些配置，才可以让本地的Kafka Client通过外网IP连接到部署在ECS上的Kafka。</p>
<p>打开阿里云控制台/云服务器ECS/实例，在<strong>更多</strong>选项里选择网络和安全组/安全组配置：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555574758784.png" alt=""></p>
<p>然后进入配置规则：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555574799842.png" alt=""></p>
<p>添加安全组规则：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555574830647.png" alt=""></p>
<p>因为是自己用的，所以为了方便起见，将授权对象设置为<code>0.0.0.0/0</code>：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/4/18/1555574846030.png" alt=""></p>
<p>设置完ECS之后，我们还需要配置一下Kafka Broker的信息，打开<code>config/server.properties</code>文件，添加如下信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">advertised.listeners=PLAINTEXT://ECS&#22806;&#32593;IP:9092</span><br></pre></td></tr></table></figure></p>
<p><code>advertised.listeners</code>这个属性的作用是告诉Zookeeper，该Broker将以这里配置的IP作为Host。这样，本地Kafka Client就可以通过ECS的外网IP连接到Broker了。</p>
<h2 id="u542F_u52A8Kafka"><a href="#u542F_u52A8Kafka" class="headerlink" title="启动Kafka"></a>启动Kafka</h2><p>在上文中，我们知道Kafka离开Zookeeper是玩不转的，所以首先要启动Zookeeper：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/zookeeper-server-start.sh config/zookeeper.properties &#38;</span><br></pre></td></tr></table></figure></p>
<p>然后再启动Kafka Broker：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/root/kafka_2.12-2.0.0/bin/kafka-server-start.sh config/server.properties &#38;</span><br></pre></td></tr></table></figure></p>
<p>至此，Kafka最基本的搭建和启动就成功了。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节介绍了如何使用Linux服务器搭建单机Kafka，因为后续的Kafka CLI要基于单机Kafka进行实操。所以希望大家都能自己动手先搭建单机Kafka。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>这一节介绍如何在Linux服务器上搭建单机Kafka。</p>
<h2 id="u79DF_u8D41_u670D_u52A1_u5668"><a href="#u79DF_u8D41_u670D_u52A1_u5668" class="headerlink" title="租赁服务器"></a>租赁服务器</h2><p>为了更加真实，本小册的实践内容都搭建在云服务器上。可以在阿里云或者腾讯云租赁服务器，如果想租赁国外的服务器，可以在<a href="https://www.vultr.com/?ref=7702774">Vultr</a>租赁。我选择在阿里云租赁了一台Linux服务器。配置不需要太高，入门级的就可以，系统可以选择CentOS或者Ubuntu。</p>
<blockquote>
<p>注意：在配置ECS时，宽带计费方式要选择按量计费，这样可以自动分配公网IP，并且价格实惠。</p>
</blockquote>
<h2 id="u5B89_u88C5JDK"><a href="#u5B89_u88C5JDK" class="headerlink" title="安装JDK"></a>安装JDK</h2><p>使用终端登录服务器，首先安装JDK：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt update&#10;apt install openjdk-8-jdk</span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-庖丁解牛：Consumer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-5/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-5/</id>
    <published>2018-10-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>了解完Producer，接下来介绍Kafka中的Consumer的概念，以及在消费Message时有什么样的策略。</p>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><p>Consumer负责从Topic中读取数据，我们已经知道了Topic是通过名称确定唯一的，所以指定Consumer从哪个Topic中读数据，同样使用Topic名称指定。Kafka中的Consumer有以下几点需要我们注意：</p>
<ul>
<li>我们只需要指定需要从哪个Topic中读取数据即可。不需要关心Consumer是从哪个Broker中的哪个Partition中读数据，这些工作由Kafka帮我们处理好了。</li>
<li>当持有Topic的Broker挂掉，重新恢复后，Consumer可以自动重新从该Broker中读数据。</li>
<li>在一个Partition中，Consumer是按Offset的顺序读取数据的。</li>
<li>一个Consumer可以同时读取多个Broker中的不同Partition，但是Partition之间无法保证读取数据的顺序，因为是并行执行的。</li>
</ul>
<a id="more"></a>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/kafka-consumer.png" alt=""></p>
<h3 id="Consumer_Group"><a href="#Consumer_Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h3><p>Consumer有组的概念，对于Consumer Group有以下几点需要我们注意：</p>
<ul>
<li>不同的Consumer Group之间可以读取相同的Partition中的数据。</li>
<li>Consumer Group里的Consumer之间不能读取相同的Partition中的数据，他们读取数据的Partition是专享的。</li>
<li>所以基于上面的知识点，如果Consumer数量多于Partition数量，那么就会有Consumer处于空闲的状态。</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/kafka-consumer.png" alt=""></p>
<p>上图的示例中，如果Consumer Group 2中再增加一个Consumer 4，那么Consumer 4就会处于空闲状态，因为没有多余的Partition分给它了。</p>
<h3 id="Consumer_Offset"><a href="#Consumer_Offset" class="headerlink" title="Consumer Offset"></a>Consumer Offset</h3><p>一个优秀的MQ系统，必定会有一个能力，那就是断点续传的能力。既当Consumer挂掉再恢复后，需要从挂掉的前一时刻读数据的点开始接着往后读。那么如何做到这一点呢，那就是通过Consumer Offset来实现的。</p>
<p>每当一个活跃的Consumer正在从Partition中读取数据时，Kafka都会根据给定的策略记住该Consumer读取数据的Offset。这个策略就是Consumer提交Offset的策略。目前有三个策略：</p>
<h4 id="At_most_once"><a href="#At_most_once" class="headerlink" title="At most once"></a>At most once</h4><p>这种策略下，只要Consumer读到了Message，就立即提交Offset，不考虑Message有没有被正确处理。如果Message刚读过来，还没有处理的时候，Consumer挂掉了，重新恢复后对上一次读取的Message不会重新读取，所以这种模式比较容易丢失数据。整个过程如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/27/1545902569574.png" alt=""></p>
<h4 id="At_least_once"><a href="#At_least_once" class="headerlink" title="At least once"></a>At least once</h4><p>这种策略下，Consumer需要读到Message，并且正确处理了Message后，才会提交Offset。如果Consumer挂掉，再恢复后，可以重新读取上一次的Message继续处理。这里就需要我们处理Message的逻辑必须是幂等的，否则会造成Message重复执行导致错误的业务结果。整个过程如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/27/1545903354244.png" alt=""></p>
<h4 id="Exactly_once"><a href="#Exactly_once" class="headerlink" title="Exactly once"></a>Exactly once</h4><p>这个策略想做到的是不丢数据，又可以不用幂等的处理逻辑。这里通常需要Kafka和外部系统配合使用。后面再做具体介绍。</p>
<h3 id="Consumer_Poll_Options"><a href="#Consumer_Poll_Options" class="headerlink" title="Consumer Poll Options"></a>Consumer Poll Options</h3><p>在Consumer订阅Topic拉取Message的行为中，会涉及到四个参数：</p>
<ul>
<li><code>fetch.min.bytes</code>：该参数表示每次拉取Message的最小量，默认是1Bytes。</li>
<li><code>fetch.max.bytes</code>：该参数表示每次拉取Message的最大量，默认是50MB。</li>
<li><code>max.poll.records</code>：该参数表示每次拉取Message的条数，默认是500条。</li>
<li><code>max.partitions.fetch.bytes</code>：该参数表示每个Partition在一次拉取中，可以被拉取到Message的最大量，默认是1MB。</li>
</ul>
<p>这些参数可以让Consumer控制拉取Message的速率，以及可以监控Consumer每次拉取Message的具体信息。</p>
<h3 id="Consumer_Offset_Reset_Behavior"><a href="#Consumer_Offset_Reset_Behavior" class="headerlink" title="Consumer Offset Reset Behavior"></a>Consumer Offset Reset Behavior</h3><p>在实际应用中，Consumer是很有可能在运行过程中挂掉的，那么当Consumer重新恢复后，拉取什么范围的Message，是有策略可以设置的，可以通过设置<code>auto.offset.reset</code>属性，常用的值有两个：</p>
<ul>
<li><code>earliest</code>：从Message文件的最开始进行拉取，既将Topic中的所有数据重新拉取过来。</li>
<li><code>latest</code>：从Message文件的最后开始拉取，既不考虑Topic之前的所有数据，只拉取最新的数据。</li>
</ul>
<p>在后面讲到CLI的时候，这部分再做详细阐述。</p>
<h3 id="Consumer_internal_thread"><a href="#Consumer_internal_thread" class="headerlink" title="Consumer internal thread"></a>Consumer internal thread</h3><p>为保证Consumer的稳定性和高可用性。Kafka有心跳机制，所以Consumer不光和Broker交互，也要和心跳监控节点交互：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/27/1545925702680.png" alt=""></p>
<p>这里引出了两个参数：</p>
<ul>
<li><code>seesion.timeout.ms</code>：该参数的作用是Broker认为Consumer挂掉的持续时间。默认为10秒。也就是说Broker在10秒内没有收到Consumer的心跳信号，那么认为该Consumer已经挂掉了。</li>
<li><code>heartbeat.interval.ms</code>：该参数决定了Consumer发送心跳信号的间隔时间。默认为3秒。</li>
</ul>
<p>总结一下前文介绍的Kafka核心概念。先上一张图总体概括：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/19/1545190605332.png" alt=""></p>
<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>在Producer层面，我们了解了以下知识点：</p>
<ul>
<li>Producer发送Message到Broker默认采用轮询方式，除非显示的将Message带着Key。</li>
<li>如果希望Message根据某个字段发送至相同的Partition中，可以将Message带着Key发送。</li>
<li>Producer有acks机制，关系到Message的完整性，以及整体MQ系统的整体性能（Message吞吐量）。</li>
<li>Producer发送Message有重试机制。</li>
<li>在实际使用时，我们通常需要考虑幂等Producer，以确保不会有业务上的错误。</li>
<li>Message压缩和批量发送有助于提高Message传输性能。</li>
</ul>
<h2 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h2><p>在Broker层面，我们了解了以下知识点：</p>
<ul>
<li>Partition是以文件夹的形式存储在Broker中的。</li>
<li>Partition有Replication的概念，可以确保Message的完整性。</li>
<li>Partition有Leader和ISR的概念。</li>
<li>Partition中Message存储的方式。</li>
<li>Partition中清理Message的策略。</li>
</ul>
<h2 id="Consumer-1"><a href="#Consumer-1" class="headerlink" title="Consumer"></a>Consumer</h2><p>在Consumer层面，我们了解了以下知识点：</p>
<ul>
<li>Consumer有组的概念，Consumer Group和Consumer获取Topic中数据的方式。</li>
<li>Consumer提交Offset的策略，关系到Consumer断点续传的方式。</li>
<li>Consumer如何控制获取Topic中Message的速率。</li>
<li>Consumer如何重制Offset。</li>
</ul>
<p>最后我们再明确一下有哪些是Kafka提供的保障，或者说是我们不能，也不应该违背的原则：</p>
<ul>
<li>Message写入Topic-Partition的顺序严格按照Producer发送Message的顺序。</li>
<li>Consumer从Topic-Partition读Message的顺序严格按照Partition中Message的Offset顺序。</li>
<li>如果Partition的Replication Factor是N，那么可以允许有N-1个Broker挂掉，而且Kafka可以正常运转。</li>
<li>只要Topic的Partition的数量恒定，那么带有指定Key的Message会始终写入该Key对应的Partition。</li>
<li>如果你想给Kafka集群中的某个Topic发送数据，你只需要连接Kafka集群中的一个Broker以及给定Topic名称既可。不用考虑Partition、Replication等等的问题。</li>
</ul>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>前面五个章节阐述了什么是MQ系统，然后基于这个大的框架介绍了Kafka系统中的核心模块，以及这些核心模块中的核心知识点。之后的章节主要就是实践部分，包括如何使用Kafka CLI、搭建Zookeeper、单机Kakfa、集群Kafka等。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>了解完Producer，接下来介绍Kafka中的Consumer的概念，以及在消费Message时有什么样的策略。</p>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><p>Consumer负责从Topic中读取数据，我们已经知道了Topic是通过名称确定唯一的，所以指定Consumer从哪个Topic中读数据，同样使用Topic名称指定。Kafka中的Consumer有以下几点需要我们注意：</p>
<ul>
<li>我们只需要指定需要从哪个Topic中读取数据即可。不需要关心Consumer是从哪个Broker中的哪个Partition中读数据，这些工作由Kafka帮我们处理好了。</li>
<li>当持有Topic的Broker挂掉，重新恢复后，Consumer可以自动重新从该Broker中读数据。</li>
<li>在一个Partition中，Consumer是按Offset的顺序读取数据的。</li>
<li>一个Consumer可以同时读取多个Broker中的不同Partition，但是Partition之间无法保证读取数据的顺序，因为是并行执行的。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-庖丁解牛：Producer]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-4/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-4/</id>
    <published>2018-09-30T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>通过上一章节，我们知道了Kafka的Message是如何持久化的，知道了保证高可用性、稳定性的策略。这一节来看看Kafka中如何生产Message以及相关的策略。</p>
<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>简而言之，Producer就负责往Topic里发送数据，或者说写入数据。换言之，就是往组成这个Topic的一至多个Partition里写入数据。这里有三点需要注意：</p>
<ul>
<li>我们只需要通过Producer产生数据，往Topic里塞既可。Producer会自动去选择正确的、合适的Broker和Partition持久化数据。</li>
<li>Producer默认采用轮询的机制选择Broker往Partition里持久化数据的。</li>
<li>如果其中有一个Broker挂了，当它再恢复时，Producer会自动接纳它。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/18/1545090560721.png" alt=""></p>
<h3 id="Message_keys"><a href="#Message_keys" class="headerlink" title="Message keys"></a>Message keys</h3><p>Producer默认采用轮询的机制选择Broker往Partition里持久化数据。但当我们需要根据数据中的某个字段按Partition进行分组或者排序时，就需要在每条Message里添加Key，这个Key可以是数字，也可以是字符串等等。然后相同Key的Message永远会持久化到同一个Partition。</p>
<a id="more"></a>
<h3 id="Acks"><a href="#Acks" class="headerlink" title="Acks"></a>Acks</h3><p>Producer在发送生产出的数据给Broker时，可以选择三种模式，称为acks，它是Acknowledgment的缩写。意思是Broker对Producer即将发送来的数据采用何种确认方式。</p>
<h4 id="acks_3D0"><a href="#acks_3D0" class="headerlink" title="acks=0"></a>acks=0</h4><p>在该模式下，Producer不会等待Broker的确认反馈，即不关心Broker是否正确的将发送来的数据持久化，所以在这种模式下，很有可能会丢失数据。因为如果Broker挂了，Producer不会被通知到，所以还会不停的发送数据导致数据丢失。在对数据完整性需求不强烈的场景下，这种模式可以提高性能。</p>
<h4 id="acks_3D1"><a href="#acks_3D1" class="headerlink" title="acks=1"></a>acks=1</h4><p>默认采用的模式，该模式下Producer会等待Leader Broker的确认反馈，当Broker确实将数据持久化到至少一个Partition中后，给予Producer确认反馈，Producer才会继续发送数据。该模式下有几点需要注意：</p>
<ul>
<li>不保证Replicas也持久化了数据。</li>
<li>当Producer没有收到Broker的确认反馈时，Producer会尝试重新发送数据。</li>
<li>当Leader Broker挂了，但是Replicas又没有持久化数据时，还是会丢失数据。</li>
<li>该模式只能说是可以有效防止数据丢失。</li>
</ul>
<h4 id="acks_3Dall"><a href="#acks_3Dall" class="headerlink" title="acks=all"></a>acks=all</h4><p>该模式下，Producer同样需要等待Broker的确认，但是确认更为严格，需要所有的Partition（Leader + Replicas）都持久化数据后才返回确认信息。这种模式下，只要Replicas足够多，数据基本不会丢失。</p>
<p>在该模式下，还有一个重要的参数<code>min.insync.replicas</code>需要配置。该参数的意思是当<code>acks=all</code>时，至少有多少个Replicas需要确认已成功持久化数据，这个Replicas数量也包括Leader。</p>
<p>举个例子，假设有三个Broker，参数为<code>min.insync.replicas=2</code>、<code>replication.factor=3</code>、<code>acks=all</code>，那么Producer每次发送Message时，都需要至少2个Broker给予确认反馈，换句话说，在这个Kafka集群中，只能允许一个Broker挂掉。如果<code>min.insync.replicas=3</code>，那么一个Broker都不能挂，否则Producer在发送Message时会收到<code>NOT_ENOUGH_REPLICAS</code>的异常。</p>
<h3 id="Retry"><a href="#Retry" class="headerlink" title="Retry"></a>Retry</h3><p>有时候Producer发送Message失败可能并不是因为Broker挂了，可能是因为网络问题，没有连接到Broker等等。这种问题可能在很短暂的时间内就会自动修复，那么在这种情况下，我们希望Producer在发送失败后能重新尝试发送。这里就需要设置<code>retries</code>这个参数，意思就是重试的次数，默认是0次，可以根据实际业务情况设置。</p>
<p>但是当设置了<code>retries</code>参数大于0后，有可能会带来新的问题。假如我们需要相同Key的Message进入特定的Partition，并且是要严格按照Producer生产Message的顺序排序。那么此时如果第一条Message发送失败，第二条Message发送成功了，第一条通过重试发送成功了，那Message的顺序就发生了变化。</p>
<p>这里又会引出一个参数<code>max.in.flight.requests.per.connection</code>，这个参数默认是5，意思是在被Broker阻止前，未通过acks确认的发送请求最大数，也就是在Broker处排队等待acks确认的Message数量。所以刚才那个场景，第一条和第二条Message都在Broker那排队等待确认放行，这时第一条失败了，等重试的第一条Message再来排队时，第二条早都通过进去了，所以排序就乱了。</p>
<p>如果想在设置了<code>retries</code>还要严格控制Message顺序，可以把<code>max.in.flight.requests.per.connection</code>设置为1。让Broker处永远只有一条Message在排队，就可以严格控制顺序了。但是这样做会严重影响性能（接收Message的吞吐量）。</p>
<h3 id="Idempotent_Producer"><a href="#Idempotent_Producer" class="headerlink" title="Idempotent Producer"></a>Idempotent Producer</h3><p>在实际情况中，经常会遇到一个现象，那就是当Broker给Producer返回acks确认时，网络出异常了，导致Producer没有收到ack确认，于是，Producer进行重试。如果Consumer的Offset策略（在后续章节会介绍）是<code>at least once</code>或者是<code>exactly once</code>，那么第一次对Message就已经进行了处理，比如入库。那么第二次会对相同的Message再做一次处理，对相同数据进行重复处理，势必会引起业务上的错误。整个过程如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/26/1545807972109.png" alt=""></p>
<p>所以这就需要幂等Producer来保证我们处理数据的唯一性。Kafka在0.11版本之后，就为我们提供了定义幂等Producer的能力，可以通过将<code>enable.idempotence.config</code>参数设置为<code>true</code>来定义幂等Producer。将Producer定义为幂等后，还要设置其他对应的参数：</p>
<ul>
<li><code>retries=Integer.MAX_VALUE</code></li>
<li><code>max.in.flight.requests.per.connection=1 (Kafka &gt;= v0.11 &amp; &lt; v1.1)</code></li>
<li><code>max.in.flight.requests.per.connection=5 (Kafka &gt;= v1.1)</code></li>
<li><code>acks=all</code></li>
</ul>
<p>如此设置后，可以有效防止重复消费Message，整个过程就会如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/26/1545808307901.png" alt=""></p>
<h3 id="Message_Compression"><a href="#Message_Compression" class="headerlink" title="Message Compression"></a>Message Compression</h3><p>消息压缩的作用不言而喻：</p>
<ul>
<li>加快网络传输速度，减少消息延迟。</li>
<li>更有效的利用磁盘空间。</li>
<li>加快消息吞吐率。</li>
</ul>
<p>只需要设置<code>compression.type</code>参数，该参数默认是<code>none</code>，可选项有<code>gzip</code>、<code>lz4</code>、<code>snappy</code>。建议使用<code>lz4</code>或者<code>snappy</code>。</p>
<h3 id="Message_Batch"><a href="#Message_Batch" class="headerlink" title="Message Batch"></a>Message Batch</h3><p>上面介绍了<code>max.in.flight.requests.per.connection</code>参数，默认会在Broker那排队5条Message，那么如果第六条来了怎么办呢？这时候Kafka会自动开启批量处理Message的模式，将这6条Message作为一个批次进行处理。这一个批次可以看作是一次Message处理请求。</p>
<p>开启批量模式后，会引出两个参数：</p>
<ul>
<li><code>linger.ms</code>：每次批量处理的间隔时间。如果设为5，那么就是每5毫秒对Message进行一次批量处理。</li>
<li><code>batch.size</code>：每个批次的最大字节数，默认是16KB，可以设置为32KB或者64KB，可以提高性能。</li>
</ul>
<p>过程如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/26/1545814677871.png" alt=""></p>
<h3 id="Producer_Buffer"><a href="#Producer_Buffer" class="headerlink" title="Producer Buffer"></a>Producer Buffer</h3><p>在大多数情况下，Consumer消费Message的速率是远不如Producer生产Message的速率的。所以Producer有一个缓存机制，将Broker还没来得及接收的Message缓存在内存中。缓存的大小可以通过<code>buffer.memory</code>配置，默认大小是32MB。默认存储时间为7天，这个时间可以通过设置Broker的<code>offset.retention.minutes</code>属性改变。</p>
<p>如果Producer的缓存被打满后，Producer会被阻塞，阻塞的最大时间可以通过<code>max.block.ms</code>配置，默认大小是60秒。</p>
<p>概括一下，就是当Producer生产Message的速率大于Broker接收Message（Consumer消费数据）的速率时，Producer会把Broker还没来得及接收的Message存在缓存里（内存），当存满设置的缓存大小后，Producer将不再发送Message给Broker，也就是进入阻塞状态，如果在设置的阻塞时间内，缓存还没有被释放出有用空间，那么Producer将抛出异常。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节我们了解了Kafka的Producer，介绍很重要的Acks机制、Retry机制、幂等机制以及消息批次机制等。这些和我们满足性能方面的需求息息相关，同时我们也进一步了解了Kafka是如何保证业务层面的高可用性的。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>通过上一章节，我们知道了Kafka的Message是如何持久化的，知道了保证高可用性、稳定性的策略。这一节来看看Kafka中如何生产Message以及相关的策略。</p>
<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>简而言之，Producer就负责往Topic里发送数据，或者说写入数据。换言之，就是往组成这个Topic的一至多个Partition里写入数据。这里有三点需要注意：</p>
<ul>
<li>我们只需要通过Producer产生数据，往Topic里塞既可。Producer会自动去选择正确的、合适的Broker和Partition持久化数据。</li>
<li>Producer默认采用轮询的机制选择Broker往Partition里持久化数据的。</li>
<li>如果其中有一个Broker挂了，当它再恢复时，Producer会自动接纳它。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/18/1545090560721.png" alt=""></p>
<h3 id="Message_keys"><a href="#Message_keys" class="headerlink" title="Message keys"></a>Message keys</h3><p>Producer默认采用轮询的机制选择Broker往Partition里持久化数据。但当我们需要根据数据中的某个字段按Partition进行分组或者排序时，就需要在每条Message里添加Key，这个Key可以是数字，也可以是字符串等等。然后相同Key的Message永远会持久化到同一个Partition。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-庖丁解牛：Partition]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-3/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-3/</id>
    <published>2018-09-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.011Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>了解了Kafka的窗户和内核之后，我们深入Broker中，看看Topic和Broker之间的关系，它们之间到底是用什么联系起来的。Broker对Message的持久化是如何处理的。</p>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>Kafka的Partition是分区的概念，在Kafka中，一个Topic可以有多个Partition，换句话说，就是一个Topic中的内容是被多个Partition分割的。对于Partition，我们需要注意以下几个要点：</p>
<ul>
<li>一个Topic下的所有Partition是有顺序的，或者说在创建Topic和Partition时，Partition的顺序就已经是确定了的。</li>
<li>每条进入Partition中的Message都会获得一个自增的ID，这个ID称为Offset（消息的偏移量）。</li>
<li>通常在说Message的Offset时，只是针对该条Message所在的Partition而言。举个例子，Partition-0中Offset为3的Message和Partition-1中Offset为3的Message没有任何关系。</li>
<li>当说到Message的顺序时，通常有两种解读：<ul>
<li>业务语义上的Message顺序，如下图所示，1至4条Message之间是有语义顺序的，可以理解为是消息生产者生产消息时的顺序。</li>
<li>Partition中的Message顺序，如下图所示，Partition-1中的Message如果按照Offset的顺序，那么第一条和第二条Message其实是语义上的第一条和第三条Message。</li>
</ul>
</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/kafka-message-order.png" alt=""></p>
<ul>
<li>当Message进入Partition后，它的Offset和内容就无法再修改了。</li>
<li>Message默认是随机存储在一个Topic下的不同的Partition中的，如上图。除非显示的指定Partition。</li>
<li>存储在Partition中的Message是有时效性的，默认是保存一周，可以通过配置更改（后续章节会介绍）。</li>
</ul>
<a id="more"></a>
<p>在Kafka中，一个Partition对应物理机器上的一个文件夹，文件夹命名会以Topic名称加序号表示。换句话说，Partition在Broker中以文件夹的形式存在。每个Partition文件夹中会有多个大小相等的日志段文件（Segment File），消息生产者生产的消息发送到Broker后就会以追加到日志文件末尾的方式持久化到Partition中。</p>
<h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>我们再来看一个和Partition相关的概念，Replication。从字面意思就可以看出，这是Partition副本的意思。Replication Factor决定了将Partition复制几份，也就是将数据复制几份。Partition的副本也是会随机被分配到任意Broker中。下图展示了它们之间的关系：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/17/1545061968721.png" alt=""></p>
<p>从上图中可以看出，如果Broker 102挂掉了，是不会影响我们的Kafka集群的运转的，因为我们的数据并没有丢失，Broker 101和Broker 103中任何持久化着Topic-A的数据。这就是Replication的作用，它可以有效保证数据在Kafka系统中的完整性和有效性。</p>
<h3 id="Leader_for_Partition"><a href="#Leader_for_Partition" class="headerlink" title="Leader for Partition"></a>Leader for Partition</h3><p>当Partition有多个副本时，又会引出一个概念，那就是Partition的Leader Broker。关于Partition的Leader有以下几个要点：</p>
<ul>
<li>在任何时候，只有一个Broker会成为某个Partition的Leader。</li>
<li>只有作为Leader的Broker才会为Partition接收和处理数据。其他持有Partition副本的Broker只是从Leader Broker同步数据。</li>
<li>每个Partition只有一个Leader Broker，但可以有多个随从Broker，或者说是ISR（in-sync replica）。</li>
</ul>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/18/1545064328376.png" alt=""></p>
<p>上图所示，Broker 101是Topic-A Partition 0的Leader Broker。Broker 102是Topic-A Partition 1的Leader Broker。如果Broker 101挂掉了，那么Broker 102会自动被选举为新的Topic-A Partition 0的Leader Broker。当Broker 101恢复后，会重新将Leader交还给Broker 101。选举Leader Broker的工作由Zookeeper帮Kafka完成，这里暂做了解。</p>
<h3 id="Partition_Count_and_Replication_Factor_Convention"><a href="#Partition_Count_and_Replication_Factor_Convention" class="headerlink" title="Partition Count  and Replication Factor Convention"></a>Partition Count  and Replication Factor Convention</h3><p>在通常情况下，设置Topic的Partition数量和Replication数量有一些惯例可以参照。</p>
<p><strong>首先这两个参数是非常非常重要的，直接关系到Kafka集群的性能、高可用问题。在创建Topic之前，一定要先思考如何设置Partition数量和Replication数量。并且尽量不要在之后调整Partition数量和Replication数量。</strong></p>
<p>前文中讲过，如果在Kafka运行时调整Topic的Partition数量，会直接影响Message根据Key的顺序问题。如果调整Replication数量，会给集群带来较大的性能压力，因为涉及到Zookeeper要重新选举Leader一系列操作。</p>
<p>所以在较小的Kafka集群中（小于6个Broker），一般每个Topic的Partition数量为Broker数量的两倍。在较大的Kafka集群中（大于12个Broker），一般每个Topic的Partition数量等于Broker的数量。介于这两者之间的可以根据具体业务和IaaS的情况，设置两倍于Broker或等于Broker数量。</p>
<p><strong>Replication数量最少为2，通常为3，最大也就设置到4</strong>。前文中说过，Replication的数量关系到我们可以容忍有几个Broker挂掉（N -1个）。而且如果<code>acks=all</code>，Replication太多会影响效率，并且会增加磁盘空间。所以综上，一般将Replication Factor设置为3，比较合理。</p>
<h3 id="Segment_File"><a href="#Segment_File" class="headerlink" title="Segment File"></a>Segment File</h3><p>我们已经知道了Topic是由Partition构成的。再来说说构成Partition的Segment文件。</p>
<p>进入<code>kafka_2.12-2.0.0/data/kafka</code>这个目录后（这里的目录暂做了解，后续在Kafka搭建小节里会讲到），可以看到一些以<code>Topic name-index</code>这种格式命名的文件夹，这些就是Partition：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/29/1546053528484.png" alt=""></p>
<p>进入<code>first_topic-0</code>这个Partition后，可以看到有一些文件，<code>*.log</code>就是Partition的Segment文件：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/29/1546053710199.png" alt=""></p>
<p>Partition的Segment文件涉及到两个参数：</p>
<ul>
<li><code>log.segment.bytes</code>：设置每个Segment文件的大小，默认是1GB。</li>
<li><code>log.segment.ms</code>：设置每个Segment文件允许写入的时间，默认是一周。</li>
</ul>
<p>上面两个参数说明了，Partition的Segment文件可以有多个，当一个Segment的大小达到<code>log.segment.bytes</code>参数设置的大小后，关闭（不允许写入）这个Segment文件，并自动开启下一个Segment文件。如果一个Segment文件在<code>log.segment.ms</code>参数设置的时间内没有写满，那么也将自动关闭，并开启新的Segment文件。所以始终只会有一个处于活跃状态的Segment文件可以被写入。</p>
<p><code>log.segment.bytes</code>设置的越小，Partition的Segment文件数就越多，对关闭的<code>*.log</code>文件压缩操作就越频繁。<code>log.segment.ms</code>的值也同样影响文件压缩的频率。所以这两个参数要根据业务实际情况，对吞吐量的需求去合理设置。</p>
<p>在上图中，还看到<code>*.index</code>和<code>*.timeindex</code>两个文件，这两个都是帮助Kafka查找Message的索引文件：</p>
<ul>
<li><code>*.index</code>：这个文件记录了Message Offset，可以让Kafka通过Message Offset快速定位到Message。</li>
<li><code>*.timeindex</code>：这个文件记录了Message的时间戳，可以让Kafka通过绝对时间定位到Message。</li>
</ul>
<p>这三个文件的名称是一样的，整个名称的长度为20位数字，第一个Segment文件从0开始，后续每个Segment文件的名称为上一个<code>*.log</code>文件中最后一条Message Offset，其他位数用0填充，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0000000000000000000.index&#10;0000000000000000000.log&#10;0000000000000037489.index&#10;0000000000000037489.log&#10;0000000000005467283.index&#10;0000000000005467283.log</span><br></pre></td></tr></table></figure>
<p>用一张图来概括Partition和Segment文件的关系：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/29/1546055197464.png" alt=""></p>
<h3 id="Delete_Cleanup_Policy"><a href="#Delete_Cleanup_Policy" class="headerlink" title="Delete Cleanup Policy"></a>Delete Cleanup Policy</h3><p>Kafka的Message既然是存在磁盘上的，那么必然会有数据回收或者数据清理的机制，这里涉及到一个参数<code>log.cleanup.policy</code>如果将值设置为<code>delete</code>，那么Partition中的Message会基于规则在一段时间后被删除。这里的规则有两个，一个是基于时间的，一个是基于Partition大小的。</p>
<h4 id="log-retention-hours"><a href="#log-retention-hours" class="headerlink" title="log.retention.hours"></a>log.retention.hours</h4><p><code>log.retention.hours</code>参数的值默认是168小时，既1周时间，也就是Partition中的未处于活跃状态的Segment文件只保留一周，一周后会被自动删除。</p>
<p>这个参数如果设置的比较大，那么意味着Topic的历史数据会保留较长时间，Consumer丢失数据的容错率会高一些。同时会占用更多磁盘空间。如果设置的比较小，意味着Topic的历史数据保留的时间较短，Consumer丢失数据的潜在风险较大，但是占用的磁盘空间较小。所以该值需要根据实际情况设置。</p>
<h4 id="log-retention-bytes"><a href="#log-retention-bytes" class="headerlink" title="log.retention.bytes"></a>log.retention.bytes</h4><p><code>log.retention.bytes</code>参数的值默认是-1，也就是指Partition的大小是无穷大的，既不考虑Partition的大小。如果将其设置为524288000，那么就表示当Partition大小超过500MB时，会删除未处于活跃状态的Segment文件。</p>
<p>通常情况下，使用默认配置就好，既不考虑Partition大小，历史数据保留一周。但也可以根据业务自行设置，灵活组合。但有一点需要注意的是，这两个规则只要达到一个，就会启动清理数据的任务。</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/31/1546267108235.png" alt=""></p>
<h3 id="Compaction_Cleanup_Policy"><a href="#Compaction_Cleanup_Policy" class="headerlink" title="Compaction Cleanup Policy"></a>Compaction Cleanup Policy</h3><p>另外一个策略是压缩策略，<code>__consumer_offset</code>这个Topic默认采用的就是这种策略，我们先看一张图：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2019/1/1/1546353684917.png" alt=""></p>
<p>上图表示的应该比较清楚了，压缩模式就是把相同Key的旧数据删了，每个Key只留下最近的数据。这种模式相对DELETE策略，至少每个Key都会有数据，但是历史数据会丢失。</p>
<p>当<code>log.cleanup.policy=compact</code>时，有以下相关的一些参数需要我们注意：</p>
<ul>
<li><code>segment.ms</code>：该参数会使用默认的值，默认为7天。该参数表示等待关闭活跃状态Segment文件的时间。</li>
<li><code>segment.bytes</code>：每个Segment文件的大小，默认为1G。</li>
<li><code>min.compaction.lag.ms</code>：当Message可以被压缩的时候，要等待的时长，也就是延迟压缩的时间，默认是0。</li>
<li><code>delete.retention.ms</code>：当Message被标记为需要压缩到删除它之间的时间，默认为24小时。</li>
<li><code>min.cleanable.dirty.ratio</code>：压缩率，默认为0.5。</li>
</ul>
<h4 id="Cleanup_Frequency"><a href="#Cleanup_Frequency" class="headerlink" title="Cleanup Frequency"></a>Cleanup Frequency</h4><p>不论是删除策略还是压缩策略，都是针对Partition的Segment文件进行的，根本还是磁盘IO操作，所以这种清理工作不应该过于频繁，否则会对整个Broker造成性能方面的影响。对Segment文件的大小也要把控在合理的范围内。太小，太多的Segment文件肯定会使清理工作更加频繁。</p>
<p>另外还可以对<code>log.cleaner.backoff.ms</code>参数进行设置来控制清理频率，这个参数控制检测是否需要清理的时间，默认是15秒检查一次。将其设大一点，也可以降低清理频率。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节通过对Partition、Replication、Segment File的介绍可以了解Broker中对Message持久化的方式。通过对Partition Leader、Relipcation Factor、Message的处理策略的介绍了解了Kafka保证可用性和稳定性的基本策略。这些概念是之后我们进行实践时的基础。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>了解了Kafka的窗户和内核之后，我们深入Broker中，看看Topic和Broker之间的关系，它们之间到底是用什么联系起来的。Broker对Message的持久化是如何处理的。</p>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>Kafka的Partition是分区的概念，在Kafka中，一个Topic可以有多个Partition，换句话说，就是一个Topic中的内容是被多个Partition分割的。对于Partition，我们需要注意以下几个要点：</p>
<ul>
<li>一个Topic下的所有Partition是有顺序的，或者说在创建Topic和Partition时，Partition的顺序就已经是确定了的。</li>
<li>每条进入Partition中的Message都会获得一个自增的ID，这个ID称为Offset（消息的偏移量）。</li>
<li>通常在说Message的Offset时，只是针对该条Message所在的Partition而言。举个例子，Partition-0中Offset为3的Message和Partition-1中Offset为3的Message没有任何关系。</li>
<li>当说到Message的顺序时，通常有两种解读：<ul>
<li>业务语义上的Message顺序，如下图所示，1至4条Message之间是有语义顺序的，可以理解为是消息生产者生产消息时的顺序。</li>
<li>Partition中的Message顺序，如下图所示，Partition-1中的Message如果按照Offset的顺序，那么第一条和第二条Message其实是语义上的第一条和第三条Message。</li>
</ul>
</li>
</ul>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/kafka-message-order.png" alt=""></p>
<ul>
<li>当Message进入Partition后，它的Offset和内容就无法再修改了。</li>
<li>Message默认是随机存储在一个Topic下的不同的Partition中的，如上图。除非显示的指定Partition。</li>
<li>存储在Partition中的Message是有时效性的，默认是保存一周，可以通过配置更改（后续章节会介绍）。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-庖丁解牛：Topic&Broker]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-2/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-2/</id>
    <published>2018-08-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.010Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Apache Kafka正是上节描述的MQ系统，但不仅是MQ系统，它往往也被描述为<strong>分布式提交日志系统</strong>或者<strong>分布式流式处理系统</strong>。从这节开始，我们将逐步了解Kafka的核心概念。</p>
<h2 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h2><p>在Kafka中，Topic可以理解为表示一组特殊的数据流。可以将它想象为关系性数据库中的表。</p>
<ul>
<li>数据库中的表存储着同一类的数据。那么Topic同样表示同一类的数据流。</li>
<li>数据库中的表可以根据需求创建多张。那么Topic同样可以根据需求创建多个，但有一点区别是，Topic没有像数据库表中约束（Constraints）的概念。</li>
<li>数据库中表的名称是不能重复的，表名能唯一确定一张表。那么Topic同样是以名称确定唯一的，Topic名称不能重复。</li>
</ul>
<a id="more"></a>
<h2 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h2><p>一个Kafka的Server就称之为Broker，可以每台物理服务器上只部署一个Broker，可以将多个Broker部署在一台物理服务器上。本身Broker这个单词的意思是中间代理的意思。Broker负责接收Producer发送的消息、对消息进行持久化、让Consumer获取消息。</p>
<p>关于Broker，我们需要注意以下几点概念：</p>
<ul>
<li>Kafka集群就是由多个Broker组成的。</li>
<li>每个Broker都有一个整数类型的唯一标识ID。</li>
<li>当我们连接到任意一个Broker后，我们就已经连接到了整个Kafka集群。我们连接的第一个Broker称之为Bootstrap Broker。</li>
<li>通常，最小的Kafka集群最好有三个Broker。</li>
</ul>
<p>我们来看看Broker、Topic、Partition（后续章节会介绍）之间的关系。假设有Broker 101、Broker 102、Broker 103三个Broker。Topic-A、Topic-B两个Topic，这两个Topic分别有三个Partition和两个Partition。他们的关系如下图所示：</p>
<p><img src="http://devtalking.oss-cn-beijing.aliyuncs.com/2018/12/17/1545060563441.png" alt=""></p>
<p>可以看到，Topic的Partition在Kafka集群中是随机分配给Broker的。也就是说Topic-A的数据会分别被持久化在这三个Broker中，而Topic-B的数据只会持久化在Broker 101和Broker 102中。如果Topic-A再加一个Partition 4，则它会随机被分配给任意一个Broker。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一章节介绍了Topic和Broker的概念，Topic承载了Message的输入输出，相当于Kafka对外的窗户。Broker则负责Kafka内部核心的功能，比如Message持久化、如何保证Kafka高可用性等等。。在后续的章节里，会详细介绍它们的各种配置和用法。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Apache Kafka正是上节描述的MQ系统，但不仅是MQ系统，它往往也被描述为<strong>分布式提交日志系统</strong>或者<strong>分布式流式处理系统</strong>。从这节开始，我们将逐步了解Kafka的核心概念。</p>
<h2 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h2><p>在Kafka中，Topic可以理解为表示一组特殊的数据流。可以将它想象为关系性数据库中的表。</p>
<ul>
<li>数据库中的表存储着同一类的数据。那么Topic同样表示同一类的数据流。</li>
<li>数据库中的表可以根据需求创建多张。那么Topic同样可以根据需求创建多个，但有一点区别是，Topic没有像数据库表中约束（Constraints）的概念。</li>
<li>数据库中表的名称是不能重复的，表名能唯一确定一张表。那么Topic同样是以名称确定唯一的，Topic名称不能重复。</li>
</ul>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Kafka从上手到实践-初步认知：MQ系统]]></title>
    <link href="http://www.devtalking.com//articles/kafka-practice-1/"/>
    <id>http://www.devtalking.com//articles/kafka-practice-1/</id>
    <published>2018-08-14T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.007Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>首先我们来认知什么是MQ系统既消息队列（Message Queue）系统。举个不恰当的例子，消息（Message）就相当于自来水，队列（Queue）就相当于自来水管道，错综复杂的管道将自来水送给千家万户。在计算机领域，消息其实就是数据，各种格式的数据，队列就是运输数据的管道，通过各种运输策略将数据送达使用它们的地方。</p>
<h2 id="u6D88_u606F_u751F_u4EA7_u8005_uFF08Producer_uFF09"><a href="#u6D88_u606F_u751F_u4EA7_u8005_uFF08Producer_uFF09" class="headerlink" title="消息生产者（Producer）"></a>消息生产者（Producer）</h2><p>任何MQ系统都离不开消息生产者（后文中统一使用Producer），否则MQ系统也就没有了存在的意义。好比没有了水源，自来水管道也就没有意义了一样。MQ系统中的Producer既消息（数据）生产者，主要的作用就是生成数据，然后发送给MQ系统中的队列，通常情况下，消息生产者将生产出的消息丢给MQ系统的队列后通常就不再关心消息的去向了，所以它的职责主要就是生成数据，以及数据是否成功被队列接收。然后丢进队列。每个MQ系统都有自己的消息格式，以字节数组的形式在队列中传输。</p>
<a id="more"></a>
<h2 id="u6D88_u606F_u4E3B_u9898_uFF08Topic_uFF09"><a href="#u6D88_u606F_u4E3B_u9898_uFF08Topic_uFF09" class="headerlink" title="消息主题（Topic）"></a>消息主题（Topic）</h2><p>消息主题指的是一类消息，相当于数据库中的表，或文件系统中的一个文件夹，是MQ系统中一切的基础。我们来引用《Kafka：The Definitive Guide》一书中的例图来举例：</p>
<p><img src="https://user-gold-cdn.xitu.io/2019/1/3/1681196f3e9a65e4?w=521&amp;h=242&amp;f=jpeg&amp;s=38367" alt=""></p>
<p>图例展示的是一个独立的队列系统，图中的Metrics Pub/Sub，Logging Pub/Sub，Tracking Pub/Sub其实就是充当了Topic的作用，相当于对消息做了分类。</p>
<h2 id="u6D88_u606F_uFF08Message_uFF09"><a href="#u6D88_u606F_uFF08Message_uFF09" class="headerlink" title="消息（Message）"></a>消息（Message）</h2><p>MQ系统的内部数据单元一般称为消息（Message），消息类似数据库中的一行或一条记录。不同的MQ系统有不同的消息协议，这个消息协议的作用是为了让消息生产者和消息消费者都能够明白消息所承载的信息，既消息生产者需要知道如何构造消息，消息消费者需要知道如何解析消息，所以就需要有一种统一的格式来描述消息，这个描述消息的格式就是消息协议。</p>
<h2 id="u6570_u636E_u6301_u4E45_u5316_uFF08Data_Persistent_uFF09"><a href="#u6570_u636E_u6301_u4E45_u5316_uFF08Data_Persistent_uFF09" class="headerlink" title="数据持久化（Data Persistent）"></a>数据持久化（Data Persistent）</h2><p>在使用MQ系统时，数据的健壮性和一致性是至关重要的。试想一下，如果消息生产者生产了消息并且发送走了，但是在同时消息消费者掉线了，那么这条消息就很有可能丢失了，再或者消息生产者生产了一个很大的文件，需要将其序列化后送入队列，那么在消息被消费的时候，应该将序列化后的数据反序列化，如果序列化后的数据有个别丢失，那么就会导致反序列后的信息是不一致的。</p>
<p>所以在MQ系统中，数据持久化就是用来避免上述情况发生的。通常数据持久化的方式有文件存储，数据库存储两大类，其中还有一些参杂各种缓存机制。对数据持久化的时机也不尽相同，有些是在消息生产者端持久化，有些是在队列中持久化，也有在消息消费者端做持久化。同时对应的重新消费消息的机制和策略也会不相同，比如有消息生产者重发，也有消息消费者重新拉取等。</p>
<h2 id="u6D88_u606F_u6D88_u8D39_u8005_uFF08Consumer_uFF09"><a href="#u6D88_u606F_u6D88_u8D39_u8005_uFF08Consumer_uFF09" class="headerlink" title="消息消费者（Consumer）"></a>消息消费者（Consumer）</h2><p>消息消费者（后文中统一使用Consumer）顾名思义就是消息的使用者，通过订阅一个或多个不同的消息主题，获取到不同类别的消息进行使用。是整个MQ系统的最后一个环节。</p>
<h2 id="u5C0F_u7ED3"><a href="#u5C0F_u7ED3" class="headerlink" title="小结"></a>小结</h2><p>这一章节概括了什么是MQ系统，它应该具备哪些基本的功能，这些功能能做什么事情。让大家在脑海里对MQ系统有初步的认知。后续章节在介绍Kafka时其实都是对这几个模块的庖丁解牛。希望能给小伙伴们带来帮助。</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>首先我们来认知什么是MQ系统既消息队列（Message Queue）系统。举个不恰当的例子，消息（Message）就相当于自来水，队列（Queue）就相当于自来水管道，错综复杂的管道将自来水送给千家万户。在计算机领域，消息其实就是数据，各种格式的数据，队列就是运输数据的管道，通过各种运输策略将数据送达使用它们的地方。</p>
<h2 id="u6D88_u606F_u751F_u4EA7_u8005_uFF08Producer_uFF09"><a href="#u6D88_u606F_u751F_u4EA7_u8005_uFF08Producer_uFF09" class="headerlink" title="消息生产者（Producer）"></a>消息生产者（Producer）</h2><p>任何MQ系统都离不开消息生产者（后文中统一使用Producer），否则MQ系统也就没有了存在的意义。好比没有了水源，自来水管道也就没有意义了一样。MQ系统中的Producer既消息（数据）生产者，主要的作用就是生成数据，然后发送给MQ系统中的队列，通常情况下，消息生产者将生产出的消息丢给MQ系统的队列后通常就不再关心消息的去向了，所以它的职责主要就是生成数据，以及数据是否成功被队列接收。然后丢进队列。每个MQ系统都有自己的消息格式，以字节数组的形式在队列中传输。</p>]]>
    
    </summary>
    
      <category term="Kafka" scheme="http://www.devtalking.com/tags/Kafka/"/>
    
      <category term="中间件" scheme="http://www.devtalking.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[机器学习笔记十七之集成学习、随机森林]]></title>
    <link href="http://www.devtalking.com//articles/machine-learning-17/"/>
    <id>http://www.devtalking.com//articles/machine-learning-17/</id>
    <published>2018-07-31T16:00:00.000Z</published>
    <updated>2020-06-21T08:12:29.014Z</updated>
    <content type="html"><![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>到目前为止，我们已经学习了大概有八种机器学习的算法，其中有解决分类问题的，有解决回归问题的。这些算法其实没有谁是最好的，谁不好之说，反而应该将这些算法集合起来，发挥他们的最大价值。比如我们买东西或看电影之前，多少都会咨询身边的朋友，或去网上看看买家的评价，然后我们才会根据口碑好坏，或评价好坏决定买还是不买，看还是不看。在机器学习中，同样有这样的思路，这就是重要的集成学习。</p>
<h2 id="u96C6_u6210_u5B66_u4E60"><a href="#u96C6_u6210_u5B66_u4E60" class="headerlink" title="集成学习"></a>集成学习</h2><p>机器学习中的集成学习就是将选择若干算法，针对同一样本数据训练模型，然后看看结果，使用投票机制，少数服从多数，用多数算法给出的结果当作最终的决策依据，这就是集成学习的核心思路。下面我们先手动模拟一个使用集成学习解决回归问题的的示例：</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建500个点的样本数据</span></span><br><span class="line">X, y = datasets.make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.3</span>, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制样本数据</span></span><br><span class="line">plt.scatter(X[y==<span class="number">0</span>, <span class="number">0</span>], X[y==<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.scatter(X[y==<span class="number">1</span>, <span class="number">0</span>], X[y==<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/9c07fb9e783815c1557d2a2e01163bd9.jpg" alt=""></p>
<p>分别使用逻辑回归、SVM、决策树针对上面的样本数据训练模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 拆分样本数据</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用逻辑回归</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">log_clf = LogisticRegression()</span><br><span class="line">log_clf.fit(X_train, y_train)</span><br><span class="line">log_clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.872</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用SVM</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svc_clf = SVC()</span><br><span class="line">svc_clf.fit(X_train, y_train)</span><br><span class="line">svc_clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.89600000000000002</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用决策树</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt_clf = DecisionTreeClassifier()</span><br><span class="line">dt_clf.fit(X_train, y_train)</span><br><span class="line">dt_clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.85599999999999998</span></span><br></pre></td></tr></table></figure>
<p>可以看到，使用三种不同的分类算法训练出的模型，最后的$R^2$评分都不尽相同。下面我们使用投票的方式，选择出最终预测值，具体思路是先求出三种模型对测试数据的预测结果，将三个结果向量相加，得到新的结果向量，因为分类只有0和1，所以新的结果向量里的值最大为3，最小为0。然后通过Fancy Index的方式，求出三种模型预测中至少有2种预测为1的，才真正认为是1的分类，那么也就是新结果向量里大于等于2的结果，其余小于2的都认为是0的分类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 求出三种模型对测试数据的预测结果</span></span><br><span class="line">y_predict1 = log_clf.predict(X_test)</span><br><span class="line">y_predict2 = svc_clf.predict(X_test)</span><br><span class="line">y_predict3 = dt_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line">y_predict = np.array((y_predict1 + y_predict2 + y_predict3) &gt;= <span class="number">2</span>, dtype=<span class="string">'int'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算最终的评分</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">accuracy_score(y_test, y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.88800000000000001</span></span><br></pre></td></tr></table></figure>
<p>上面的示例是我们手动使用三种算法的结果通过投票方式求得了最终的决策依据。其实Scikit Learn中已经为我们封装了这种方式，名为<code>VotingClassifier</code>，既投票分类器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 引入投票分类器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># VotingClassifier和Pipeline的用法非常类似，这里的voting="hard"可以先忽略</span></span><br><span class="line">voting_clf = VotingClassifier(estimators=[</span><br><span class="line">	(<span class="string">"log_clf"</span>, LogisticRegression()),</span><br><span class="line">	(<span class="string">"svm_clf"</span>, SVC()),</span><br><span class="line">	(<span class="string">"dt_clf"</span>, DecisionTreeClassifier(random_state=<span class="number">666</span>))</span><br><span class="line">], voting=<span class="string">"hard"</span>)</span><br><span class="line"></span><br><span class="line">voting_clf.fit(X_train, y_train)</span><br><span class="line">voting_clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.88800000000000001</span></span><br></pre></td></tr></table></figure>
<p>可以看到，使用<code>VotingClassifier</code>最后的评分和我们手动模拟的是一致的。</p>
<h2 id="Soft_Voting"><a href="#Soft_Voting" class="headerlink" title="Soft Voting"></a>Soft Voting</h2><p>在上一节中，Scikit Learn提供的<code>VotingClassifier</code>有一个参数<code>voting</code>，我们传了<code>hard</code>这个值。其实这个参数就表示投票的方式，<code>hard</code>代表的就是少数服从多数的机制。</p>
<p>但是，其实在很多时候少数服从多数得到的结果并不是正确的，这个在日常生活中其实很常见，所谓真理掌握在少数人手里就是这个意思。所以更合理的投票机制应该是对投票人加以权重值，投票人越专业，越权威，那么权重值就应该高一些。就好比歌唱比赛，评委有三类人，第一类是音乐制作人，特点是人少，但权重值高，第二类是职业歌手，人数次之，权重值也次之，第三类是普通观众，这类人人数最多，但是权重值也最低。那么决定选手去留还是掌握在少数的音乐制作人和职业歌手这些评委。这个思路其实就是Soft Voting。</p>
<p>再举一个示例，假设有5个模型，针对同一个二分类问题，将每种类别都计算出了概率：</p>
<ul>
<li>模型1 A-99%，B-1%</li>
<li>模型2 A-49%，B-51%</li>
<li>模型3 A-40%，B-60%</li>
<li>模型4 A-90%，B-10%</li>
<li>模型5 A-30%，B-70%</li>
</ul>
<p>从上面的数据，明显可以得到，整体的分类应该B，因为模型2、模型3、模型5的结论都是B，所以按照Hard Voting方式，少数服从多数，那整体的类别会定为B。</p>
<p>但是我们可以换个角度去看问题，模型1和模型4对判定为类别A的概率都在90%以上，说明非常笃定。而模型2、模型3、模型5虽然结论为类别B，但是类别A和类别B的判定概率相差并不是很大。而我们将五种模型对类别A、类别B的概率加起来就可以明显的看到，判定为类别A的总概率为：</p>
<p>$$\frac {(0.99 + 0.49 + 0.4 + 0.9 + 0.3)} 5 = 0.616$$</p>
<p>而判定为类别B的总概率为：</p>
<p>$$\frac {(0.01 + 0.51 + 0.6 + 0.1 + 0.7)} 5 = 0.384$$</p>
<p>显然判定为类别A的总概率要远高于类别B，那么整体类别应该是A。</p>
<p>以上模型判定类别的概率其实就可以理解为权重值。所以Soft Voting要求集合里的每一个模型都能估计出类别的概率。那么我们来看看我们已经了解过的机器学习算法哪些是支持概率的：</p>
<ul>
<li>逻辑回归算法本身就是基于概率模型的，通过Sigmoid函数计算概率。</li>
<li>kNN算法也是支持估计概率的，如果和预测点相邻的3个点，有2个点是红色，1个是蓝色，那么可以很容计算出红色类别的概率是$\frac 2 3$，蓝色类别的概率是$\frac 1 3$。</li>
<li>决策树算法也是支持估计概率的，它的思路和kNN的很相近，每个叶子节点中如果信息熵或基尼系数不为0，那么就肯定至少包含2种以上的类别，那么用一个类别的数量除以所有类别的数据就能得到概率。</li>
<li>SVM算法本身是不能够天然支持估计概率的。不过Scikit Learn中提供的<code>SVC</code>通过其他方式实现了估计概率的能力，代价就是增加了算法的时间复杂度和训练时间。它有一个<code>probability</code>参数，默认为<code>false</code>既不支持估计概率，如果显示传入<code>true</code>，那么就会启用估计概率的能力。</li>
</ul>
<p>下面来看看Soft Voting如何使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 还是使用上一节的数据，同样构建VotingClassifier，voiting参数传入soft。这里注意SVC要显示传入probability=True</span></span><br><span class="line">voting_clf1 = VotingClassifier(estimators=[</span><br><span class="line">	(<span class="string">"log_clf"</span>, LogisticRegression()),</span><br><span class="line">	(<span class="string">"svm_clf"</span>, SVC(probability=<span class="keyword">True</span>)),</span><br><span class="line">	(<span class="string">"dt_clf"</span>, DecisionTreeClassifier(random_state=<span class="number">666</span>))</span><br><span class="line">], voting=<span class="string">"soft"</span>)</span><br><span class="line"></span><br><span class="line">voting_clf1.fit(X_train, y_train)</span><br><span class="line">voting_clf1.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.89600000000000002</span></span><br></pre></td></tr></table></figure>
<p>可以看到Soft Voting相比较Hard Voting，预测评分是有提高的。</p>
<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>上两节主要介绍了集成学习的原理。那么就这个原理而言，它的好坏是有一个基本的先决条件的。对于投票机制而言，5个人投票和1000个人投票得到的结果，毫无疑问是后者更具有说服力。所以前两节我们只使用了三个机器学习算法训练的模型去投票是不具有很强的说服力的。那么问题来了，我们如何能有更多的模型，来作为投票者呢？这就是这一节要说的取样问题。</p>
<p>我们知道机器学习算法是有限的，有几十个就顶破天了，所以用不同的算法这条路是行不通的，那么我们就从同一种算法的不同模型这个思路入手。基本思路就是使用一种机器学习算法，创建更多的子模型，然后集成这些子模型的意见进行投票，有个前提是子模型之间不能一致，要有差异性。这一点大家应该很好理解，模型之间的差异性越大，投票才有意义。</p>
<p>那么如何创建子模型的差异性呢？通常的做法是训练每个子模型时只看样本数据的一部分，比如一共有1000个样本数据，每个子模型只看100个样本数据，因为样本数据有差异性，所以训练出的子模型之间就自然存在差异性了。这时问题又来了，训练子模型时只这么少的样本数据，那么每个子模型的准确率自然会比较低。此时就应征了，人多力量大，一把筷子折不断的道理。</p>
<p>假设有三个子模型，每个子模型的准确率只有51%，为什么要用51%作为示例呢，因为投硬币的概率都有50%，所以比它只高一点，算是很低的准确率了。那么整体的准确率为：</p>
<p>$$0.51^3 + C_3^2 \cdot 0.51^2 \cdot 0.49 = 0.515$$</p>
<p>三个准确率为51%的子模型，可以使整体的准确率提高至51.5%。那如果是500个子模型，整体的准确率会提升至：</p>
<p>$$\sum_{i=251}^{500}C_{500}^i \cdot 0.51^i \cdot 0.49^{500-i} = 0.656$$</p>
<p>可见当子模型的数量增加时，同时会增加整体的准确率。所以其实子模型并不需要太高的准确率。</p>
<h3 id="u5B50_u6A21_u578B_u53D6_u6837_u65B9_u5F0F"><a href="#u5B50_u6A21_u578B_u53D6_u6837_u65B9_u5F0F" class="headerlink" title="子模型取样方式"></a>子模型取样方式</h3><p>子模型的取样方式有两种：</p>
<ul>
<li>放回取样：每次取完训练子模型的部分样本数据后，再放回样本数据池里，训练下一个子模型使用同样的方式。这样的方式，训练不同的子模型会可能会用到小部分相同的样本数据。</li>
<li>不放回取样：每次取完训练子模型的部分样本数据后，这部分样本数据不再放回样本数据池里，训练下一个子模型使用同样的方式。这样的方式，训练不同的子模型的样本数据不会重复。</li>
</ul>
<p>通常使用放回取样的方式更多，举个例子，假如有500个样本数据，训练子模型时使用50条数据，那么使用不放回取样只能训练出10个子模型。而如果使用放回取样的话，理论上可以训练出成千上万个子模型。在机器学习中，将取样称为Bagging。而在统计学中，放回取样称为Bootstrap。</p>
<p>下面我们用代码来看看如何使用取样的方式训练子模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 还是使用之前构造的样本数据</span></span><br><span class="line"><span class="comment"># 我们使用决策树这个算法，然后导入BaggingClassifier</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># BaggingClassifier的第一个参数是给定一个算法类型</span></span><br><span class="line"><span class="comment"># n_estimators参数是创建多少个子模型</span></span><br><span class="line"><span class="comment"># max_samples参数是每个子模型使用多少样本数据训练</span></span><br><span class="line"><span class="comment"># bootstrap为True表示为放回取样方式，为False表示为不放回取样方式</span></span><br><span class="line">bagging_clf = BaggingClassifier(</span><br><span class="line">	DecisionTreeClassifier(), n_estimators=<span class="number">500</span>, max_samples=<span class="number">100</span>, bootstrap=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">bagging_clf.fit(X_train, y_train)</span><br><span class="line">bagging_clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.88</span></span><br></pre></td></tr></table></figure>
<h3 id="OOB"><a href="#OOB" class="headerlink" title="OOB"></a>OOB</h3><p>使用放回取样方式虽然可以构建更多的子模型，但是它有一个问题，那就是在有限次的放回取样过程中，有一部分样本数据可能根本没有取到，按严格的数学计算，这个比例大概是37%。这个情况称为OOB（Out of Bag）换个思路思考，这37%根本没有被用到的样本数据恰好可以作为测试数据来用，所以在使用这种方式时，我们可以不用<code>train_test_split</code>对样本数据进行拆分，直接使用没有被用到的这37%的样本数据既可。来看看<code>BaggingClassifier</code>如何使用OOB：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多加一个参数oob_score，True为使用OOB，既记住哪些样本取过，哪些没取过</span></span><br><span class="line">bagging_clf = BaggingClassifier(</span><br><span class="line">	DecisionTreeClassifier(), </span><br><span class="line">	n_estimators=<span class="number">500</span>, </span><br><span class="line">	max_samples=<span class="number">100</span>, </span><br><span class="line">	bootstrap=<span class="keyword">True</span>,</span><br><span class="line">	oob_score=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">bagging_clf.fit(X, y)</span><br><span class="line"><span class="comment"># 使用没取过样本作为测试数据</span></span><br><span class="line">bagging_clf.oob_score_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.91000000000000003</span></span><br></pre></td></tr></table></figure>
<p>可以看到准确率是有所提高的。</p>
<h3 id="u5E76_u53D1_u53D6_u6837"><a href="#u5E76_u53D1_u53D6_u6837" class="headerlink" title="并发取样"></a>并发取样</h3><p>按照Bagging的思路，因为不需要保证每次取样的唯一性，所以每次取样是可以并行处理的。我们可以使用<code>n_jobs</code>指定运行的CPU核数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先看看之前的训练时间</span></span><br><span class="line">%%time</span><br><span class="line">bagging_clf = BaggingClassifier(</span><br><span class="line">	DecisionTreeClassifier(), </span><br><span class="line">	n_estimators=<span class="number">500</span>, </span><br><span class="line">	max_samples=<span class="number">100</span>, </span><br><span class="line">	bootstrap=<span class="keyword">True</span>,</span><br><span class="line">	oob_score=<span class="keyword">True</span>)</span><br><span class="line">bagging_clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">CPU times: user <span class="number">717</span> ms, sys: <span class="number">6.41</span> ms, total: <span class="number">724</span> ms</span><br><span class="line">Wall time: <span class="number">723</span> ms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再看看加了n_jobs参数后的训练时间，n_jobs=-1表示使用电脑的所有CPU核数</span></span><br><span class="line">%%time</span><br><span class="line">bagging_clf = BaggingClassifier(</span><br><span class="line">	DecisionTreeClassifier(), </span><br><span class="line">	n_estimators=<span class="number">500</span>, </span><br><span class="line">	max_samples=<span class="number">100</span>, </span><br><span class="line">	bootstrap=<span class="keyword">True</span>,</span><br><span class="line">	oob_score=<span class="keyword">True</span>,</span><br><span class="line">	n_jobs=-<span class="number">1</span>)</span><br><span class="line">bagging_clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">CPU times: user <span class="number">264</span> ms, sys: <span class="number">57.6</span> ms, total: <span class="number">322</span> ms</span><br><span class="line">Wall time: <span class="number">571</span> ms</span><br></pre></td></tr></table></figure>
<p>可以看到，训练时间缩短了150多毫秒。</p>
<blockquote>
<p>在<a href="http://www.devtalking.com/articles/machine-learning-4/"> 机器学习笔记四之kNN算法、超参数、数据归一化 </a>中的网格搜索超参数一节介绍过n_jobs参数。</p>
</blockquote>
<h3 id="u7279_u5F81_u53D6_u6837"><a href="#u7279_u5F81_u53D6_u6837" class="headerlink" title="特征取样"></a>特征取样</h3><p>我们之前讲的都是对样本数据条数进行随机取样，<code>BaggingClassifier</code>还可以对特征进行随机取样，这样更能增加子模型的差异性，称为Random Subspaces。另外还有既对样本条数取样，又针对特征随机取样的方式，称为Random Patches。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># max_features 表示随机取几个特征</span></span><br><span class="line"><span class="comment"># bootstrap_features为True表示对特征取样是放回取样方式</span></span><br><span class="line">random_subspaces_clf = BaggingClassifier(</span><br><span class="line">	DecisionTreeClassifier(), </span><br><span class="line">	n_estimators=<span class="number">500</span>, </span><br><span class="line">	max_samples=<span class="number">500</span>, </span><br><span class="line">	bootstrap=<span class="keyword">True</span>,</span><br><span class="line">	oob_score=<span class="keyword">True</span>,</span><br><span class="line">	n_jobs=-<span class="number">1</span>,</span><br><span class="line">	max_features=<span class="number">1</span>,</span><br><span class="line">	bootstrap_features=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">random_subspaces_clf.fit(X, y)</span><br><span class="line">random_subspaces_clf.oob_score_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.82999999999999996</span></span><br></pre></td></tr></table></figure>
<p>首先将<code>max_samples</code>设置为500，意在取消对样本数据条数随机取样，因为一共有500个样本数据，要创建500个子模型，如果每个子模型都使用500个样本数据，那相当于对样本条数取样是没有意义的。又因为我们的样本特征只有2个，所以<code>max_features</code>设置为1。</p>
<p>如果将<code>max_samples</code>设回100的话，那就是既对样本条数随机取样，又对特征随机取样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">random_patches_clf = BaggingClassifier(</span><br><span class="line">	DecisionTreeClassifier(), </span><br><span class="line">	n_estimators=<span class="number">100</span>, </span><br><span class="line">	max_samples=<span class="number">500</span>, </span><br><span class="line">	bootstrap=<span class="keyword">True</span>,</span><br><span class="line">	oob_score=<span class="keyword">True</span>,</span><br><span class="line">	n_jobs=-<span class="number">1</span>,</span><br><span class="line">	max_features=<span class="number">1</span>,</span><br><span class="line">	bootstrap_features=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">random_patches_clf.fit(X, y)</span><br><span class="line">random_patches_clf.oob_score_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.79400000000000004</span></span><br></pre></td></tr></table></figure>
<h2 id="u968F_u673A_u68EE_u6797"><a href="#u968F_u673A_u68EE_u6797" class="headerlink" title="随机森林"></a>随机森林</h2><p>前面几个章节介绍了集成学习的原理。在集成学习中，如果使用决策树，通过取样的方式创建子模型，这些子模型就是一个个随机的决策树。我们管这种方式形象的称为随机森林。在Scikit Learn中，也为我们封装好了随机森林的类，它的原理和上一小节示例中通过<code>BaggingClassifier</code>和<code>DecisionTreeClassifier</code>构建的分类器基本是一样的。我们来看看如何使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rf_clf = RandomForestClassifier(n_estimators=<span class="number">500</span>, oob_score=<span class="keyword">True</span>, random_state=<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 还是使用之前构建的样本数据</span></span><br><span class="line">rf_clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">RandomForestClassifier(bootstrap=<span class="keyword">True</span>, class_weight=<span class="keyword">None</span>, criterion=<span class="string">'gini'</span>,</span><br><span class="line">			max_depth=<span class="keyword">None</span>, max_features=<span class="string">'auto'</span>, max_leaf_nodes=<span class="keyword">None</span>,</span><br><span class="line">			min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="keyword">None</span>,</span><br><span class="line">			min_samples_leaf=<span class="number">1</span>, min_samples_split=<span class="number">2</span>,</span><br><span class="line">			min_weight_fraction_leaf=<span class="number">0.0</span>, n_estimators=<span class="number">500</span>, n_jobs=<span class="number">1</span>,</span><br><span class="line">			oob_score=<span class="keyword">True</span>, random_state=<span class="number">666</span>, verbose=<span class="number">0</span>, warm_start=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">rf_clf.oob_score_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.89200000000000002</span></span><br></pre></td></tr></table></figure>
<p><code>fit</code>之后，从返回结果里可以看到，<code>RandomForestClassifier</code>的参数综合了<code>BaggingClassifier</code>及<code>DecisionTreeClassifier</code>的参数。我们可以对不同的参数进行调优，训练出更好的模型。</p>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>我们之前介绍的集成学习中子模型之间是相互独立的，差异越大越好。那么集成学习中还有一种创建子模型的方式，就是每个子模型之间有关联，都在尝试增强整体的效果。这种方式称为Boosting方式。</p>
<h3 id="Ada_Boosting"><a href="#Ada_Boosting" class="headerlink" title="Ada Boosting"></a>Ada Boosting</h3><p>在Boosting方式中，有一种方式称为Ada Boosting，我们用网络上的一幅解决回归问题的图来做以解释：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/dc245dddc9e81012b48a1edc4ef88f9e.jpg" alt=""></p>
<p>我们先来看第一个齿轮上下连接的图，下面的图是原始样本数据，每个样本点的权重值都是一样的，上面的图是第一个子模型预测出的结果，那势必会有没有被准确预测的样本点，将这些样本点的权重值加大。</p>
<p>第二列下图中展示的深色点就是权重值增大的样本点，浅色点是上一个子模型预测出的样本点。那么训练第二个子模型时会优先考虑权重大的样本点进行拟合，拟合出的结果如第二列上图所示。</p>
<p>然后再将第二个子模型没有预测出的样本点的权重值增大，如第三列下图所示，在训练第三个子模型时优先考虑第二个子模型没有预测出的样本点进行拟合。以此类推，这样就可以训练出很多子模型，不同于取样方式，Boosting方式的所有子模型使用全量的样本数据进行训练，不过样本数据有权重值的概念，而且后一个子模型是在完善上一个子模型的错误，从而所有子模型达到增强整体的作用。这就是Ada Boosting的原理。</p>
<p>下面来看看Scikit Learn为我们提供的<code>AdaBoostClassifier</code>如何使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=<span class="number">2</span>), n_estimators=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Boosting方式没有OOB的概念，所以还是需要使用拆分后的样本数据</span></span><br><span class="line">ada_clf.fit(X_train, y_train)</span><br><span class="line">ada_clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.86399999999999999</span></span><br></pre></td></tr></table></figure>
<h3 id="Gradient_Boosting"><a href="#Gradient_Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h3><p>还有一种Boosting的方式称为Gradient Boosting。它的原理是我们训练第一个子模型M1，它肯定会有没有准确预测到的样本，我们称为错误E1。然后我们将E1这些样本点作为训练第二个子模型的样本数据，训练出第二个子模型M2，然后它必然还会产生错误E2。那么再将E2作为训练第三个子模型的样本数据，产生错误E3，以此类推，训练出多个子模型。最终预测的结果是M1+M2+M3+…的结果。</p>
<p>下面来看看Scikit Learn为我们提供的<code>GradientBoostingClassifier</code>如何使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># GradientBoostingClassifier本身就是使用决策树作为算法实现的，所以不再需要传入算法实例</span></span><br><span class="line">gd_clf = GradientBoostingClassifier(max_depth=<span class="number">2</span>, n_estimators=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Boosting方式没有OOB的概念，所以还是需要使用拆分后的样本数据</span></span><br><span class="line">gd_clf.fit(X_train, y_train)</span><br><span class="line">gd_clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">0.90400000000000003</span></span><br></pre></td></tr></table></figure>
<h2 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h2><p>这一小节我们再来认识一个集成学习创建子模型的思路，Stacking。</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/906458322308a046b8ed9a5054bea0ee.jpg" alt=""></p>
<p>上图也是网络上的一幅图，我们先看中间那层，Subset1和Subset2是将原始样本数据分成两部分后的数据，我们先使用Subset1训练出三个子模型，这三个子模型会产生错误，既没有预测到的样本数据。然后将这三个子模型的三个错误结果和Subset2组成新的样本数据，训练出第四个子模型。整体的预测结果以第四个子模型的结果为准。这就是Stacking的基本原理，通过Stacking方式可以构建出比较复杂的子模型关系网：</p>
<p><img src="https://devtalking.oss-cn-beijing.aliyuncs.com/5694b519f162aa165a3c99ba2b0d8e39.jpg" alt=""></p>
<p>上图有三层，一共7个子模型，就需要将原始样本数据分成三份，第一份作为训练第一层三个子模型的样本数据，第二份作为训练第二层子模型的样本数据其中一部分，以此类推。</p>
<p>不过在Scikit Learn中没有提供任何Stacking的类供我们使用，Stacking的原理已经有神经网络的雏形了，里面涉及到的调参环节非常多，大家有兴趣可以自己尝试实现Stacking算法。</p>
<blockquote>
<p>申明：本文为慕课网<a href="https://www.imooc.com/t/108955" target="_blank" rel="external">liuyubobobo</a>老师<a href="https://coding.imooc.com/learn/list/169.html" target="_blank" rel="external">《Python3入门机器学习 经典算法与应用》</a>课程的学习笔记，未经允许不得转载。</p>
</blockquote>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-4115205380866695" data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

]]></content>
    <summary type="html">
    <![CDATA[<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- DevTalking Banner1 -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-4115205380866695"
     data-ad-slot="5844761160"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>到目前为止，我们已经学习了大概有八种机器学习的算法，其中有解决分类问题的，有解决回归问题的。这些算法其实没有谁是最好的，谁不好之说，反而应该将这些算法集合起来，发挥他们的最大价值。比如我们买东西或看电影之前，多少都会咨询身边的朋友，或去网上看看买家的评价，然后我们才会根据口碑好坏，或评价好坏决定买还是不买，看还是不看。在机器学习中，同样有这样的思路，这就是重要的集成学习。</p>
<h2 id="u96C6_u6210_u5B66_u4E60"><a href="#u96C6_u6210_u5B66_u4E60" class="headerlink" title="集成学习"></a>集成学习</h2><p>机器学习中的集成学习就是将选择若干算法，针对同一样本数据训练模型，然后看看结果，使用投票机制，少数服从多数，用多数算法给出的结果当作最终的决策依据，这就是集成学习的核心思路。下面我们先手动模拟一个使用集成学习解决回归问题的的示例：</p>]]>
    
    </summary>
    
      <category term="Bagging" scheme="http://www.devtalking.com/tags/Bagging/"/>
    
      <category term="Boosting" scheme="http://www.devtalking.com/tags/Boosting/"/>
    
      <category term="Stacking" scheme="http://www.devtalking.com/tags/Stacking/"/>
    
      <category term="机器学习" scheme="http://www.devtalking.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="随机森林" scheme="http://www.devtalking.com/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
    
      <category term="集成学习" scheme="http://www.devtalking.com/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习算法" scheme="http://www.devtalking.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
